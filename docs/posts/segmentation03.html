<!DOCTYPE html>
<html lang="ja-jp">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Python + ESPNetをオリジナルデータで学習する(学習編) | ハムレット型エンジニアのカンニングノート</title>
    <meta name="generator" content="VuePress 1.8.2">
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>(adsbygoogle = window.adsbygoogle || []).push({  google_ad_client: "ca-pub-2263820744635038",  enable_page_level_ads: true });</script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.0/dist/katex.min.css">
    <meta name="description" content="Python + ESPNetでCityscapesデータセットから人のみを抽出した仮のオリジナルデータで学習を実施します．">
    <meta property="article:published_time" content="2021-03-23T00:00:00.000Z">
    <meta property="article:modified_time" content="2021-08-21T03:21:52.000Z">
    <meta property="og:site_name" content="ハムレット型エンジニアのカンニングノート">
    <meta property="og:title" content="Python + ESPNetをオリジナルデータで学習する(学習編)">
    <meta property="og:description" content="Python + ESPNetでCityscapesデータセットから人のみを抽出した仮のオリジナルデータで学習を実施します．">
    <meta property="og:type" content="article">
    <meta property="og:url" content="/posts/segmentation03.html">
    <meta property="og:image" content="https://www.hamlet-engineer.com/image/org_seg1.png">
    <meta name="twitter:title" content="Python + ESPNetをオリジナルデータで学習する(学習編)">
    <meta name="twitter:description" content="Python + ESPNetでCityscapesデータセットから人のみを抽出した仮のオリジナルデータで学習を実施します．">
    <meta name="twitter:url" content="/posts/segmentation03.html">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:image" content="https://www.hamlet-engineer.com/image/org_seg1.png">
    <meta name="twitter:label2" content="Filed under">
    <meta name="twitter:data2" content="Python, Jupyter, ESPNet, セマンティックセグメンテーション">
    <meta property="article:tag" content="Python">
    <meta name="google-site-verification" content="BDXGk8FJfikB_I6Pyxv35Zc87jBMziCgRMvmpNDpdYA">
    
    <link rel="preload" href="/assets/css/0.styles.f79f4c23.css" as="style"><link rel="preload" href="/assets/js/app.3cfd382f.js" as="script"><link rel="preload" href="/assets/js/89.d8bb9cc1.js" as="script"><link rel="prefetch" href="/assets/js/10.387bb19e.js"><link rel="prefetch" href="/assets/js/100.a799ffa0.js"><link rel="prefetch" href="/assets/js/101.fa60a035.js"><link rel="prefetch" href="/assets/js/102.25f376bb.js"><link rel="prefetch" href="/assets/js/103.0907ab72.js"><link rel="prefetch" href="/assets/js/104.dea8a754.js"><link rel="prefetch" href="/assets/js/105.23c78c9b.js"><link rel="prefetch" href="/assets/js/106.b65e2105.js"><link rel="prefetch" href="/assets/js/107.ec091658.js"><link rel="prefetch" href="/assets/js/108.1eb16650.js"><link rel="prefetch" href="/assets/js/109.70af0358.js"><link rel="prefetch" href="/assets/js/11.c03d9f1e.js"><link rel="prefetch" href="/assets/js/110.c89d2632.js"><link rel="prefetch" href="/assets/js/111.a44d9bf3.js"><link rel="prefetch" href="/assets/js/112.5b9d6d73.js"><link rel="prefetch" href="/assets/js/113.d8b958dc.js"><link rel="prefetch" href="/assets/js/114.fb069c41.js"><link rel="prefetch" href="/assets/js/115.652a1464.js"><link rel="prefetch" href="/assets/js/116.9fec312b.js"><link rel="prefetch" href="/assets/js/117.326a4209.js"><link rel="prefetch" href="/assets/js/118.deb368dc.js"><link rel="prefetch" href="/assets/js/119.8c1bf770.js"><link rel="prefetch" href="/assets/js/12.6b53bc93.js"><link rel="prefetch" href="/assets/js/120.2650bc3a.js"><link rel="prefetch" href="/assets/js/121.49efe1b6.js"><link rel="prefetch" href="/assets/js/122.dd524cac.js"><link rel="prefetch" href="/assets/js/123.8e1fdba5.js"><link rel="prefetch" href="/assets/js/124.6a42f4d8.js"><link rel="prefetch" href="/assets/js/125.1eade554.js"><link rel="prefetch" href="/assets/js/126.b7bf7959.js"><link rel="prefetch" href="/assets/js/127.e61d1645.js"><link rel="prefetch" href="/assets/js/128.1c5217e5.js"><link rel="prefetch" href="/assets/js/129.7ac7c760.js"><link rel="prefetch" href="/assets/js/13.3b3badef.js"><link rel="prefetch" href="/assets/js/130.43bd0c2f.js"><link rel="prefetch" href="/assets/js/131.35db070d.js"><link rel="prefetch" href="/assets/js/132.dc24c499.js"><link rel="prefetch" href="/assets/js/14.187217cc.js"><link rel="prefetch" href="/assets/js/15.923f60e7.js"><link rel="prefetch" href="/assets/js/16.f8a98b29.js"><link rel="prefetch" href="/assets/js/17.3fde79f0.js"><link rel="prefetch" href="/assets/js/18.da60d686.js"><link rel="prefetch" href="/assets/js/19.780b6aaa.js"><link rel="prefetch" href="/assets/js/2.e26bae79.js"><link rel="prefetch" href="/assets/js/20.01611bf3.js"><link rel="prefetch" href="/assets/js/21.d7457e09.js"><link rel="prefetch" href="/assets/js/22.90cd91e2.js"><link rel="prefetch" href="/assets/js/23.45bbae45.js"><link rel="prefetch" href="/assets/js/24.7945179a.js"><link rel="prefetch" href="/assets/js/25.9fa87841.js"><link rel="prefetch" href="/assets/js/26.614c844f.js"><link rel="prefetch" href="/assets/js/27.9b2e5048.js"><link rel="prefetch" href="/assets/js/28.162483d5.js"><link rel="prefetch" href="/assets/js/29.d9909fd1.js"><link rel="prefetch" href="/assets/js/3.928b27a3.js"><link rel="prefetch" href="/assets/js/30.6fcff0e9.js"><link rel="prefetch" href="/assets/js/31.771e74e1.js"><link rel="prefetch" href="/assets/js/32.ed1f5775.js"><link rel="prefetch" href="/assets/js/33.9dbf45bf.js"><link rel="prefetch" href="/assets/js/34.4d05c87d.js"><link rel="prefetch" href="/assets/js/35.560c9532.js"><link rel="prefetch" href="/assets/js/36.e10da7da.js"><link rel="prefetch" href="/assets/js/37.af72d88f.js"><link rel="prefetch" href="/assets/js/38.b5a52184.js"><link rel="prefetch" href="/assets/js/39.762b6bb9.js"><link rel="prefetch" href="/assets/js/4.067e6e97.js"><link rel="prefetch" href="/assets/js/40.d02b246c.js"><link rel="prefetch" href="/assets/js/41.9806e32e.js"><link rel="prefetch" href="/assets/js/42.013b9cb0.js"><link rel="prefetch" href="/assets/js/43.2dd25cf7.js"><link rel="prefetch" href="/assets/js/44.de3f60c8.js"><link rel="prefetch" href="/assets/js/45.1a2993b2.js"><link rel="prefetch" href="/assets/js/46.6c8b0a69.js"><link rel="prefetch" href="/assets/js/47.675d93e1.js"><link rel="prefetch" href="/assets/js/48.17b77f37.js"><link rel="prefetch" href="/assets/js/49.347861f4.js"><link rel="prefetch" href="/assets/js/5.6efe9776.js"><link rel="prefetch" href="/assets/js/50.f6341873.js"><link rel="prefetch" href="/assets/js/51.f1ddc38b.js"><link rel="prefetch" href="/assets/js/52.e98162c7.js"><link rel="prefetch" href="/assets/js/53.96725d3e.js"><link rel="prefetch" href="/assets/js/54.1e5808cb.js"><link rel="prefetch" href="/assets/js/55.4f02871b.js"><link rel="prefetch" href="/assets/js/56.9eb69c66.js"><link rel="prefetch" href="/assets/js/57.281ff3ce.js"><link rel="prefetch" href="/assets/js/58.4f7906ee.js"><link rel="prefetch" href="/assets/js/59.93778594.js"><link rel="prefetch" href="/assets/js/6.fd7bbb92.js"><link rel="prefetch" href="/assets/js/60.0ffb588d.js"><link rel="prefetch" href="/assets/js/61.10ae7b38.js"><link rel="prefetch" href="/assets/js/62.846ed723.js"><link rel="prefetch" href="/assets/js/63.1cdfb99f.js"><link rel="prefetch" href="/assets/js/64.497a5efd.js"><link rel="prefetch" href="/assets/js/65.83fb5a70.js"><link rel="prefetch" href="/assets/js/66.e6b550a8.js"><link rel="prefetch" href="/assets/js/67.7d200d6a.js"><link rel="prefetch" href="/assets/js/68.c82dec0b.js"><link rel="prefetch" href="/assets/js/69.bced1ad8.js"><link rel="prefetch" href="/assets/js/7.1f44172b.js"><link rel="prefetch" href="/assets/js/70.db8e428f.js"><link rel="prefetch" href="/assets/js/71.ca4767a2.js"><link rel="prefetch" href="/assets/js/72.823b43d2.js"><link rel="prefetch" href="/assets/js/73.29f35506.js"><link rel="prefetch" href="/assets/js/74.b8457674.js"><link rel="prefetch" href="/assets/js/75.5e17669f.js"><link rel="prefetch" href="/assets/js/76.1aeee3e6.js"><link rel="prefetch" href="/assets/js/77.73d951ce.js"><link rel="prefetch" href="/assets/js/78.42215c0d.js"><link rel="prefetch" href="/assets/js/79.5c2d2373.js"><link rel="prefetch" href="/assets/js/8.8d94ecb4.js"><link rel="prefetch" href="/assets/js/80.74bea07d.js"><link rel="prefetch" href="/assets/js/81.faddc4c8.js"><link rel="prefetch" href="/assets/js/82.3c0356dd.js"><link rel="prefetch" href="/assets/js/83.3c49cc26.js"><link rel="prefetch" href="/assets/js/84.f886a39c.js"><link rel="prefetch" href="/assets/js/85.3c7aa2d4.js"><link rel="prefetch" href="/assets/js/86.ce8eecfb.js"><link rel="prefetch" href="/assets/js/87.33770ab7.js"><link rel="prefetch" href="/assets/js/88.dc78b2ad.js"><link rel="prefetch" href="/assets/js/9.4e1f9b25.js"><link rel="prefetch" href="/assets/js/90.88c0f352.js"><link rel="prefetch" href="/assets/js/91.ee6d7c69.js"><link rel="prefetch" href="/assets/js/92.99c31009.js"><link rel="prefetch" href="/assets/js/93.e2ff9b79.js"><link rel="prefetch" href="/assets/js/94.0f30c88b.js"><link rel="prefetch" href="/assets/js/95.44874624.js"><link rel="prefetch" href="/assets/js/96.b34a82f7.js"><link rel="prefetch" href="/assets/js/97.9085d8bb.js"><link rel="prefetch" href="/assets/js/98.a42ed7ab.js"><link rel="prefetch" href="/assets/js/99.2597b73c.js">
    <link rel="stylesheet" href="/assets/css/0.styles.f79f4c23.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><section id="global-layout" data-v-98a81704><header class="header" data-v-00466d8e data-v-98a81704><div class="header-navbar" data-v-00466d8e><div class="flex-xbc main header-nav" data-v-00466d8e><div class="nav-link" data-v-00466d8e><a href="/" class="inblock link-logo router-link-active" data-v-00466d8e><img data-src="/logo.png" loading="lazy" alt="logo" class="logo-img lazy" data-v-00466d8e></a> <nav class="link-list" data-v-00466d8e><a href="/" class="list-item router-link-active" data-v-00466d8e>ホーム</a><a href="/about/" class="list-item" data-v-00466d8e>ページ集</a><a href="/posts/" class="list-item router-link-active" data-v-00466d8e>技術</a><a href="/study/" class="list-item" data-v-00466d8e>小ネタ</a><a href="/other/" class="list-item" data-v-00466d8e>その他</a><a href="/tag/" class="list-item" data-v-00466d8e>タグ</a><a href="/category/" class="list-item" data-v-00466d8e>カテゴリ</a><a href="https://twitter.com/hirasu1231" target="_blank" rel="noopener noreferrer" class="list-item" data-v-00466d8e>筆者</a></nav></div> <div class="search-box" data-v-00466d8e><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div></div></div> </header> <!----> <section class="page" data-v-98a81704 data-v-98a81704><section class="info no-bg" data-v-2602fa21><article class="main info-content" data-v-c4dc5dfa data-v-2602fa21><div class="content-header" data-v-c4dc5dfa><h1 class="header-title" data-v-c4dc5dfa>Python + ESPNetをオリジナルデータで学習する(学習編)</h1></div> <div class="flex-wcc content-tag" data-v-c4dc5dfa><div class="inblock tag-list" data-v-c4dc5dfa><a href="/category/Python/" class="tag-text" data-v-c4dc5dfa>Python
      </a></div> <span class="tag-space" data-v-c4dc5dfa>/</span> <div class="inblock tag-list" data-v-c4dc5dfa><a href="/tag/Python/" class="tag-text" data-v-c4dc5dfa>Python
      </a><a href="/tag/Jupyter/" class="tag-text" data-v-c4dc5dfa>Jupyter
      </a><a href="/tag/ESPNet/" class="tag-text" data-v-c4dc5dfa>ESPNet
      </a><a href="/tag/セマンティックセグメンテーション/" class="tag-text" data-v-c4dc5dfa>セマンティックセグメンテーション
      </a></div></div> <div class="content content__default" data-v-c4dc5dfa><p>セマンティックセグメンテーションの中で軽いモデルであるESPNetv2を実装します．<br>
本稿ではCityscapesデータセットから人のみを抽出した仮のオリジナルデータで学習を実施します．<br></p> <!----> <p>今回はGoogle ColabとGoogle Driveを連携させて，notebook形式で実行してます．<br></p> <blockquote><p>Google Colaboratory（以下Google Colab）は、Google社が無料で提供している機械学習の教育や研究用の開発環境です。開発環境はJupyter Notebookに似たインターフェースを持ち、Pythonの主要なライブラリがプリインストールされています。<br>
引用元：<a href="https://interface.cqpub.co.jp/ail01/" target="_blank" rel="noopener noreferrer">Google Colabの使い方<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p></blockquote> <p>最終的に，人以外の背景を着色して，zoomのバーチャル背景機能のようなクロマキー合成を実装したいです．<br> <img alt="" data-src="/image/zoom.jpg" loading="lazy" class="lazy"></p> <p></p><div class="table-of-contents"><ul><li><a href="#作業ディレクトリのファイル構成">作業ディレクトリのファイル構成</a></li><li><a href="#オリジナルデータの学習">オリジナルデータの学習</a><ul><li><a href="#オリジナルデータの学習コードの作成">オリジナルデータの学習コードの作成</a></li><li><a href="#オリジナルデータの学習-第1段階">オリジナルデータの学習(第1段階)</a></li><li><a href="#オリジナルデータの学習-第2段階">オリジナルデータの学習(第2段階)</a></li></ul></li><li><a href="#オリジナルデータモデルのテスト">オリジナルデータモデルのテスト</a><ul><li><a href="#テストの実行">テストの実行</a></li><li><a href="#テスト結果">テスト結果</a></li></ul></li><li><a href="#まとめ">まとめ</a></li><li><a href="#参考サイト">参考サイト</a></li></ul></div><p></p> <p><a href="https://px.a8.net/svt/ejp?a8mat=3HBXCY+4DRW36+50+2HM5Z5" rel="nofollow"><img border="0" width="1000" height="124" alt="" src="https://www27.a8.net/svt/bgt?aid=210508450265&amp;wid=001&amp;eno=01&amp;mid=s00000000018015052000&amp;mc=1"></a><img border="0" width="1" height="1" src="https://www10.a8.net/0.gif?a8mat=3HBXCY+4DRW36+50+2HM5Z5" alt=""></p> <p><a href="https://px.a8.net/svt/ejp?a8mat=3HIN6N+3YAMCY+CO4+6BMG1" rel="nofollow"><img border="0" width="1000" height="124" alt="" src="https://www23.a8.net/svt/bgt?aid=210821855239&amp;wid=001&amp;eno=01&amp;mid=s00000001642001062000&amp;mc=1"></a><img border="0" width="1" height="1" src="https://www17.a8.net/0.gif?a8mat=3HIN6N+3YAMCY+CO4+6BMG1" alt=""></p> <p><a href="https://px.a8.net/svt/ejp?a8mat=3HIN6N+7FBNEA+4AQ0+5YJRM" rel="nofollow">全国630店舗以上！もみほぐし・足つぼ・ハンドリフレ・クイックヘッドのリラクゼーション店【りらくる】</a><img border="0" width="1" height="1" src="https://www15.a8.net/0.gif?a8mat=3HIN6N+7FBNEA+4AQ0+5YJRM" alt=""></p> <h2 id="作業ディレクトリのファイル構成"><a href="#作業ディレクトリのファイル構成" class="header-anchor">#</a> 作業ディレクトリのファイル構成</h2> <p>プロジェクトディレクトリはsegmentationとしています．度々，省略しています．</p> <div class="language- extra-class"><pre class="language-text"><code>segmentation
├── /EdgeNets
│   ├── /vision_datasets
│   │   ├── create_data.ipynb &lt;- データ生成用ノートブック
│   │   ├── /cityscapes
│   │   └── /human_city  &lt;- 仮オリジナルデータ
│   │       ├── train.txt
│   │       ├── val.txt
│   │       ├── /train
│   │       │   ├── /rgb
│   │       │   └── /label
│   │       └── /val
│   │           ├── /rgb
│   │           └── /label
│   │
│   ├── /results_segmentation &lt;- モデルの出力ディレクトリ
│   │   └── /human_city
│   ├── /result_images &lt;- 着色画像の出力ディレクトリ
│   │   └── /human_city
│   │
│   ├── /sample_images &lt;- サンプル画像
│   ├── train_segmentation.py
│   ├── test_segmentation.py
│   ├── custom_test_segmentation.py &lt;- 新規作成
│   ├── custom_train_segmentation.py &lt;- 新規作成
│   └── (省略)
└── ESPNetv2.ipynb &lt;- 実行用ノートブック
</code></pre></div><h2 id="オリジナルデータの学習"><a href="#オリジナルデータの学習" class="header-anchor">#</a> オリジナルデータの学習</h2> <h3 id="オリジナルデータの学習コードの作成"><a href="#オリジナルデータの学習コードの作成" class="header-anchor">#</a> オリジナルデータの学習コードの作成</h3> <p>デフォルトのtrain_segmentation.pyではオリジナルデータでの学習に対応していないため，オリジナルデータに対応した<code>custom_train_segmentation.py</code>を作成します．<br>
train_segmentation.pyではそれぞれのデータセットのクラス数に自動で指定されるため，コマンドの引数で指定されるように変更します．<br>
また，miou_val, val_lossをエポックの度にtxtファイルに記述するようにしています．<br></p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># custom_train_segmentation.py</span>

<span class="token comment"># ============================================</span>
__author__ <span class="token operator">=</span> <span class="token string">&quot;Sachin Mehta&quot;</span>
__license__ <span class="token operator">=</span> <span class="token string">&quot;MIT&quot;</span>
__maintainer__ <span class="token operator">=</span> <span class="token string">&quot;Sachin Mehta&quot;</span>
<span class="token comment"># ============================================</span>

<span class="token keyword">import</span> argparse
<span class="token keyword">import</span> os
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim
<span class="token keyword">from</span> utilities<span class="token punctuation">.</span>utils <span class="token keyword">import</span> save_checkpoint<span class="token punctuation">,</span> model_parameters<span class="token punctuation">,</span> compute_flops
<span class="token keyword">from</span> utilities<span class="token punctuation">.</span>train_eval_seg <span class="token keyword">import</span> train_seg <span class="token keyword">as</span> train
<span class="token keyword">from</span> utilities<span class="token punctuation">.</span>train_eval_seg <span class="token keyword">import</span> val_seg <span class="token keyword">as</span> val
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriter
<span class="token keyword">from</span> loss_fns<span class="token punctuation">.</span>segmentation_loss <span class="token keyword">import</span> SegmentationLoss
<span class="token keyword">import</span> random
<span class="token keyword">import</span> math
<span class="token keyword">import</span> time
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> utilities<span class="token punctuation">.</span>print_utils <span class="token keyword">import</span> <span class="token operator">*</span>


<span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token punctuation">)</span><span class="token punctuation">:</span>
    crop_size <span class="token operator">=</span> args<span class="token punctuation">.</span>crop_size
    <span class="token keyword">assert</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>crop_size<span class="token punctuation">,</span> <span class="token builtin">tuple</span><span class="token punctuation">)</span>
    print_info_message<span class="token punctuation">(</span><span class="token string">'Running Model at image resolution {}x{} with batch size {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>crop_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> crop_size<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> args<span class="token punctuation">.</span>batch_size<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>isdir<span class="token punctuation">(</span>args<span class="token punctuation">.</span>savedir<span class="token punctuation">)</span><span class="token punctuation">:</span>
        os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>args<span class="token punctuation">.</span>savedir<span class="token punctuation">)</span>
        
    <span class="token keyword">if</span> args<span class="token punctuation">.</span>dataset <span class="token operator">==</span> <span class="token string">'custom'</span><span class="token punctuation">:</span>
        <span class="token keyword">from</span> data_loader<span class="token punctuation">.</span>segmentation<span class="token punctuation">.</span>custom_dataset_loader <span class="token keyword">import</span> CustomSegmentationDataset
        train_dataset <span class="token operator">=</span> CustomSegmentationDataset<span class="token punctuation">(</span>root<span class="token operator">=</span>args<span class="token punctuation">.</span>data_path<span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> crop_size<span class="token operator">=</span>crop_size<span class="token punctuation">,</span> scale<span class="token operator">=</span>args<span class="token punctuation">.</span>scale<span class="token punctuation">)</span>
        val_dataset <span class="token operator">=</span> CustomSegmentationDataset<span class="token punctuation">(</span>root<span class="token operator">=</span>args<span class="token punctuation">.</span>data_path<span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> crop_size<span class="token operator">=</span>crop_size<span class="token punctuation">,</span> scale<span class="token operator">=</span>args<span class="token punctuation">.</span>scale<span class="token punctuation">)</span>
                         
        seg_classes <span class="token operator">=</span> args<span class="token punctuation">.</span>num_classes
        class_wts <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>seg_classes<span class="token punctuation">)</span>
        
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        print_error_message<span class="token punctuation">(</span><span class="token string">'Dataset: {} not yet supported'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span><span class="token punctuation">)</span>
        exit<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

    print_info_message<span class="token punctuation">(</span><span class="token string">'Training samples: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>train_dataset<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    print_info_message<span class="token punctuation">(</span><span class="token string">'Validation samples: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>val_dataset<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> args<span class="token punctuation">.</span>model <span class="token operator">==</span> <span class="token string">'espnetv2'</span><span class="token punctuation">:</span>
        <span class="token keyword">from</span> model<span class="token punctuation">.</span>segmentation<span class="token punctuation">.</span>espnetv2 <span class="token keyword">import</span> espnetv2_seg
        args<span class="token punctuation">.</span>classes <span class="token operator">=</span> seg_classes
        model <span class="token operator">=</span> espnetv2_seg<span class="token punctuation">(</span>args<span class="token punctuation">)</span>
    <span class="token keyword">elif</span> args<span class="token punctuation">.</span>model <span class="token operator">==</span> <span class="token string">'dicenet'</span><span class="token punctuation">:</span>
        <span class="token keyword">from</span> model<span class="token punctuation">.</span>segmentation<span class="token punctuation">.</span>dicenet <span class="token keyword">import</span> dicenet_seg
        model <span class="token operator">=</span> dicenet_seg<span class="token punctuation">(</span>args<span class="token punctuation">,</span> classes<span class="token operator">=</span>seg_classes<span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        print_error_message<span class="token punctuation">(</span><span class="token string">'Arch: {} not yet supported'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>model<span class="token punctuation">)</span><span class="token punctuation">)</span>
        exit<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> args<span class="token punctuation">.</span>finetune<span class="token punctuation">:</span>
        <span class="token keyword">if</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>isfile<span class="token punctuation">(</span>args<span class="token punctuation">.</span>finetune<span class="token punctuation">)</span><span class="token punctuation">:</span>
            print_info_message<span class="token punctuation">(</span><span class="token string">'Loading weights for finetuning from {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>finetune<span class="token punctuation">)</span><span class="token punctuation">)</span>
            weight_dict <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>args<span class="token punctuation">.</span>finetune<span class="token punctuation">,</span> map_location<span class="token operator">=</span>torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span>device<span class="token operator">=</span><span class="token string">'cpu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>weight_dict<span class="token punctuation">)</span>
            print_info_message<span class="token punctuation">(</span><span class="token string">'Done'</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            print_warning_message<span class="token punctuation">(</span><span class="token string">'No file for finetuning. Please check.'</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> args<span class="token punctuation">.</span>freeze_bn<span class="token punctuation">:</span>
        print_info_message<span class="token punctuation">(</span><span class="token string">'Freezing batch normalization layers'</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> m <span class="token keyword">in</span> model<span class="token punctuation">.</span>modules<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">)</span><span class="token punctuation">:</span>
                m<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
                m<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">False</span>
                m<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">False</span>

    num_gpus <span class="token operator">=</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>device_count<span class="token punctuation">(</span><span class="token punctuation">)</span>
    device <span class="token operator">=</span> <span class="token string">'cuda'</span> <span class="token keyword">if</span> num_gpus <span class="token operator">&gt;</span> <span class="token number">0</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span>

    train_params <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">'params'</span><span class="token punctuation">:</span> model<span class="token punctuation">.</span>get_basenet_params<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'lr'</span><span class="token punctuation">:</span> args<span class="token punctuation">.</span>lr<span class="token punctuation">}</span><span class="token punctuation">,</span>
                    <span class="token punctuation">{</span><span class="token string">'params'</span><span class="token punctuation">:</span> model<span class="token punctuation">.</span>get_segment_params<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'lr'</span><span class="token punctuation">:</span> args<span class="token punctuation">.</span>lr <span class="token operator">*</span> args<span class="token punctuation">.</span>lr_mult<span class="token punctuation">}</span><span class="token punctuation">]</span>

    optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>train_params<span class="token punctuation">,</span> momentum<span class="token operator">=</span>args<span class="token punctuation">.</span>momentum<span class="token punctuation">,</span> weight_decay<span class="token operator">=</span>args<span class="token punctuation">.</span>weight_decay<span class="token punctuation">)</span>

    num_params <span class="token operator">=</span> model_parameters<span class="token punctuation">(</span>model<span class="token punctuation">)</span>
    flops <span class="token operator">=</span> compute_flops<span class="token punctuation">(</span>model<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token operator">=</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> crop_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> crop_size<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    print_info_message<span class="token punctuation">(</span><span class="token string">'FLOPs for an input of size {}x{}: {:.2f} million'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>crop_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> crop_size<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> flops<span class="token punctuation">)</span><span class="token punctuation">)</span>
    print_info_message<span class="token punctuation">(</span><span class="token string">'Network Parameters: {:.2f} million'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>num_params<span class="token punctuation">)</span><span class="token punctuation">)</span>

    writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span>log_dir<span class="token operator">=</span>args<span class="token punctuation">.</span>savedir<span class="token punctuation">,</span> comment<span class="token operator">=</span><span class="token string">'Training and Validation logs'</span><span class="token punctuation">)</span>
    <span class="token keyword">try</span><span class="token punctuation">:</span>
        writer<span class="token punctuation">.</span>add_graph<span class="token punctuation">(</span>model<span class="token punctuation">,</span> input_to_model<span class="token operator">=</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> crop_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> crop_size<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">except</span><span class="token punctuation">:</span>
        print_log_message<span class="token punctuation">(</span><span class="token string">&quot;Not able to generate the graph. Likely because your model is not supported by ONNX&quot;</span><span class="token punctuation">)</span>

    start_epoch <span class="token operator">=</span> <span class="token number">0</span>
    best_miou <span class="token operator">=</span> <span class="token number">0.0</span>
    <span class="token keyword">if</span> args<span class="token punctuation">.</span>resume<span class="token punctuation">:</span>
        <span class="token keyword">if</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>isfile<span class="token punctuation">(</span>args<span class="token punctuation">.</span>resume<span class="token punctuation">)</span><span class="token punctuation">:</span>
            print_info_message<span class="token punctuation">(</span><span class="token string">&quot;=&gt; loading checkpoint '{}'&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>resume<span class="token punctuation">)</span><span class="token punctuation">)</span>
            checkpoint <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>args<span class="token punctuation">.</span>resume<span class="token punctuation">,</span> map_location<span class="token operator">=</span>torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cpu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            start_epoch <span class="token operator">=</span> checkpoint<span class="token punctuation">[</span><span class="token string">'epoch'</span><span class="token punctuation">]</span>
            best_miou <span class="token operator">=</span> checkpoint<span class="token punctuation">[</span><span class="token string">'best_miou'</span><span class="token punctuation">]</span>
            model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>checkpoint<span class="token punctuation">[</span><span class="token string">'state_dict'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            optimizer<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>checkpoint<span class="token punctuation">[</span><span class="token string">'optimizer'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            print_info_message<span class="token punctuation">(</span><span class="token string">&quot;=&gt; loaded checkpoint '{}' (epoch {})&quot;</span>
                               <span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>resume<span class="token punctuation">,</span> checkpoint<span class="token punctuation">[</span><span class="token string">'epoch'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            print_warning_message<span class="token punctuation">(</span><span class="token string">&quot;=&gt; no checkpoint found at '{}'&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>resume<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">#criterion = nn.CrossEntropyLoss(weight=class_wts, reduction='none', ignore_index=args.ignore_idx)</span>
    criterion <span class="token operator">=</span> SegmentationLoss<span class="token punctuation">(</span>n_classes<span class="token operator">=</span>seg_classes<span class="token punctuation">,</span> loss_type<span class="token operator">=</span>args<span class="token punctuation">.</span>loss_type<span class="token punctuation">,</span>
                         device<span class="token operator">=</span>device<span class="token punctuation">,</span> ignore_idx<span class="token operator">=</span>args<span class="token punctuation">.</span>ignore_idx<span class="token punctuation">,</span>
                         class_wts<span class="token operator">=</span>class_wts<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> num_gpus <span class="token operator">&gt;=</span> <span class="token number">1</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> num_gpus <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
            <span class="token comment"># for a single GPU, we do not need DataParallel wrapper for Criteria.</span>
            <span class="token comment"># So, falling back to its internal wrapper</span>
            <span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>parallel <span class="token keyword">import</span> DataParallel
            model <span class="token operator">=</span> DataParallel<span class="token punctuation">(</span>model<span class="token punctuation">)</span>
            model <span class="token operator">=</span> model<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
            criterion <span class="token operator">=</span> criterion<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token keyword">from</span> utilities<span class="token punctuation">.</span>parallel_wrapper <span class="token keyword">import</span> DataParallelModel<span class="token punctuation">,</span> DataParallelCriteria
            model <span class="token operator">=</span> DataParallelModel<span class="token punctuation">(</span>model<span class="token punctuation">)</span>
            model <span class="token operator">=</span> model<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
            criterion <span class="token operator">=</span> DataParallelCriteria<span class="token punctuation">(</span>criterion<span class="token punctuation">)</span>
            criterion <span class="token operator">=</span> criterion<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token keyword">if</span> torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">import</span> torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn <span class="token keyword">as</span> cudnn
            cudnn<span class="token punctuation">.</span>benchmark <span class="token operator">=</span> <span class="token boolean">True</span>
            cudnn<span class="token punctuation">.</span>deterministic <span class="token operator">=</span> <span class="token boolean">True</span>

    train_loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>train_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>args<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                           pin_memory<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span>args<span class="token punctuation">.</span>workers<span class="token punctuation">)</span>
    val_loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>val_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>args<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
                         pin_memory<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span>args<span class="token punctuation">.</span>workers<span class="token punctuation">)</span>

    <span class="token keyword">if</span> args<span class="token punctuation">.</span>scheduler <span class="token operator">==</span> <span class="token string">'fixed'</span><span class="token punctuation">:</span>
        step_size <span class="token operator">=</span> args<span class="token punctuation">.</span>step_size
        step_sizes <span class="token operator">=</span> <span class="token punctuation">[</span>step_size <span class="token operator">*</span> i <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>math<span class="token punctuation">.</span>ceil<span class="token punctuation">(</span>args<span class="token punctuation">.</span>epochs <span class="token operator">/</span> step_size<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
        <span class="token keyword">from</span> utilities<span class="token punctuation">.</span>lr_scheduler <span class="token keyword">import</span> FixedMultiStepLR
        lr_scheduler <span class="token operator">=</span> FixedMultiStepLR<span class="token punctuation">(</span>base_lr<span class="token operator">=</span>args<span class="token punctuation">.</span>lr<span class="token punctuation">,</span> steps<span class="token operator">=</span>step_sizes<span class="token punctuation">,</span> gamma<span class="token operator">=</span>args<span class="token punctuation">.</span>lr_decay<span class="token punctuation">)</span>
    <span class="token keyword">elif</span> args<span class="token punctuation">.</span>scheduler <span class="token operator">==</span> <span class="token string">'clr'</span><span class="token punctuation">:</span>
        step_size <span class="token operator">=</span> args<span class="token punctuation">.</span>step_size
        step_sizes <span class="token operator">=</span> <span class="token punctuation">[</span>step_size <span class="token operator">*</span> i <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>math<span class="token punctuation">.</span>ceil<span class="token punctuation">(</span>args<span class="token punctuation">.</span>epochs <span class="token operator">/</span> step_size<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
        <span class="token keyword">from</span> utilities<span class="token punctuation">.</span>lr_scheduler <span class="token keyword">import</span> CyclicLR
        lr_scheduler <span class="token operator">=</span> CyclicLR<span class="token punctuation">(</span>min_lr<span class="token operator">=</span>args<span class="token punctuation">.</span>lr<span class="token punctuation">,</span> cycle_len<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> steps<span class="token operator">=</span>step_sizes<span class="token punctuation">,</span> gamma<span class="token operator">=</span>args<span class="token punctuation">.</span>lr_decay<span class="token punctuation">)</span>
    <span class="token keyword">elif</span> args<span class="token punctuation">.</span>scheduler <span class="token operator">==</span> <span class="token string">'poly'</span><span class="token punctuation">:</span>
        <span class="token keyword">from</span> utilities<span class="token punctuation">.</span>lr_scheduler <span class="token keyword">import</span> PolyLR
        lr_scheduler <span class="token operator">=</span> PolyLR<span class="token punctuation">(</span>base_lr<span class="token operator">=</span>args<span class="token punctuation">.</span>lr<span class="token punctuation">,</span> max_epochs<span class="token operator">=</span>args<span class="token punctuation">.</span>epochs<span class="token punctuation">,</span> power<span class="token operator">=</span>args<span class="token punctuation">.</span>power<span class="token punctuation">)</span>
    <span class="token keyword">elif</span> args<span class="token punctuation">.</span>scheduler <span class="token operator">==</span> <span class="token string">'hybrid'</span><span class="token punctuation">:</span>
        <span class="token keyword">from</span> utilities<span class="token punctuation">.</span>lr_scheduler <span class="token keyword">import</span> HybirdLR
        lr_scheduler <span class="token operator">=</span> HybirdLR<span class="token punctuation">(</span>base_lr<span class="token operator">=</span>args<span class="token punctuation">.</span>lr<span class="token punctuation">,</span> max_epochs<span class="token operator">=</span>args<span class="token punctuation">.</span>epochs<span class="token punctuation">,</span> clr_max<span class="token operator">=</span>args<span class="token punctuation">.</span>clr_max<span class="token punctuation">,</span>
                        cycle_len<span class="token operator">=</span>args<span class="token punctuation">.</span>cycle_len<span class="token punctuation">)</span>
    <span class="token keyword">elif</span> args<span class="token punctuation">.</span>scheduler <span class="token operator">==</span> <span class="token string">'linear'</span><span class="token punctuation">:</span>
        <span class="token keyword">from</span> utilities<span class="token punctuation">.</span>lr_scheduler <span class="token keyword">import</span> LinearLR
        lr_scheduler <span class="token operator">=</span> LinearLR<span class="token punctuation">(</span>base_lr<span class="token operator">=</span>args<span class="token punctuation">.</span>lr<span class="token punctuation">,</span> max_epochs<span class="token operator">=</span>args<span class="token punctuation">.</span>epochs<span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        print_error_message<span class="token punctuation">(</span><span class="token string">'{} scheduler Not supported'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>scheduler<span class="token punctuation">)</span><span class="token punctuation">)</span>
        exit<span class="token punctuation">(</span><span class="token punctuation">)</span>

    print_info_message<span class="token punctuation">(</span>lr_scheduler<span class="token punctuation">)</span>

    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>savedir <span class="token operator">+</span> os<span class="token punctuation">.</span>sep <span class="token operator">+</span> <span class="token string">'arguments.json'</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> outfile<span class="token punctuation">:</span>
        <span class="token keyword">import</span> json
        arg_dict <span class="token operator">=</span> <span class="token builtin">vars</span><span class="token punctuation">(</span>args<span class="token punctuation">)</span>
        arg_dict<span class="token punctuation">[</span><span class="token string">'model_params'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'{} '</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>num_params<span class="token punctuation">)</span>
        arg_dict<span class="token punctuation">[</span><span class="token string">'flops'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'{} '</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>flops<span class="token punctuation">)</span>
        json<span class="token punctuation">.</span>dump<span class="token punctuation">(</span>arg_dict<span class="token punctuation">,</span> outfile<span class="token punctuation">)</span>

    extra_info_ckpt <span class="token operator">=</span> <span class="token string">'{}_{}_{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>model<span class="token punctuation">,</span> args<span class="token punctuation">.</span>s<span class="token punctuation">,</span> crop_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    
    <span class="token comment"># val log txtfile</span>
    txt_outpath <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>args<span class="token punctuation">.</span>savedir<span class="token punctuation">,</span> <span class="token string">'val_logs.txt'</span><span class="token punctuation">)</span>
    txt_outfile <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span>txt_outpath<span class="token punctuation">,</span> <span class="token string">&quot;w&quot;</span><span class="token punctuation">)</span>
    txt_outfile<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'epoch, miou_val, val_loss\n'</span><span class="token punctuation">)</span>
    
    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>start_epoch<span class="token punctuation">,</span> args<span class="token punctuation">.</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        lr_base <span class="token operator">=</span> lr_scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span>epoch<span class="token punctuation">)</span>
        <span class="token comment"># set the optimizer with the learning rate</span>
        <span class="token comment"># This can be done inside the MyLRScheduler</span>
        lr_seg <span class="token operator">=</span> lr_base <span class="token operator">*</span> args<span class="token punctuation">.</span>lr_mult
        optimizer<span class="token punctuation">.</span>param_groups<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'lr'</span><span class="token punctuation">]</span> <span class="token operator">=</span> lr_base
        optimizer<span class="token punctuation">.</span>param_groups<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'lr'</span><span class="token punctuation">]</span> <span class="token operator">=</span> lr_seg

        print_info_message<span class="token punctuation">(</span>
            <span class="token string">'Running epoch {} with learning rates: base_net {:.6f}, segment_net {:.6f}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> lr_base<span class="token punctuation">,</span> lr_seg<span class="token punctuation">)</span><span class="token punctuation">)</span>
        miou_train<span class="token punctuation">,</span> train_loss <span class="token operator">=</span> train<span class="token punctuation">(</span>model<span class="token punctuation">,</span> train_loader<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> criterion<span class="token punctuation">,</span> seg_classes<span class="token punctuation">,</span> epoch<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span>
        miou_val<span class="token punctuation">,</span> val_loss <span class="token operator">=</span> val<span class="token punctuation">(</span>model<span class="token punctuation">,</span> val_loader<span class="token punctuation">,</span> criterion<span class="token punctuation">,</span> seg_classes<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span>
        
        <span class="token comment"># write txtfile</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'epoch, miou_val, val_loss'</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'{},{:.2f}, {:.6f}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> miou_val<span class="token punctuation">,</span> val_loss<span class="token punctuation">)</span><span class="token punctuation">)</span>
        txt_outfile<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'{},{:.2f}, {:.6f}\n'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> miou_val<span class="token punctuation">,</span> val_loss<span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># remember best miou and save checkpoint</span>
        is_best <span class="token operator">=</span> miou_val <span class="token operator">&gt;</span> best_miou
        best_miou <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span>miou_val<span class="token punctuation">,</span> best_miou<span class="token punctuation">)</span>

        weights_dict <span class="token operator">=</span> model<span class="token punctuation">.</span>module<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> device <span class="token operator">==</span> <span class="token string">'cuda'</span> <span class="token keyword">else</span> model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span>
        save_checkpoint<span class="token punctuation">(</span><span class="token punctuation">{</span>
            <span class="token string">'epoch'</span><span class="token punctuation">:</span> epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span>
            <span class="token string">'arch'</span><span class="token punctuation">:</span> args<span class="token punctuation">.</span>model<span class="token punctuation">,</span>
            <span class="token string">'state_dict'</span><span class="token punctuation">:</span> weights_dict<span class="token punctuation">,</span>
            <span class="token string">'best_miou'</span><span class="token punctuation">:</span> best_miou<span class="token punctuation">,</span>
            <span class="token string">'optimizer'</span><span class="token punctuation">:</span> optimizer<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">}</span><span class="token punctuation">,</span> is_best<span class="token punctuation">,</span> args<span class="token punctuation">.</span>savedir<span class="token punctuation">,</span> extra_info_ckpt<span class="token punctuation">)</span>

        writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">'Segmentation/LR/base'</span><span class="token punctuation">,</span> <span class="token builtin">round</span><span class="token punctuation">(</span>lr_base<span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">,</span> epoch<span class="token punctuation">)</span>
        writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">'Segmentation/LR/seg'</span><span class="token punctuation">,</span> <span class="token builtin">round</span><span class="token punctuation">(</span>lr_seg<span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">,</span> epoch<span class="token punctuation">)</span>
        writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">'Segmentation/Loss/train'</span><span class="token punctuation">,</span> train_loss<span class="token punctuation">,</span> epoch<span class="token punctuation">)</span>
        writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">'Segmentation/Loss/val'</span><span class="token punctuation">,</span> val_loss<span class="token punctuation">,</span> epoch<span class="token punctuation">)</span>
        writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">'Segmentation/mIOU/train'</span><span class="token punctuation">,</span> miou_train<span class="token punctuation">,</span> epoch<span class="token punctuation">)</span>
        writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">'Segmentation/mIOU/val'</span><span class="token punctuation">,</span> miou_val<span class="token punctuation">,</span> epoch<span class="token punctuation">)</span>
        writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">'Segmentation/Complexity/Flops'</span><span class="token punctuation">,</span> best_miou<span class="token punctuation">,</span> math<span class="token punctuation">.</span>ceil<span class="token punctuation">(</span>flops<span class="token punctuation">)</span><span class="token punctuation">)</span>
        writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">'Segmentation/Complexity/Params'</span><span class="token punctuation">,</span> best_miou<span class="token punctuation">,</span> math<span class="token punctuation">.</span>ceil<span class="token punctuation">(</span>num_params<span class="token punctuation">)</span><span class="token punctuation">)</span>

    writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
    txt_outfile<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">&quot;__main__&quot;</span><span class="token punctuation">:</span>
    <span class="token keyword">from</span> commons<span class="token punctuation">.</span>general_details <span class="token keyword">import</span> segmentation_models<span class="token punctuation">,</span> segmentation_schedulers<span class="token punctuation">,</span> segmentation_loss_fns<span class="token punctuation">,</span> \
        segmentation_datasets

    parser <span class="token operator">=</span> argparse<span class="token punctuation">.</span>ArgumentParser<span class="token punctuation">(</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--resume'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">str</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'path to checkpoint to resume from'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--workers'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'number of data loading workers'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--ignore-idx'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">255</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Index or label to be ignored during training'</span><span class="token punctuation">)</span>

    <span class="token comment"># model details</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--freeze-bn'</span><span class="token punctuation">,</span> action<span class="token operator">=</span><span class="token string">'store_true'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Freeze BN params or not'</span><span class="token punctuation">)</span>

    <span class="token comment"># dataset and result directories</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--dataset'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">str</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">'pascal'</span><span class="token punctuation">,</span> choices<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'custom'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Datasets'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--data-path'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">str</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'dataset path'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--coco-path'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">str</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'MS COCO dataset path'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--savedir'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">str</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">'./results_segmentation'</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Location to save the results'</span><span class="token punctuation">)</span>
    <span class="token comment">## only for cityscapes</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--coarse'</span><span class="token punctuation">,</span> action<span class="token operator">=</span><span class="token string">'store_true'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Want to use coarse annotations or not'</span><span class="token punctuation">)</span>

    <span class="token comment"># scheduler details</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--scheduler'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">'hybrid'</span><span class="token punctuation">,</span> choices<span class="token operator">=</span>segmentation_schedulers<span class="token punctuation">,</span>
                        <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Learning rate scheduler (fixed, clr, poly)'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--epochs'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'num of training epochs'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--step-size'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">51</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'steps at which lr should be decreased'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--lr'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">9e</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">float</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'initial learning rate'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--lr-mult'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">10.0</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">float</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'initial learning rate'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--lr-decay'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">float</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'factor by which lr should be decreased'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--momentum'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">float</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'momentum'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--weight-decay'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">4e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">float</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'weight decay (default: 4e-5)'</span><span class="token punctuation">)</span>
    <span class="token comment"># for Polynomial LR</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--power'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">float</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'power factor for Polynomial LR'</span><span class="token punctuation">)</span>

    <span class="token comment"># for hybrid LR</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--clr-max'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">61</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Max number of epochs for cylic LR before '</span>
                                  <span class="token string">'changing last cycle to linear'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--cycle-len'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Duration of cycle'</span><span class="token punctuation">)</span>

    <span class="token comment"># input details</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--batch-size'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">40</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'list of batch sizes'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--crop-size'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> nargs<span class="token operator">=</span><span class="token string">'+'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                        <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'list of image crop sizes, with each item storing the crop size (should be a tuple).'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--loss-type'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">'ce'</span><span class="token punctuation">,</span> choices<span class="token operator">=</span>segmentation_loss_fns<span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Loss function (ce or miou)'</span><span class="token punctuation">)</span>

    <span class="token comment"># model related params</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--s'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">float</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">2.0</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Factor by which channels will be scaled'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--model'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">'espnet'</span><span class="token punctuation">,</span> choices<span class="token operator">=</span>segmentation_models<span class="token punctuation">,</span>
                        <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Which model? basic= basic CNN model, res=resnet style)'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--channels'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Input channels'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--num-classes'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span>
                        <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'ImageNet classes. Required for loading the base network'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--finetune'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">str</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Finetune the segmentation model'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--model-width'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Model width'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--model-height'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Model height'</span><span class="token punctuation">)</span>

    args <span class="token operator">=</span> parser<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span>

    random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">1882</span><span class="token punctuation">)</span>
    torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">1882</span><span class="token punctuation">)</span>
        
    <span class="token keyword">if</span> args<span class="token punctuation">.</span>dataset <span class="token operator">==</span> <span class="token string">'custom'</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> args<span class="token punctuation">.</span>crop_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">512</span><span class="token punctuation">:</span>
            args<span class="token punctuation">.</span>scale <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">0.25</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span>
        <span class="token keyword">elif</span> args<span class="token punctuation">.</span>crop_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">1024</span><span class="token punctuation">:</span>
            args<span class="token punctuation">.</span>scale <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">0.35</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">)</span>
        <span class="token keyword">elif</span> args<span class="token punctuation">.</span>crop_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">2048</span><span class="token punctuation">:</span>
            args<span class="token punctuation">.</span>scale <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">2.0</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            print_error_message<span class="token punctuation">(</span><span class="token string">'Select image size from 512x256, 1024x512, 2048x1024'</span><span class="token punctuation">)</span>
        print_log_message<span class="token punctuation">(</span><span class="token string">'Using scale = ({}, {})'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>scale<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> args<span class="token punctuation">.</span>scale<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        print_error_message<span class="token punctuation">(</span><span class="token string">'{} dataset not yet supported'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> <span class="token keyword">not</span> args<span class="token punctuation">.</span>finetune<span class="token punctuation">:</span>
        <span class="token keyword">from</span> model<span class="token punctuation">.</span>weight_locations<span class="token punctuation">.</span>classification <span class="token keyword">import</span> model_weight_map

        weight_file_key <span class="token operator">=</span> <span class="token string">'{}_{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>model<span class="token punctuation">,</span> args<span class="token punctuation">.</span>s<span class="token punctuation">)</span>
        <span class="token keyword">assert</span> weight_file_key <span class="token keyword">in</span> model_weight_map<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'{} does not exist'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>weight_file_key<span class="token punctuation">)</span>
        args<span class="token punctuation">.</span>weights <span class="token operator">=</span> model_weight_map<span class="token punctuation">[</span>weight_file_key<span class="token punctuation">]</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        args<span class="token punctuation">.</span>weights <span class="token operator">=</span> <span class="token string">''</span>
        <span class="token keyword">assert</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>isfile<span class="token punctuation">(</span>args<span class="token punctuation">.</span>finetune<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'{} weight file does not exist'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>finetune<span class="token punctuation">)</span>

    <span class="token keyword">assert</span> <span class="token builtin">len</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>crop_size<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token string">'crop-size argument must contain 2 values'</span>
    <span class="token keyword">assert</span> args<span class="token punctuation">.</span>data_path <span class="token operator">!=</span> <span class="token string">''</span><span class="token punctuation">,</span> <span class="token string">'Dataset path is an empty string. Please check.'</span>

    args<span class="token punctuation">.</span>crop_size <span class="token operator">=</span> <span class="token builtin">tuple</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>crop_size<span class="token punctuation">)</span>
    timestr <span class="token operator">=</span> time<span class="token punctuation">.</span>strftime<span class="token punctuation">(</span><span class="token string">&quot;%Y%m%d-%H%M%S&quot;</span><span class="token punctuation">)</span>
    args<span class="token punctuation">.</span>savedir <span class="token operator">=</span> <span class="token string">'{}/model_{}_{}/s_{}_sch_{}_loss_{}_res_{}_sc_{}_{}/{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>savedir<span class="token punctuation">,</span> args<span class="token punctuation">.</span>model<span class="token punctuation">,</span> args<span class="token punctuation">.</span>dataset<span class="token punctuation">,</span> args<span class="token punctuation">.</span>s<span class="token punctuation">,</span>
                               args<span class="token punctuation">.</span>scheduler<span class="token punctuation">,</span>
                               args<span class="token punctuation">.</span>loss_type<span class="token punctuation">,</span> args<span class="token punctuation">.</span>crop_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> args<span class="token punctuation">.</span>scale<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> args<span class="token punctuation">.</span>scale<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> timestr<span class="token punctuation">)</span>
    main<span class="token punctuation">(</span>args<span class="token punctuation">)</span>
</code></pre></div><h3 id="オリジナルデータの学習-第1段階"><a href="#オリジナルデータの学習-第1段階" class="header-anchor">#</a> オリジナルデータの学習(第1段階)</h3> <p>最初の段階では、低解像度の画像を入力として使用して、より大きなバッチサイズに合わせることができます。<br>
モデルは，<code>./results_segmentation/human_city</code>に出力されます．<br> <code>--num-classes</code>でクラス数を指定することを忘れずに．</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token operator">%</span>cd <span class="token operator">/</span>content<span class="token operator">/</span>drive<span class="token operator">/</span>My\ Drive<span class="token operator">/</span>segmentation<span class="token operator">/</span>EdgeNets

<span class="token comment"># original dataset</span>
!CUDA_VISIBLE_DEVICES<span class="token operator">=</span><span class="token number">0</span> python custom_train_segmentation<span class="token punctuation">.</span>py \
                        <span class="token operator">-</span><span class="token operator">-</span>model espnetv2 <span class="token operator">-</span><span class="token operator">-</span>s <span class="token number">2.0</span> \
                        <span class="token operator">-</span><span class="token operator">-</span>dataset custom \
                        <span class="token operator">-</span><span class="token operator">-</span>savedir <span class="token punctuation">.</span><span class="token operator">/</span>results_segmentation<span class="token operator">/</span>human_city \
                        <span class="token operator">-</span><span class="token operator">-</span>data<span class="token operator">-</span>path <span class="token punctuation">.</span><span class="token operator">/</span>vision_datasets<span class="token operator">/</span>human_city<span class="token operator">/</span> \
                        <span class="token operator">-</span><span class="token operator">-</span>batch<span class="token operator">-</span>size <span class="token number">25</span> \
                        <span class="token operator">-</span><span class="token operator">-</span>crop<span class="token operator">-</span>size <span class="token number">512</span> <span class="token number">256</span> \
                        <span class="token operator">-</span><span class="token operator">-</span>num<span class="token operator">-</span>classes <span class="token number">2</span> \
                        <span class="token operator">-</span><span class="token operator">-</span>lr <span class="token number">0.009</span> <span class="token operator">-</span><span class="token operator">-</span>scheduler hybrid <span class="token operator">-</span><span class="token operator">-</span>clr<span class="token operator">-</span><span class="token builtin">max</span> <span class="token number">61</span> <span class="token operator">-</span><span class="token operator">-</span>epochs <span class="token number">50</span>
</code></pre></div><h3 id="オリジナルデータの学習-第2段階"><a href="#オリジナルデータの学習-第2段階" class="header-anchor">#</a> オリジナルデータの学習(第2段階)</h3> <p>第2段階では、バッチ正規化レイヤーをフリーズしてから、わずかに高い画像解像度で微調整します。<br>
--finetuneでは，第1段階で出力した学習モデルを指定します．<br>
ここでも，<code>--num-classes</code>でクラス数を指定することを忘れずに．</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># original dataset</span>
!CUDA_VISIBLE_DEVICES<span class="token operator">=</span><span class="token number">0</span> python custom_train_segmentation<span class="token punctuation">.</span>py \
                        <span class="token operator">-</span><span class="token operator">-</span>model espnetv2 <span class="token operator">-</span><span class="token operator">-</span>s <span class="token number">2.0</span> \
                        <span class="token operator">-</span><span class="token operator">-</span>dataset custom \
                        <span class="token operator">-</span><span class="token operator">-</span>savedir <span class="token punctuation">.</span><span class="token operator">/</span>results_segmentation<span class="token operator">/</span>human_city0318 \
                        <span class="token operator">-</span><span class="token operator">-</span>data<span class="token operator">-</span>path <span class="token punctuation">.</span><span class="token operator">/</span>vision_datasets<span class="token operator">/</span>human_city<span class="token operator">/</span> \
                        <span class="token operator">-</span><span class="token operator">-</span>batch<span class="token operator">-</span>size <span class="token number">6</span> \
                        <span class="token operator">-</span><span class="token operator">-</span>crop<span class="token operator">-</span>size <span class="token number">1024</span> <span class="token number">512</span> \
                        <span class="token operator">-</span><span class="token operator">-</span>lr <span class="token number">0.005</span> <span class="token operator">-</span><span class="token operator">-</span>scheduler hybrid <span class="token operator">-</span><span class="token operator">-</span>clr<span class="token operator">-</span><span class="token builtin">max</span> <span class="token number">61</span>\
                        <span class="token operator">-</span><span class="token operator">-</span>epochs <span class="token number">25</span> \
                        <span class="token operator">-</span><span class="token operator">-</span>freeze<span class="token operator">-</span>bn \
                        <span class="token operator">-</span><span class="token operator">-</span>num<span class="token operator">-</span>classes <span class="token number">2</span> \
                        <span class="token operator">-</span><span class="token operator">-</span>finetune <span class="token punctuation">.</span><span class="token operator">/</span>results_segmentation<span class="token operator">/</span>human_city<span class="token operator">/</span>model_espnetv2_custom<span class="token operator">/</span>s_2<span class="token punctuation">.</span>0_sch_hybrid_loss_ce_res_512_sc_0<span class="token punctuation">.</span>25_0<span class="token punctuation">.</span><span class="token number">5</span><span class="token operator">/</span>＊＊＊＊<span class="token operator">/</span>espnetv2_2<span class="token punctuation">.</span>0_512_best<span class="token punctuation">.</span>pth

</code></pre></div><h2 id="オリジナルデータモデルのテスト"><a href="#オリジナルデータモデルのテスト" class="header-anchor">#</a> オリジナルデータモデルのテスト</h2> <h3 id="テストの実行"><a href="#テストの実行" class="header-anchor">#</a> テストの実行</h3> <p>オリジナルデータで学習したモデルで/sample_dataの画像でsegmentationを実施しました．<br>
以下のコマンドで実行できます．</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token operator">%</span>cd <span class="token operator">/</span>content<span class="token operator">/</span>drive<span class="token operator">/</span>My\ Drive<span class="token operator">/</span>segmentation<span class="token operator">/</span>EdgeNets
!CUDA_VISIBLE_DEVICES<span class="token operator">=</span><span class="token number">0</span> python custom_test_segmentation<span class="token punctuation">.</span>py \
                        <span class="token operator">-</span><span class="token operator">-</span>model espnetv2 \
                        <span class="token operator">-</span><span class="token operator">-</span>s <span class="token number">2.0</span> \
                        <span class="token operator">-</span><span class="token operator">-</span>dataset custom \
                        <span class="token operator">-</span><span class="token operator">-</span>data<span class="token operator">-</span>path <span class="token punctuation">.</span><span class="token operator">/</span>sample_images<span class="token operator">/</span> \
                        <span class="token operator">-</span><span class="token operator">-</span>split custom \
                        <span class="token operator">-</span><span class="token operator">-</span>im<span class="token operator">-</span>size <span class="token number">1024</span> <span class="token number">512</span>\
                        <span class="token operator">-</span><span class="token operator">-</span>num<span class="token operator">-</span>classes <span class="token number">2</span> \
                        <span class="token operator">-</span><span class="token operator">-</span>weights<span class="token operator">-</span>test <span class="token punctuation">.</span><span class="token operator">/</span>results_segmentation<span class="token operator">/</span>human_city0318<span class="token operator">/</span>model_espnetv2_custom<span class="token operator">/</span>s_2<span class="token punctuation">.</span>0_sch_hybrid_loss_ce_res_1024_sc_0<span class="token punctuation">.</span>35_1<span class="token punctuation">.</span><span class="token number">0</span><span class="token operator">/</span>＊＊＊＊<span class="token operator">/</span>espnetv2_2<span class="token punctuation">.</span>0_1024_best<span class="token punctuation">.</span>pth \
                        <span class="token operator">-</span><span class="token operator">-</span>savedir<span class="token operator">-</span>name sample_images_org
</code></pre></div><h3 id="テスト結果"><a href="#テスト結果" class="header-anchor">#</a> テスト結果</h3> <p>Cityscapesデータセットの人は立っている状態ばかりなので，立っている人は着色されていますが，座っている人は着色されませんでした．<br>
学習データに入っていないので当然ですが，このようにはっきり形となって出ると，面白いです．<br> <br>
立っている人の画像<br> <img alt="" data-src="/image/org_seg1.png" loading="lazy" class="lazy"><br> <br>
座っている人の画像<br> <img alt="" data-src="/image/org_seg2.png" loading="lazy" class="lazy"></p> <h2 id="まとめ"><a href="#まとめ" class="header-anchor">#</a> まとめ</h2> <p>本稿ではCityscapesデータセットから人のみを抽出した仮のオリジナルデータで学習を実施しました．<br>
次回から，セグメンテーションしてクロマキー合成を実施したいです．</p> <h2 id="参考サイト"><a href="#参考サイト" class="header-anchor">#</a> 参考サイト</h2> <p><a href="https://github.com/sacmehta/EdgeNets" target="_blank" rel="noopener noreferrer">sacmehta/EdgeNets<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a><br> <a href="https://github.com/sacmehta/EdgeNets/blob/master/README_Segmentation.md" target="_blank" rel="noopener noreferrer">sacmehta/EdgeNets/README_Segmentation.md<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> <a href="https://qiita.com/tokyokuma/items/37b1370ea7c84399fbb9" target="_blank" rel="noopener noreferrer">ESPNetで自作データセットを学習してセグメンテーション<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a><br> <a href="https://rikoubou.hatenablog.com/entry/2019/02/21/190310" target="_blank" rel="noopener noreferrer">【python/OpenCV】画像の特定の色を抽出する方法<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a><br> <a href="https://qiita.com/pashango2/items/d6dda5f07109ee5b6163" target="_blank" rel="noopener noreferrer">PIL/Pillowで画像の色を高速に置換する<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a><br> <a href="http://ni4muraano.hatenablog.com/entry/2017/05/15/000000" target="_blank" rel="noopener noreferrer">【OpenCV】 forループを使わずに指定した色を別の色に変更する<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p><a href="https://px.a8.net/svt/ejp?a8mat=3HBXCY+4DRW36+50+2HM5Z5" rel="nofollow"><img border="0" width="1000" height="124" alt="" src="https://www27.a8.net/svt/bgt?aid=210508450265&amp;wid=001&amp;eno=01&amp;mid=s00000000018015052000&amp;mc=1"></a><img border="0" width="1" height="1" src="https://www10.a8.net/0.gif?a8mat=3HBXCY+4DRW36+50+2HM5Z5" alt=""></p> <p><a href="https://px.a8.net/svt/ejp?a8mat=3HIN6N+3YAMCY+CO4+6BMG1" rel="nofollow"><img border="0" width="1000" height="124" alt="" src="https://www23.a8.net/svt/bgt?aid=210821855239&amp;wid=001&amp;eno=01&amp;mid=s00000001642001062000&amp;mc=1"></a><img border="0" width="1" height="1" src="https://www17.a8.net/0.gif?a8mat=3HIN6N+3YAMCY+CO4+6BMG1" alt=""></p> <p><a href="https://px.a8.net/svt/ejp?a8mat=3HIN6N+7FBNEA+4AQ0+5YJRM" rel="nofollow">全国630店舗以上！もみほぐし・足つぼ・ハンドリフレ・クイックヘッドのリラクゼーション店【りらくる】</a><img border="0" width="1" height="1" src="https://www15.a8.net/0.gif?a8mat=3HIN6N+7FBNEA+4AQ0+5YJRM" alt=""></p> <!----></div> <div class="content-time" data-v-c4dc5dfa><time datetime="3/23/2021, 12:00:00 AM" class="time-text" data-v-c4dc5dfa>Create Time: 3/23/2021, 12:00:00 AM
    </time> <time datetime="8/21/2021, 3:21:52 AM" class="time-text" data-v-c4dc5dfa>Last Updated: 8/21/2021, 3:21:52 AM
    </time></div></article> <section class="flex-xb main info-nav" data-v-203269c1 data-v-2602fa21><a href="/posts/cyclegan01.html" class="flex-xb nav-item" data-v-203269c1><div class="flex-xcc item-img" data-v-203269c1><img data-src="https://www.hamlet-engineer.com/image/cyclegan_zebra.png" loading="lazy" alt="Python + CycleGanで茶毛のウマをシマウマに変換する" class="img lazy" data-v-203269c1></div> <article class="flex-ysc item-content" data-v-203269c1><h2 class="content-title" data-v-203269c1>Python + CycleGanで茶毛のウマをシマウマに変換する</h2> <div class="content" data-v-203269c1><p>画像生成系のCycleGanを実装します．Python + CycleGanで茶毛のウマをシマウマに変換します．<br></p>
</div></article></a> <a href="/posts/color_replace.html" class="flex-xb nav-item" data-v-203269c1><div class="flex-xcc item-img" data-v-203269c1><img data-src="https://www.hamlet-engineer.com/image/color_replace.png" loading="lazy" alt="Python, OpenCVで指定した色の抽出と別の色への置換を実装する" class="img lazy" data-v-203269c1></div> <article class="flex-ysc item-content" data-v-203269c1><h2 class="content-title" data-v-203269c1>Python, OpenCVで指定した色の抽出と別の色への置換を実装する</h2> <div class="content" data-v-203269c1><p>Python, OpenCVで指定した色の抽出と別の色への置換を実装します．<br>
本稿では，Cityscapesデータセットのカラーマスキング画像の内，人だけを抽出し，白色に置換します．</p>
</div></article></a></section> <!----></section></section> <footer class="footer" data-v-8dceedee data-v-98a81704><nav class="link-list" data-v-8dceedee><a href="https://twitter.com/hirasu1231" target="_blank" rel="noopener noreferrer" class="list-item" data-v-8dceedee>Twitter</a><a href="https://github.com/hirasu1231" target="_blank" rel="noopener noreferrer" class="list-item" data-v-8dceedee>Github</a></nav> <a href="/" class="copyright router-link-active" data-v-8dceedee>ハムレット型エンジニアのカンニングノート © 2022</a></footer></section><div class="global-ui"><!----><!----></div></div>
    <script src="/assets/js/app.3cfd382f.js" defer></script><script src="/assets/js/89.d8bb9cc1.js" defer></script>
  </body>
</html>
