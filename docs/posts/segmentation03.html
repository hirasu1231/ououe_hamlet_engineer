<!DOCTYPE html>
<html lang="ja-jp">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Python + ESPNetをオリジナルデータで学習する(学習編) | ハムレット型エンジニアのカンニングノート</title>
    <meta name="generator" content="VuePress 1.8.2">
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>(adsbygoogle = window.adsbygoogle || []).push({  google_ad_client: "ca-pub-2263820744635038",  enable_page_level_ads: true });</script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.0/dist/katex.min.css">
    <meta name="description" content="Python + ESPNetでCityscapesデータセットから人のみを抽出した仮のオリジナルデータで学習を実施します．">
    <meta property="article:published_time" content="2021-03-23T00:00:00.000Z">
    <meta property="article:modified_time" content="2022-06-14T06:24:05.000Z">
    <meta property="og:site_name" content="ハムレット型エンジニアのカンニングノート">
    <meta property="og:title" content="Python + ESPNetをオリジナルデータで学習する(学習編)">
    <meta property="og:description" content="Python + ESPNetでCityscapesデータセットから人のみを抽出した仮のオリジナルデータで学習を実施します．">
    <meta property="og:type" content="article">
    <meta property="og:url" content="/posts/segmentation03.html">
    <meta property="og:image" content="https://www.hamlet-engineer.com/image/org_seg1.png">
    <meta name="twitter:title" content="Python + ESPNetをオリジナルデータで学習する(学習編)">
    <meta name="twitter:description" content="Python + ESPNetでCityscapesデータセットから人のみを抽出した仮のオリジナルデータで学習を実施します．">
    <meta name="twitter:url" content="/posts/segmentation03.html">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:image" content="https://www.hamlet-engineer.com/image/org_seg1.png">
    <meta name="twitter:label2" content="Filed under">
    <meta name="twitter:data2" content="Python, Jupyter, ESPNet, Semantic_Segmentation">
    <meta property="article:tag" content="Python">
    <meta name="google-site-verification" content="BDXGk8FJfikB_I6Pyxv35Zc87jBMziCgRMvmpNDpdYA">
    
    <link rel="preload" href="/assets/css/0.styles.f79f4c23.css" as="style"><link rel="preload" href="/assets/js/app.78c225c3.js" as="script"><link rel="preload" href="/assets/js/146.3a75fc9d.js" as="script"><link rel="prefetch" href="/assets/js/10.14a68762.js"><link rel="prefetch" href="/assets/js/100.7de1e0ad.js"><link rel="prefetch" href="/assets/js/101.78890898.js"><link rel="prefetch" href="/assets/js/102.ad2551f9.js"><link rel="prefetch" href="/assets/js/103.b008bfc7.js"><link rel="prefetch" href="/assets/js/104.f4e719b2.js"><link rel="prefetch" href="/assets/js/105.7555b35a.js"><link rel="prefetch" href="/assets/js/106.6c5f890d.js"><link rel="prefetch" href="/assets/js/107.6e10dacc.js"><link rel="prefetch" href="/assets/js/108.5aa9925f.js"><link rel="prefetch" href="/assets/js/109.488eb94c.js"><link rel="prefetch" href="/assets/js/11.1f33645b.js"><link rel="prefetch" href="/assets/js/110.e2492ed3.js"><link rel="prefetch" href="/assets/js/111.72ffb74b.js"><link rel="prefetch" href="/assets/js/112.7d2b6fbe.js"><link rel="prefetch" href="/assets/js/113.89824f8a.js"><link rel="prefetch" href="/assets/js/114.37a0a99c.js"><link rel="prefetch" href="/assets/js/115.ed4cfb8a.js"><link rel="prefetch" href="/assets/js/116.48896ce5.js"><link rel="prefetch" href="/assets/js/117.23c02a81.js"><link rel="prefetch" href="/assets/js/118.1290efc3.js"><link rel="prefetch" href="/assets/js/119.e664cfb1.js"><link rel="prefetch" href="/assets/js/12.64db5509.js"><link rel="prefetch" href="/assets/js/120.85572d71.js"><link rel="prefetch" href="/assets/js/121.2bd47651.js"><link rel="prefetch" href="/assets/js/122.b35398d2.js"><link rel="prefetch" href="/assets/js/123.4f228291.js"><link rel="prefetch" href="/assets/js/124.9e976945.js"><link rel="prefetch" href="/assets/js/125.ba54dcc1.js"><link rel="prefetch" href="/assets/js/126.e14d1be5.js"><link rel="prefetch" href="/assets/js/127.f3d0991b.js"><link rel="prefetch" href="/assets/js/128.3bb2a8a6.js"><link rel="prefetch" href="/assets/js/129.0da5dd65.js"><link rel="prefetch" href="/assets/js/13.fbd3e0d8.js"><link rel="prefetch" href="/assets/js/130.93a492c2.js"><link rel="prefetch" href="/assets/js/131.de57059c.js"><link rel="prefetch" href="/assets/js/132.6b58d569.js"><link rel="prefetch" href="/assets/js/133.507254e4.js"><link rel="prefetch" href="/assets/js/134.3b752490.js"><link rel="prefetch" href="/assets/js/135.6fb057c2.js"><link rel="prefetch" href="/assets/js/136.f4dd8b59.js"><link rel="prefetch" href="/assets/js/137.fe8b68e4.js"><link rel="prefetch" href="/assets/js/138.4e56b4b5.js"><link rel="prefetch" href="/assets/js/139.d84c2411.js"><link rel="prefetch" href="/assets/js/14.8f6d46b1.js"><link rel="prefetch" href="/assets/js/140.e74afc37.js"><link rel="prefetch" href="/assets/js/141.568b1c59.js"><link rel="prefetch" href="/assets/js/142.89f7b4e8.js"><link rel="prefetch" href="/assets/js/143.0e9583c5.js"><link rel="prefetch" href="/assets/js/144.b9c134bc.js"><link rel="prefetch" href="/assets/js/145.89ef3d22.js"><link rel="prefetch" href="/assets/js/147.0f08f28c.js"><link rel="prefetch" href="/assets/js/148.446f7719.js"><link rel="prefetch" href="/assets/js/149.384351b0.js"><link rel="prefetch" href="/assets/js/15.ccffc3c7.js"><link rel="prefetch" href="/assets/js/150.9070f578.js"><link rel="prefetch" href="/assets/js/151.0cc5fe4a.js"><link rel="prefetch" href="/assets/js/152.a73e988e.js"><link rel="prefetch" href="/assets/js/153.59293406.js"><link rel="prefetch" href="/assets/js/154.6963065d.js"><link rel="prefetch" href="/assets/js/155.7cf3ae3d.js"><link rel="prefetch" href="/assets/js/156.f1572624.js"><link rel="prefetch" href="/assets/js/157.e4dda607.js"><link rel="prefetch" href="/assets/js/158.f1d135f7.js"><link rel="prefetch" href="/assets/js/159.ad84f494.js"><link rel="prefetch" href="/assets/js/16.5d39bb4c.js"><link rel="prefetch" href="/assets/js/160.a7f591d2.js"><link rel="prefetch" href="/assets/js/161.9a8246ae.js"><link rel="prefetch" href="/assets/js/162.54fdf4f5.js"><link rel="prefetch" href="/assets/js/163.3c339287.js"><link rel="prefetch" href="/assets/js/164.7aaa1933.js"><link rel="prefetch" href="/assets/js/165.95433ae3.js"><link rel="prefetch" href="/assets/js/166.091ce08e.js"><link rel="prefetch" href="/assets/js/167.25fa3672.js"><link rel="prefetch" href="/assets/js/168.1d259f4d.js"><link rel="prefetch" href="/assets/js/169.176eb07a.js"><link rel="prefetch" href="/assets/js/17.53adc151.js"><link rel="prefetch" href="/assets/js/170.9114185d.js"><link rel="prefetch" href="/assets/js/171.a1ae6a01.js"><link rel="prefetch" href="/assets/js/172.0f502029.js"><link rel="prefetch" href="/assets/js/173.61c886f8.js"><link rel="prefetch" href="/assets/js/174.1a7e7751.js"><link rel="prefetch" href="/assets/js/175.6acfb128.js"><link rel="prefetch" href="/assets/js/176.f4c60f99.js"><link rel="prefetch" href="/assets/js/177.1b1667a7.js"><link rel="prefetch" href="/assets/js/178.2e03570e.js"><link rel="prefetch" href="/assets/js/179.3bfd4228.js"><link rel="prefetch" href="/assets/js/18.07445f9f.js"><link rel="prefetch" href="/assets/js/180.53cfa2b2.js"><link rel="prefetch" href="/assets/js/181.49eb331b.js"><link rel="prefetch" href="/assets/js/182.979f2985.js"><link rel="prefetch" href="/assets/js/183.72774fc4.js"><link rel="prefetch" href="/assets/js/184.48d50bd7.js"><link rel="prefetch" href="/assets/js/185.2b2617ea.js"><link rel="prefetch" href="/assets/js/186.e9099e99.js"><link rel="prefetch" href="/assets/js/187.9c7fc757.js"><link rel="prefetch" href="/assets/js/188.6dad4802.js"><link rel="prefetch" href="/assets/js/189.df429035.js"><link rel="prefetch" href="/assets/js/19.5e4ce222.js"><link rel="prefetch" href="/assets/js/190.1e3e3312.js"><link rel="prefetch" href="/assets/js/191.b81bd5df.js"><link rel="prefetch" href="/assets/js/192.d6e8a461.js"><link rel="prefetch" href="/assets/js/193.6136f407.js"><link rel="prefetch" href="/assets/js/194.7d27720a.js"><link rel="prefetch" href="/assets/js/2.83d55d0b.js"><link rel="prefetch" href="/assets/js/20.813107bf.js"><link rel="prefetch" href="/assets/js/21.9c962f16.js"><link rel="prefetch" href="/assets/js/22.93e0f87a.js"><link rel="prefetch" href="/assets/js/23.8ede9a39.js"><link rel="prefetch" href="/assets/js/24.58baed08.js"><link rel="prefetch" href="/assets/js/25.ed782329.js"><link rel="prefetch" href="/assets/js/26.268b3b88.js"><link rel="prefetch" href="/assets/js/27.e1760db0.js"><link rel="prefetch" href="/assets/js/28.2ae03c14.js"><link rel="prefetch" href="/assets/js/29.fb28f750.js"><link rel="prefetch" href="/assets/js/3.1a104747.js"><link rel="prefetch" href="/assets/js/30.e20b3493.js"><link rel="prefetch" href="/assets/js/31.18cefc2c.js"><link rel="prefetch" href="/assets/js/32.f4d5d739.js"><link rel="prefetch" href="/assets/js/33.e1a5597c.js"><link rel="prefetch" href="/assets/js/34.365b776e.js"><link rel="prefetch" href="/assets/js/35.bda0cc53.js"><link rel="prefetch" href="/assets/js/36.5452ae7d.js"><link rel="prefetch" href="/assets/js/37.c6f37188.js"><link rel="prefetch" href="/assets/js/38.c2ad773b.js"><link rel="prefetch" href="/assets/js/39.00f26e1b.js"><link rel="prefetch" href="/assets/js/4.88b9a38a.js"><link rel="prefetch" href="/assets/js/40.e6c64db6.js"><link rel="prefetch" href="/assets/js/41.82f875ee.js"><link rel="prefetch" href="/assets/js/42.04c38605.js"><link rel="prefetch" href="/assets/js/43.e333f554.js"><link rel="prefetch" href="/assets/js/44.6ef2d2ce.js"><link rel="prefetch" href="/assets/js/45.423edfcc.js"><link rel="prefetch" href="/assets/js/46.9f95279f.js"><link rel="prefetch" href="/assets/js/47.6b131cef.js"><link rel="prefetch" href="/assets/js/48.05870f04.js"><link rel="prefetch" href="/assets/js/49.22089cfd.js"><link rel="prefetch" href="/assets/js/5.74cf20b7.js"><link rel="prefetch" href="/assets/js/50.a4e9dda4.js"><link rel="prefetch" href="/assets/js/51.4b655f08.js"><link rel="prefetch" href="/assets/js/52.e4b2c276.js"><link rel="prefetch" href="/assets/js/53.fe83d6c9.js"><link rel="prefetch" href="/assets/js/54.17feb69e.js"><link rel="prefetch" href="/assets/js/55.71735542.js"><link rel="prefetch" href="/assets/js/56.f99474ed.js"><link rel="prefetch" href="/assets/js/57.c8de5b4e.js"><link rel="prefetch" href="/assets/js/58.0a144433.js"><link rel="prefetch" href="/assets/js/59.c7ac8f3d.js"><link rel="prefetch" href="/assets/js/6.913c84b4.js"><link rel="prefetch" href="/assets/js/60.17c95535.js"><link rel="prefetch" href="/assets/js/61.c6f2297c.js"><link rel="prefetch" href="/assets/js/62.6dce89c6.js"><link rel="prefetch" href="/assets/js/63.36ccdb43.js"><link rel="prefetch" href="/assets/js/64.1d91a8ba.js"><link rel="prefetch" href="/assets/js/65.a2e22a71.js"><link rel="prefetch" href="/assets/js/66.87303c98.js"><link rel="prefetch" href="/assets/js/67.89623558.js"><link rel="prefetch" href="/assets/js/68.e80920c1.js"><link rel="prefetch" href="/assets/js/69.79da8f40.js"><link rel="prefetch" href="/assets/js/7.e918a77f.js"><link rel="prefetch" href="/assets/js/70.e173bc68.js"><link rel="prefetch" href="/assets/js/71.5e222d81.js"><link rel="prefetch" href="/assets/js/72.abc56e09.js"><link rel="prefetch" href="/assets/js/73.4896d99a.js"><link rel="prefetch" href="/assets/js/74.d411110c.js"><link rel="prefetch" href="/assets/js/75.84386e6a.js"><link rel="prefetch" href="/assets/js/76.c79a8463.js"><link rel="prefetch" href="/assets/js/77.5e99581b.js"><link rel="prefetch" href="/assets/js/78.c4de285b.js"><link rel="prefetch" href="/assets/js/79.ade8eec6.js"><link rel="prefetch" href="/assets/js/8.f4a02c1c.js"><link rel="prefetch" href="/assets/js/80.5b147778.js"><link rel="prefetch" href="/assets/js/81.62db783a.js"><link rel="prefetch" href="/assets/js/82.65a263e8.js"><link rel="prefetch" href="/assets/js/83.e1a0b762.js"><link rel="prefetch" href="/assets/js/84.cd6ff420.js"><link rel="prefetch" href="/assets/js/85.b2be1cff.js"><link rel="prefetch" href="/assets/js/86.2c125bc3.js"><link rel="prefetch" href="/assets/js/87.7860a486.js"><link rel="prefetch" href="/assets/js/88.8cf32e9b.js"><link rel="prefetch" href="/assets/js/89.4d99846d.js"><link rel="prefetch" href="/assets/js/9.e008d612.js"><link rel="prefetch" href="/assets/js/90.f1e3cc00.js"><link rel="prefetch" href="/assets/js/91.ac40f3e7.js"><link rel="prefetch" href="/assets/js/92.eef4a977.js"><link rel="prefetch" href="/assets/js/93.8e486766.js"><link rel="prefetch" href="/assets/js/94.19ee679d.js"><link rel="prefetch" href="/assets/js/95.31ef0bca.js"><link rel="prefetch" href="/assets/js/96.d5f3eed1.js"><link rel="prefetch" href="/assets/js/97.702c8909.js"><link rel="prefetch" href="/assets/js/98.c706be80.js"><link rel="prefetch" href="/assets/js/99.8924b0dc.js">
    <link rel="stylesheet" href="/assets/css/0.styles.f79f4c23.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><section id="global-layout" data-v-98a81704><header class="header" data-v-00466d8e data-v-98a81704><div class="header-navbar" data-v-00466d8e><div class="flex-xbc main header-nav" data-v-00466d8e><div class="nav-link" data-v-00466d8e><a href="/" class="inblock link-logo router-link-active" data-v-00466d8e><img data-src="/logo.png" loading="lazy" alt="logo" class="logo-img lazy" data-v-00466d8e></a> <nav class="link-list" data-v-00466d8e><a href="/" class="list-item router-link-active" data-v-00466d8e>ホーム</a><a href="/about/" class="list-item" data-v-00466d8e>ページ集</a><a href="/posts/" class="list-item router-link-active" data-v-00466d8e>技術</a><a href="/study/" class="list-item" data-v-00466d8e>小ネタ</a><a href="/other/" class="list-item" data-v-00466d8e>その他</a><a href="/tag/" class="list-item" data-v-00466d8e>タグ</a><a href="/category/" class="list-item" data-v-00466d8e>カテゴリ</a><a href="https://twitter.com/hirasu1231" target="_blank" rel="noopener noreferrer" class="list-item" data-v-00466d8e>筆者</a></nav></div> <div class="search-box" data-v-00466d8e><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div></div></div> </header> <!----> <section class="page" data-v-98a81704 data-v-98a81704><section class="info no-bg" data-v-2602fa21><article class="main info-content" data-v-c4dc5dfa data-v-2602fa21><div class="content-header" data-v-c4dc5dfa><h1 class="header-title" data-v-c4dc5dfa>Python + ESPNetをオリジナルデータで学習する(学習編)</h1></div> <div class="flex-wcc content-tag" data-v-c4dc5dfa><div class="inblock tag-list" data-v-c4dc5dfa><a href="/category/Python/" class="tag-text" data-v-c4dc5dfa>Python
      </a></div> <span class="tag-space" data-v-c4dc5dfa>/</span> <div class="inblock tag-list" data-v-c4dc5dfa><a href="/tag/Python/" class="tag-text" data-v-c4dc5dfa>Python
      </a><a href="/tag/Jupyter/" class="tag-text" data-v-c4dc5dfa>Jupyter
      </a><a href="/tag/ESPNet/" class="tag-text" data-v-c4dc5dfa>ESPNet
      </a><a href="/tag/Semantic_Segmentation/" class="tag-text" data-v-c4dc5dfa>Semantic_Segmentation
      </a></div></div> <div class="content content__default" data-v-c4dc5dfa><p>セマンティックセグメンテーションの中で軽いモデルであるESPNetv2を実装します．<br>
本稿ではCityscapesデータセットから人のみを抽出した仮のオリジナルデータで学習を実施します．<br></p> <!----> <p>今回はGoogle ColabとGoogle Driveを連携させて，notebook形式で実行してます．<br></p> <blockquote><p>Google Colaboratory（以下Google Colab）は、Google社が無料で提供している機械学習の教育や研究用の開発環境です。開発環境はJupyter Notebookに似たインターフェースを持ち、Pythonの主要なライブラリがプリインストールされています。<br>
引用元：<a href="https://interface.cqpub.co.jp/ail01/" target="_blank" rel="noopener noreferrer">Google Colabの使い方<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p></blockquote> <p>最終的に，人以外の背景を着色して，zoomのバーチャル背景機能のようなクロマキー合成を実装したいです．<br> <img alt="" data-src="/image/zoom.jpg" loading="lazy" class="lazy"></p> <p></p><div class="table-of-contents"><ul><li><a href="#作業ディレクトリのファイル構成">作業ディレクトリのファイル構成</a></li><li><a href="#オリジナルデータの学習">オリジナルデータの学習</a><ul><li><a href="#オリジナルデータの学習コードの作成">オリジナルデータの学習コードの作成</a></li><li><a href="#オリジナルデータの学習-第1段階">オリジナルデータの学習(第1段階)</a></li><li><a href="#オリジナルデータの学習-第2段階">オリジナルデータの学習(第2段階)</a></li></ul></li><li><a href="#オリジナルデータモデルのテスト">オリジナルデータモデルのテスト</a><ul><li><a href="#テストの実行">テストの実行</a></li><li><a href="#テスト結果">テスト結果</a></li></ul></li><li><a href="#まとめ">まとめ</a></li><li><a href="#参考サイト">参考サイト</a></li></ul></div><p></p> <p><a href="https://px.a8.net/svt/ejp?a8mat=3HBXCY+4DRW36+50+2HM5Z5" rel="nofollow"><img border="0" width="1000" height="124" alt="" src="https://www27.a8.net/svt/bgt?aid=210508450265&amp;wid=001&amp;eno=01&amp;mid=s00000000018015052000&amp;mc=1"></a><img border="0" width="1" height="1" src="https://www10.a8.net/0.gif?a8mat=3HBXCY+4DRW36+50+2HM5Z5" alt=""></p> <p><a href="https://px.a8.net/svt/ejp?a8mat=3HIN6N+3YAMCY+CO4+6BMG1" rel="nofollow"><img border="0" width="1000" height="124" alt="" src="https://www23.a8.net/svt/bgt?aid=210821855239&amp;wid=001&amp;eno=01&amp;mid=s00000001642001062000&amp;mc=1"></a><img border="0" width="1" height="1" src="https://www17.a8.net/0.gif?a8mat=3HIN6N+3YAMCY+CO4+6BMG1" alt=""></p> <p><a href="https://px.a8.net/svt/ejp?a8mat=3HIN6N+7FBNEA+4AQ0+5YJRM" rel="nofollow">全国630店舗以上！もみほぐし・足つぼ・ハンドリフレ・クイックヘッドのリラクゼーション店【りらくる】</a><img border="0" width="1" height="1" src="https://www15.a8.net/0.gif?a8mat=3HIN6N+7FBNEA+4AQ0+5YJRM" alt=""></p> <h2 id="作業ディレクトリのファイル構成"><a href="#作業ディレクトリのファイル構成" class="header-anchor">#</a> 作業ディレクトリのファイル構成</h2> <p>プロジェクトディレクトリはsegmentationとしています．度々，省略しています．</p> <div class="language- extra-class"><pre class="language-text"><code>segmentation
├── /EdgeNets
│   ├── /vision_datasets
│   │   ├── create_data.ipynb &lt;- データ生成用ノートブック
│   │   ├── /cityscapes
│   │   └── /human_city  &lt;- 仮オリジナルデータ
│   │       ├── train.txt
│   │       ├── val.txt
│   │       ├── /train
│   │       │   ├── /rgb
│   │       │   └── /label
│   │       └── /val
│   │           ├── /rgb
│   │           └── /label
│   │
│   ├── /results_segmentation &lt;- モデルの出力ディレクトリ
│   │   └── /human_city
│   ├── /result_images &lt;- 着色画像の出力ディレクトリ
│   │   └── /human_city
│   │
│   ├── /sample_images &lt;- サンプル画像
│   ├── train_segmentation.py
│   ├── test_segmentation.py
│   ├── custom_test_segmentation.py &lt;- 新規作成
│   ├── custom_train_segmentation.py &lt;- 新規作成
│   └── (省略)
└── ESPNetv2.ipynb &lt;- 実行用ノートブック
</code></pre></div><h2 id="オリジナルデータの学習"><a href="#オリジナルデータの学習" class="header-anchor">#</a> オリジナルデータの学習</h2> <h3 id="オリジナルデータの学習コードの作成"><a href="#オリジナルデータの学習コードの作成" class="header-anchor">#</a> オリジナルデータの学習コードの作成</h3> <p>デフォルトのtrain_segmentation.pyではオリジナルデータでの学習に対応していないため，オリジナルデータに対応した<code>custom_train_segmentation.py</code>を作成します．<br>
train_segmentation.pyではそれぞれのデータセットのクラス数に自動で指定されるため，コマンドの引数で指定されるように変更します．<br>
また，miou_val, val_lossをエポックの度にtxtファイルに記述するようにしています．<br></p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># custom_train_segmentation.py</span>

<span class="token comment"># ============================================</span>
__author__ <span class="token operator">=</span> <span class="token string">&quot;Sachin Mehta&quot;</span>
__license__ <span class="token operator">=</span> <span class="token string">&quot;MIT&quot;</span>
__maintainer__ <span class="token operator">=</span> <span class="token string">&quot;Sachin Mehta&quot;</span>
<span class="token comment"># ============================================</span>

<span class="token keyword">import</span> argparse
<span class="token keyword">import</span> os
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim
<span class="token keyword">from</span> utilities<span class="token punctuation">.</span>utils <span class="token keyword">import</span> save_checkpoint<span class="token punctuation">,</span> model_parameters<span class="token punctuation">,</span> compute_flops
<span class="token keyword">from</span> utilities<span class="token punctuation">.</span>train_eval_seg <span class="token keyword">import</span> train_seg <span class="token keyword">as</span> train
<span class="token keyword">from</span> utilities<span class="token punctuation">.</span>train_eval_seg <span class="token keyword">import</span> val_seg <span class="token keyword">as</span> val
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriter
<span class="token keyword">from</span> loss_fns<span class="token punctuation">.</span>segmentation_loss <span class="token keyword">import</span> SegmentationLoss
<span class="token keyword">import</span> random
<span class="token keyword">import</span> math
<span class="token keyword">import</span> time
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> utilities<span class="token punctuation">.</span>print_utils <span class="token keyword">import</span> <span class="token operator">*</span>


<span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token punctuation">)</span><span class="token punctuation">:</span>
    crop_size <span class="token operator">=</span> args<span class="token punctuation">.</span>crop_size
    <span class="token keyword">assert</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>crop_size<span class="token punctuation">,</span> <span class="token builtin">tuple</span><span class="token punctuation">)</span>
    print_info_message<span class="token punctuation">(</span><span class="token string">'Running Model at image resolution {}x{} with batch size {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>crop_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> crop_size<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> args<span class="token punctuation">.</span>batch_size<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>isdir<span class="token punctuation">(</span>args<span class="token punctuation">.</span>savedir<span class="token punctuation">)</span><span class="token punctuation">:</span>
        os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>args<span class="token punctuation">.</span>savedir<span class="token punctuation">)</span>
        
    <span class="token keyword">if</span> args<span class="token punctuation">.</span>dataset <span class="token operator">==</span> <span class="token string">'custom'</span><span class="token punctuation">:</span>
        <span class="token keyword">from</span> data_loader<span class="token punctuation">.</span>segmentation<span class="token punctuation">.</span>custom_dataset_loader <span class="token keyword">import</span> CustomSegmentationDataset
        train_dataset <span class="token operator">=</span> CustomSegmentationDataset<span class="token punctuation">(</span>root<span class="token operator">=</span>args<span class="token punctuation">.</span>data_path<span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> crop_size<span class="token operator">=</span>crop_size<span class="token punctuation">,</span> scale<span class="token operator">=</span>args<span class="token punctuation">.</span>scale<span class="token punctuation">)</span>
        val_dataset <span class="token operator">=</span> CustomSegmentationDataset<span class="token punctuation">(</span>root<span class="token operator">=</span>args<span class="token punctuation">.</span>data_path<span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> crop_size<span class="token operator">=</span>crop_size<span class="token punctuation">,</span> scale<span class="token operator">=</span>args<span class="token punctuation">.</span>scale<span class="token punctuation">)</span>
                         
        seg_classes <span class="token operator">=</span> args<span class="token punctuation">.</span>num_classes
        class_wts <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>seg_classes<span class="token punctuation">)</span>
        
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        print_error_message<span class="token punctuation">(</span><span class="token string">'Dataset: {} not yet supported'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span><span class="token punctuation">)</span>
        exit<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

    print_info_message<span class="token punctuation">(</span><span class="token string">'Training samples: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>train_dataset<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    print_info_message<span class="token punctuation">(</span><span class="token string">'Validation samples: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>val_dataset<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> args<span class="token punctuation">.</span>model <span class="token operator">==</span> <span class="token string">'espnetv2'</span><span class="token punctuation">:</span>
        <span class="token keyword">from</span> model<span class="token punctuation">.</span>segmentation<span class="token punctuation">.</span>espnetv2 <span class="token keyword">import</span> espnetv2_seg
        args<span class="token punctuation">.</span>classes <span class="token operator">=</span> seg_classes
        model <span class="token operator">=</span> espnetv2_seg<span class="token punctuation">(</span>args<span class="token punctuation">)</span>
    <span class="token keyword">elif</span> args<span class="token punctuation">.</span>model <span class="token operator">==</span> <span class="token string">'dicenet'</span><span class="token punctuation">:</span>
        <span class="token keyword">from</span> model<span class="token punctuation">.</span>segmentation<span class="token punctuation">.</span>dicenet <span class="token keyword">import</span> dicenet_seg
        model <span class="token operator">=</span> dicenet_seg<span class="token punctuation">(</span>args<span class="token punctuation">,</span> classes<span class="token operator">=</span>seg_classes<span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        print_error_message<span class="token punctuation">(</span><span class="token string">'Arch: {} not yet supported'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>model<span class="token punctuation">)</span><span class="token punctuation">)</span>
        exit<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> args<span class="token punctuation">.</span>finetune<span class="token punctuation">:</span>
        <span class="token keyword">if</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>isfile<span class="token punctuation">(</span>args<span class="token punctuation">.</span>finetune<span class="token punctuation">)</span><span class="token punctuation">:</span>
            print_info_message<span class="token punctuation">(</span><span class="token string">'Loading weights for finetuning from {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>finetune<span class="token punctuation">)</span><span class="token punctuation">)</span>
            weight_dict <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>args<span class="token punctuation">.</span>finetune<span class="token punctuation">,</span> map_location<span class="token operator">=</span>torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span>device<span class="token operator">=</span><span class="token string">'cpu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>weight_dict<span class="token punctuation">)</span>
            print_info_message<span class="token punctuation">(</span><span class="token string">'Done'</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            print_warning_message<span class="token punctuation">(</span><span class="token string">'No file for finetuning. Please check.'</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> args<span class="token punctuation">.</span>freeze_bn<span class="token punctuation">:</span>
        print_info_message<span class="token punctuation">(</span><span class="token string">'Freezing batch normalization layers'</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> m <span class="token keyword">in</span> model<span class="token punctuation">.</span>modules<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">)</span><span class="token punctuation">:</span>
                m<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
                m<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">False</span>
                m<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">False</span>

    num_gpus <span class="token operator">=</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>device_count<span class="token punctuation">(</span><span class="token punctuation">)</span>
    device <span class="token operator">=</span> <span class="token string">'cuda'</span> <span class="token keyword">if</span> num_gpus <span class="token operator">&gt;</span> <span class="token number">0</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span>

    train_params <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">'params'</span><span class="token punctuation">:</span> model<span class="token punctuation">.</span>get_basenet_params<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'lr'</span><span class="token punctuation">:</span> args<span class="token punctuation">.</span>lr<span class="token punctuation">}</span><span class="token punctuation">,</span>
                    <span class="token punctuation">{</span><span class="token string">'params'</span><span class="token punctuation">:</span> model<span class="token punctuation">.</span>get_segment_params<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'lr'</span><span class="token punctuation">:</span> args<span class="token punctuation">.</span>lr <span class="token operator">*</span> args<span class="token punctuation">.</span>lr_mult<span class="token punctuation">}</span><span class="token punctuation">]</span>

    optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>train_params<span class="token punctuation">,</span> momentum<span class="token operator">=</span>args<span class="token punctuation">.</span>momentum<span class="token punctuation">,</span> weight_decay<span class="token operator">=</span>args<span class="token punctuation">.</span>weight_decay<span class="token punctuation">)</span>

    num_params <span class="token operator">=</span> model_parameters<span class="token punctuation">(</span>model<span class="token punctuation">)</span>
    flops <span class="token operator">=</span> compute_flops<span class="token punctuation">(</span>model<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token operator">=</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> crop_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> crop_size<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    print_info_message<span class="token punctuation">(</span><span class="token string">'FLOPs for an input of size {}x{}: {:.2f} million'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>crop_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> crop_size<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> flops<span class="token punctuation">)</span><span class="token punctuation">)</span>
    print_info_message<span class="token punctuation">(</span><span class="token string">'Network Parameters: {:.2f} million'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>num_params<span class="token punctuation">)</span><span class="token punctuation">)</span>

    writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span>log_dir<span class="token operator">=</span>args<span class="token punctuation">.</span>savedir<span class="token punctuation">,</span> comment<span class="token operator">=</span><span class="token string">'Training and Validation logs'</span><span class="token punctuation">)</span>
    <span class="token keyword">try</span><span class="token punctuation">:</span>
        writer<span class="token punctuation">.</span>add_graph<span class="token punctuation">(</span>model<span class="token punctuation">,</span> input_to_model<span class="token operator">=</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> crop_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> crop_size<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">except</span><span class="token punctuation">:</span>
        print_log_message<span class="token punctuation">(</span><span class="token string">&quot;Not able to generate the graph. Likely because your model is not supported by ONNX&quot;</span><span class="token punctuation">)</span>

    start_epoch <span class="token operator">=</span> <span class="token number">0</span>
    best_miou <span class="token operator">=</span> <span class="token number">0.0</span>
    <span class="token keyword">if</span> args<span class="token punctuation">.</span>resume<span class="token punctuation">:</span>
        <span class="token keyword">if</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>isfile<span class="token punctuation">(</span>args<span class="token punctuation">.</span>resume<span class="token punctuation">)</span><span class="token punctuation">:</span>
            print_info_message<span class="token punctuation">(</span><span class="token string">&quot;=&gt; loading checkpoint '{}'&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>resume<span class="token punctuation">)</span><span class="token punctuation">)</span>
            checkpoint <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>args<span class="token punctuation">.</span>resume<span class="token punctuation">,</span> map_location<span class="token operator">=</span>torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cpu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            start_epoch <span class="token operator">=</span> checkpoint<span class="token punctuation">[</span><span class="token string">'epoch'</span><span class="token punctuation">]</span>
            best_miou <span class="token operator">=</span> checkpoint<span class="token punctuation">[</span><span class="token string">'best_miou'</span><span class="token punctuation">]</span>
            model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>checkpoint<span class="token punctuation">[</span><span class="token string">'state_dict'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            optimizer<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>checkpoint<span class="token punctuation">[</span><span class="token string">'optimizer'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            print_info_message<span class="token punctuation">(</span><span class="token string">&quot;=&gt; loaded checkpoint '{}' (epoch {})&quot;</span>
                               <span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>resume<span class="token punctuation">,</span> checkpoint<span class="token punctuation">[</span><span class="token string">'epoch'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            print_warning_message<span class="token punctuation">(</span><span class="token string">&quot;=&gt; no checkpoint found at '{}'&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>resume<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">#criterion = nn.CrossEntropyLoss(weight=class_wts, reduction='none', ignore_index=args.ignore_idx)</span>
    criterion <span class="token operator">=</span> SegmentationLoss<span class="token punctuation">(</span>n_classes<span class="token operator">=</span>seg_classes<span class="token punctuation">,</span> loss_type<span class="token operator">=</span>args<span class="token punctuation">.</span>loss_type<span class="token punctuation">,</span>
                         device<span class="token operator">=</span>device<span class="token punctuation">,</span> ignore_idx<span class="token operator">=</span>args<span class="token punctuation">.</span>ignore_idx<span class="token punctuation">,</span>
                         class_wts<span class="token operator">=</span>class_wts<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> num_gpus <span class="token operator">&gt;=</span> <span class="token number">1</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> num_gpus <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
            <span class="token comment"># for a single GPU, we do not need DataParallel wrapper for Criteria.</span>
            <span class="token comment"># So, falling back to its internal wrapper</span>
            <span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>parallel <span class="token keyword">import</span> DataParallel
            model <span class="token operator">=</span> DataParallel<span class="token punctuation">(</span>model<span class="token punctuation">)</span>
            model <span class="token operator">=</span> model<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
            criterion <span class="token operator">=</span> criterion<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token keyword">from</span> utilities<span class="token punctuation">.</span>parallel_wrapper <span class="token keyword">import</span> DataParallelModel<span class="token punctuation">,</span> DataParallelCriteria
            model <span class="token operator">=</span> DataParallelModel<span class="token punctuation">(</span>model<span class="token punctuation">)</span>
            model <span class="token operator">=</span> model<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
            criterion <span class="token operator">=</span> DataParallelCriteria<span class="token punctuation">(</span>criterion<span class="token punctuation">)</span>
            criterion <span class="token operator">=</span> criterion<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token keyword">if</span> torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">import</span> torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn <span class="token keyword">as</span> cudnn
            cudnn<span class="token punctuation">.</span>benchmark <span class="token operator">=</span> <span class="token boolean">True</span>
            cudnn<span class="token punctuation">.</span>deterministic <span class="token operator">=</span> <span class="token boolean">True</span>

    train_loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>train_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>args<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                           pin_memory<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span>args<span class="token punctuation">.</span>workers<span class="token punctuation">)</span>
    val_loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>val_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>args<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
                         pin_memory<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span>args<span class="token punctuation">.</span>workers<span class="token punctuation">)</span>

    <span class="token keyword">if</span> args<span class="token punctuation">.</span>scheduler <span class="token operator">==</span> <span class="token string">'fixed'</span><span class="token punctuation">:</span>
        step_size <span class="token operator">=</span> args<span class="token punctuation">.</span>step_size
        step_sizes <span class="token operator">=</span> <span class="token punctuation">[</span>step_size <span class="token operator">*</span> i <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>math<span class="token punctuation">.</span>ceil<span class="token punctuation">(</span>args<span class="token punctuation">.</span>epochs <span class="token operator">/</span> step_size<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
        <span class="token keyword">from</span> utilities<span class="token punctuation">.</span>lr_scheduler <span class="token keyword">import</span> FixedMultiStepLR
        lr_scheduler <span class="token operator">=</span> FixedMultiStepLR<span class="token punctuation">(</span>base_lr<span class="token operator">=</span>args<span class="token punctuation">.</span>lr<span class="token punctuation">,</span> steps<span class="token operator">=</span>step_sizes<span class="token punctuation">,</span> gamma<span class="token operator">=</span>args<span class="token punctuation">.</span>lr_decay<span class="token punctuation">)</span>
    <span class="token keyword">elif</span> args<span class="token punctuation">.</span>scheduler <span class="token operator">==</span> <span class="token string">'clr'</span><span class="token punctuation">:</span>
        step_size <span class="token operator">=</span> args<span class="token punctuation">.</span>step_size
        step_sizes <span class="token operator">=</span> <span class="token punctuation">[</span>step_size <span class="token operator">*</span> i <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>math<span class="token punctuation">.</span>ceil<span class="token punctuation">(</span>args<span class="token punctuation">.</span>epochs <span class="token operator">/</span> step_size<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
        <span class="token keyword">from</span> utilities<span class="token punctuation">.</span>lr_scheduler <span class="token keyword">import</span> CyclicLR
        lr_scheduler <span class="token operator">=</span> CyclicLR<span class="token punctuation">(</span>min_lr<span class="token operator">=</span>args<span class="token punctuation">.</span>lr<span class="token punctuation">,</span> cycle_len<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> steps<span class="token operator">=</span>step_sizes<span class="token punctuation">,</span> gamma<span class="token operator">=</span>args<span class="token punctuation">.</span>lr_decay<span class="token punctuation">)</span>
    <span class="token keyword">elif</span> args<span class="token punctuation">.</span>scheduler <span class="token operator">==</span> <span class="token string">'poly'</span><span class="token punctuation">:</span>
        <span class="token keyword">from</span> utilities<span class="token punctuation">.</span>lr_scheduler <span class="token keyword">import</span> PolyLR
        lr_scheduler <span class="token operator">=</span> PolyLR<span class="token punctuation">(</span>base_lr<span class="token operator">=</span>args<span class="token punctuation">.</span>lr<span class="token punctuation">,</span> max_epochs<span class="token operator">=</span>args<span class="token punctuation">.</span>epochs<span class="token punctuation">,</span> power<span class="token operator">=</span>args<span class="token punctuation">.</span>power<span class="token punctuation">)</span>
    <span class="token keyword">elif</span> args<span class="token punctuation">.</span>scheduler <span class="token operator">==</span> <span class="token string">'hybrid'</span><span class="token punctuation">:</span>
        <span class="token keyword">from</span> utilities<span class="token punctuation">.</span>lr_scheduler <span class="token keyword">import</span> HybirdLR
        lr_scheduler <span class="token operator">=</span> HybirdLR<span class="token punctuation">(</span>base_lr<span class="token operator">=</span>args<span class="token punctuation">.</span>lr<span class="token punctuation">,</span> max_epochs<span class="token operator">=</span>args<span class="token punctuation">.</span>epochs<span class="token punctuation">,</span> clr_max<span class="token operator">=</span>args<span class="token punctuation">.</span>clr_max<span class="token punctuation">,</span>
                        cycle_len<span class="token operator">=</span>args<span class="token punctuation">.</span>cycle_len<span class="token punctuation">)</span>
    <span class="token keyword">elif</span> args<span class="token punctuation">.</span>scheduler <span class="token operator">==</span> <span class="token string">'linear'</span><span class="token punctuation">:</span>
        <span class="token keyword">from</span> utilities<span class="token punctuation">.</span>lr_scheduler <span class="token keyword">import</span> LinearLR
        lr_scheduler <span class="token operator">=</span> LinearLR<span class="token punctuation">(</span>base_lr<span class="token operator">=</span>args<span class="token punctuation">.</span>lr<span class="token punctuation">,</span> max_epochs<span class="token operator">=</span>args<span class="token punctuation">.</span>epochs<span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        print_error_message<span class="token punctuation">(</span><span class="token string">'{} scheduler Not supported'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>scheduler<span class="token punctuation">)</span><span class="token punctuation">)</span>
        exit<span class="token punctuation">(</span><span class="token punctuation">)</span>

    print_info_message<span class="token punctuation">(</span>lr_scheduler<span class="token punctuation">)</span>

    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>savedir <span class="token operator">+</span> os<span class="token punctuation">.</span>sep <span class="token operator">+</span> <span class="token string">'arguments.json'</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> outfile<span class="token punctuation">:</span>
        <span class="token keyword">import</span> json
        arg_dict <span class="token operator">=</span> <span class="token builtin">vars</span><span class="token punctuation">(</span>args<span class="token punctuation">)</span>
        arg_dict<span class="token punctuation">[</span><span class="token string">'model_params'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'{} '</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>num_params<span class="token punctuation">)</span>
        arg_dict<span class="token punctuation">[</span><span class="token string">'flops'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'{} '</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>flops<span class="token punctuation">)</span>
        json<span class="token punctuation">.</span>dump<span class="token punctuation">(</span>arg_dict<span class="token punctuation">,</span> outfile<span class="token punctuation">)</span>

    extra_info_ckpt <span class="token operator">=</span> <span class="token string">'{}_{}_{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>model<span class="token punctuation">,</span> args<span class="token punctuation">.</span>s<span class="token punctuation">,</span> crop_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    
    <span class="token comment"># val log txtfile</span>
    txt_outpath <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>args<span class="token punctuation">.</span>savedir<span class="token punctuation">,</span> <span class="token string">'val_logs.txt'</span><span class="token punctuation">)</span>
    txt_outfile <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span>txt_outpath<span class="token punctuation">,</span> <span class="token string">&quot;w&quot;</span><span class="token punctuation">)</span>
    txt_outfile<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'epoch, miou_val, val_loss\n'</span><span class="token punctuation">)</span>
    
    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>start_epoch<span class="token punctuation">,</span> args<span class="token punctuation">.</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        lr_base <span class="token operator">=</span> lr_scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span>epoch<span class="token punctuation">)</span>
        <span class="token comment"># set the optimizer with the learning rate</span>
        <span class="token comment"># This can be done inside the MyLRScheduler</span>
        lr_seg <span class="token operator">=</span> lr_base <span class="token operator">*</span> args<span class="token punctuation">.</span>lr_mult
        optimizer<span class="token punctuation">.</span>param_groups<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'lr'</span><span class="token punctuation">]</span> <span class="token operator">=</span> lr_base
        optimizer<span class="token punctuation">.</span>param_groups<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'lr'</span><span class="token punctuation">]</span> <span class="token operator">=</span> lr_seg

        print_info_message<span class="token punctuation">(</span>
            <span class="token string">'Running epoch {} with learning rates: base_net {:.6f}, segment_net {:.6f}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> lr_base<span class="token punctuation">,</span> lr_seg<span class="token punctuation">)</span><span class="token punctuation">)</span>
        miou_train<span class="token punctuation">,</span> train_loss <span class="token operator">=</span> train<span class="token punctuation">(</span>model<span class="token punctuation">,</span> train_loader<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> criterion<span class="token punctuation">,</span> seg_classes<span class="token punctuation">,</span> epoch<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span>
        miou_val<span class="token punctuation">,</span> val_loss <span class="token operator">=</span> val<span class="token punctuation">(</span>model<span class="token punctuation">,</span> val_loader<span class="token punctuation">,</span> criterion<span class="token punctuation">,</span> seg_classes<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span>
        
        <span class="token comment"># write txtfile</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'epoch, miou_val, val_loss'</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'{},{:.2f}, {:.6f}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> miou_val<span class="token punctuation">,</span> val_loss<span class="token punctuation">)</span><span class="token punctuation">)</span>
        txt_outfile<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'{},{:.2f}, {:.6f}\n'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> miou_val<span class="token punctuation">,</span> val_loss<span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># remember best miou and save checkpoint</span>
        is_best <span class="token operator">=</span> miou_val <span class="token operator">&gt;</span> best_miou
        best_miou <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span>miou_val<span class="token punctuation">,</span> best_miou<span class="token punctuation">)</span>

        weights_dict <span class="token operator">=</span> model<span class="token punctuation">.</span>module<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> device <span class="token operator">==</span> <span class="token string">'cuda'</span> <span class="token keyword">else</span> model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span>
        save_checkpoint<span class="token punctuation">(</span><span class="token punctuation">{</span>
            <span class="token string">'epoch'</span><span class="token punctuation">:</span> epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span>
            <span class="token string">'arch'</span><span class="token punctuation">:</span> args<span class="token punctuation">.</span>model<span class="token punctuation">,</span>
            <span class="token string">'state_dict'</span><span class="token punctuation">:</span> weights_dict<span class="token punctuation">,</span>
            <span class="token string">'best_miou'</span><span class="token punctuation">:</span> best_miou<span class="token punctuation">,</span>
            <span class="token string">'optimizer'</span><span class="token punctuation">:</span> optimizer<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">}</span><span class="token punctuation">,</span> is_best<span class="token punctuation">,</span> args<span class="token punctuation">.</span>savedir<span class="token punctuation">,</span> extra_info_ckpt<span class="token punctuation">)</span>

        writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">'Segmentation/LR/base'</span><span class="token punctuation">,</span> <span class="token builtin">round</span><span class="token punctuation">(</span>lr_base<span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">,</span> epoch<span class="token punctuation">)</span>
        writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">'Segmentation/LR/seg'</span><span class="token punctuation">,</span> <span class="token builtin">round</span><span class="token punctuation">(</span>lr_seg<span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">,</span> epoch<span class="token punctuation">)</span>
        writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">'Segmentation/Loss/train'</span><span class="token punctuation">,</span> train_loss<span class="token punctuation">,</span> epoch<span class="token punctuation">)</span>
        writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">'Segmentation/Loss/val'</span><span class="token punctuation">,</span> val_loss<span class="token punctuation">,</span> epoch<span class="token punctuation">)</span>
        writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">'Segmentation/mIOU/train'</span><span class="token punctuation">,</span> miou_train<span class="token punctuation">,</span> epoch<span class="token punctuation">)</span>
        writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">'Segmentation/mIOU/val'</span><span class="token punctuation">,</span> miou_val<span class="token punctuation">,</span> epoch<span class="token punctuation">)</span>
        writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">'Segmentation/Complexity/Flops'</span><span class="token punctuation">,</span> best_miou<span class="token punctuation">,</span> math<span class="token punctuation">.</span>ceil<span class="token punctuation">(</span>flops<span class="token punctuation">)</span><span class="token punctuation">)</span>
        writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">'Segmentation/Complexity/Params'</span><span class="token punctuation">,</span> best_miou<span class="token punctuation">,</span> math<span class="token punctuation">.</span>ceil<span class="token punctuation">(</span>num_params<span class="token punctuation">)</span><span class="token punctuation">)</span>

    writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
    txt_outfile<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">&quot;__main__&quot;</span><span class="token punctuation">:</span>
    <span class="token keyword">from</span> commons<span class="token punctuation">.</span>general_details <span class="token keyword">import</span> segmentation_models<span class="token punctuation">,</span> segmentation_schedulers<span class="token punctuation">,</span> segmentation_loss_fns<span class="token punctuation">,</span> \
        segmentation_datasets

    parser <span class="token operator">=</span> argparse<span class="token punctuation">.</span>ArgumentParser<span class="token punctuation">(</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--resume'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">str</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'path to checkpoint to resume from'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--workers'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'number of data loading workers'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--ignore-idx'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">255</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Index or label to be ignored during training'</span><span class="token punctuation">)</span>

    <span class="token comment"># model details</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--freeze-bn'</span><span class="token punctuation">,</span> action<span class="token operator">=</span><span class="token string">'store_true'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Freeze BN params or not'</span><span class="token punctuation">)</span>

    <span class="token comment"># dataset and result directories</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--dataset'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">str</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">'pascal'</span><span class="token punctuation">,</span> choices<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'custom'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Datasets'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--data-path'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">str</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'dataset path'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--coco-path'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">str</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'MS COCO dataset path'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--savedir'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">str</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">'./results_segmentation'</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Location to save the results'</span><span class="token punctuation">)</span>
    <span class="token comment">## only for cityscapes</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--coarse'</span><span class="token punctuation">,</span> action<span class="token operator">=</span><span class="token string">'store_true'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Want to use coarse annotations or not'</span><span class="token punctuation">)</span>

    <span class="token comment"># scheduler details</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--scheduler'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">'hybrid'</span><span class="token punctuation">,</span> choices<span class="token operator">=</span>segmentation_schedulers<span class="token punctuation">,</span>
                        <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Learning rate scheduler (fixed, clr, poly)'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--epochs'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'num of training epochs'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--step-size'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">51</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'steps at which lr should be decreased'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--lr'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">9e</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">float</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'initial learning rate'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--lr-mult'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">10.0</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">float</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'initial learning rate'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--lr-decay'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">float</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'factor by which lr should be decreased'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--momentum'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">float</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'momentum'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--weight-decay'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">4e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">float</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'weight decay (default: 4e-5)'</span><span class="token punctuation">)</span>
    <span class="token comment"># for Polynomial LR</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--power'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">float</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'power factor for Polynomial LR'</span><span class="token punctuation">)</span>

    <span class="token comment"># for hybrid LR</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--clr-max'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">61</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Max number of epochs for cylic LR before '</span>
                                  <span class="token string">'changing last cycle to linear'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--cycle-len'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Duration of cycle'</span><span class="token punctuation">)</span>

    <span class="token comment"># input details</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--batch-size'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">40</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'list of batch sizes'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--crop-size'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> nargs<span class="token operator">=</span><span class="token string">'+'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                        <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'list of image crop sizes, with each item storing the crop size (should be a tuple).'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--loss-type'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">'ce'</span><span class="token punctuation">,</span> choices<span class="token operator">=</span>segmentation_loss_fns<span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Loss function (ce or miou)'</span><span class="token punctuation">)</span>

    <span class="token comment"># model related params</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--s'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">float</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">2.0</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Factor by which channels will be scaled'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--model'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">'espnet'</span><span class="token punctuation">,</span> choices<span class="token operator">=</span>segmentation_models<span class="token punctuation">,</span>
                        <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Which model? basic= basic CNN model, res=resnet style)'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--channels'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Input channels'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--num-classes'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span>
                        <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'ImageNet classes. Required for loading the base network'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--finetune'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">str</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Finetune the segmentation model'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--model-width'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Model width'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--model-height'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Model height'</span><span class="token punctuation">)</span>

    args <span class="token operator">=</span> parser<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span>

    random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">1882</span><span class="token punctuation">)</span>
    torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">1882</span><span class="token punctuation">)</span>
        
    <span class="token keyword">if</span> args<span class="token punctuation">.</span>dataset <span class="token operator">==</span> <span class="token string">'custom'</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> args<span class="token punctuation">.</span>crop_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">512</span><span class="token punctuation">:</span>
            args<span class="token punctuation">.</span>scale <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">0.25</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span>
        <span class="token keyword">elif</span> args<span class="token punctuation">.</span>crop_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">1024</span><span class="token punctuation">:</span>
            args<span class="token punctuation">.</span>scale <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">0.35</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">)</span>
        <span class="token keyword">elif</span> args<span class="token punctuation">.</span>crop_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">2048</span><span class="token punctuation">:</span>
            args<span class="token punctuation">.</span>scale <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">2.0</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            print_error_message<span class="token punctuation">(</span><span class="token string">'Select image size from 512x256, 1024x512, 2048x1024'</span><span class="token punctuation">)</span>
        print_log_message<span class="token punctuation">(</span><span class="token string">'Using scale = ({}, {})'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>scale<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> args<span class="token punctuation">.</span>scale<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        print_error_message<span class="token punctuation">(</span><span class="token string">'{} dataset not yet supported'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> <span class="token keyword">not</span> args<span class="token punctuation">.</span>finetune<span class="token punctuation">:</span>
        <span class="token keyword">from</span> model<span class="token punctuation">.</span>weight_locations<span class="token punctuation">.</span>classification <span class="token keyword">import</span> model_weight_map

        weight_file_key <span class="token operator">=</span> <span class="token string">'{}_{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>model<span class="token punctuation">,</span> args<span class="token punctuation">.</span>s<span class="token punctuation">)</span>
        <span class="token keyword">assert</span> weight_file_key <span class="token keyword">in</span> model_weight_map<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'{} does not exist'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>weight_file_key<span class="token punctuation">)</span>
        args<span class="token punctuation">.</span>weights <span class="token operator">=</span> model_weight_map<span class="token punctuation">[</span>weight_file_key<span class="token punctuation">]</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        args<span class="token punctuation">.</span>weights <span class="token operator">=</span> <span class="token string">''</span>
        <span class="token keyword">assert</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>isfile<span class="token punctuation">(</span>args<span class="token punctuation">.</span>finetune<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'{} weight file does not exist'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>finetune<span class="token punctuation">)</span>

    <span class="token keyword">assert</span> <span class="token builtin">len</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>crop_size<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token string">'crop-size argument must contain 2 values'</span>
    <span class="token keyword">assert</span> args<span class="token punctuation">.</span>data_path <span class="token operator">!=</span> <span class="token string">''</span><span class="token punctuation">,</span> <span class="token string">'Dataset path is an empty string. Please check.'</span>

    args<span class="token punctuation">.</span>crop_size <span class="token operator">=</span> <span class="token builtin">tuple</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>crop_size<span class="token punctuation">)</span>
    timestr <span class="token operator">=</span> time<span class="token punctuation">.</span>strftime<span class="token punctuation">(</span><span class="token string">&quot;%Y%m%d-%H%M%S&quot;</span><span class="token punctuation">)</span>
    args<span class="token punctuation">.</span>savedir <span class="token operator">=</span> <span class="token string">'{}/model_{}_{}/s_{}_sch_{}_loss_{}_res_{}_sc_{}_{}/{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>savedir<span class="token punctuation">,</span> args<span class="token punctuation">.</span>model<span class="token punctuation">,</span> args<span class="token punctuation">.</span>dataset<span class="token punctuation">,</span> args<span class="token punctuation">.</span>s<span class="token punctuation">,</span>
                               args<span class="token punctuation">.</span>scheduler<span class="token punctuation">,</span>
                               args<span class="token punctuation">.</span>loss_type<span class="token punctuation">,</span> args<span class="token punctuation">.</span>crop_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> args<span class="token punctuation">.</span>scale<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> args<span class="token punctuation">.</span>scale<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> timestr<span class="token punctuation">)</span>
    main<span class="token punctuation">(</span>args<span class="token punctuation">)</span>
</code></pre></div><h3 id="オリジナルデータの学習-第1段階"><a href="#オリジナルデータの学習-第1段階" class="header-anchor">#</a> オリジナルデータの学習(第1段階)</h3> <p>最初の段階では、低解像度の画像を入力として使用して、より大きなバッチサイズに合わせることができます。<br>
モデルは，<code>./results_segmentation/human_city</code>に出力されます．<br> <code>--num-classes</code>でクラス数を指定することを忘れずに．</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token operator">%</span>cd <span class="token operator">/</span>content<span class="token operator">/</span>drive<span class="token operator">/</span>My\ Drive<span class="token operator">/</span>segmentation<span class="token operator">/</span>EdgeNets

<span class="token comment"># original dataset</span>
!CUDA_VISIBLE_DEVICES<span class="token operator">=</span><span class="token number">0</span> python custom_train_segmentation<span class="token punctuation">.</span>py \
                        <span class="token operator">-</span><span class="token operator">-</span>model espnetv2 <span class="token operator">-</span><span class="token operator">-</span>s <span class="token number">2.0</span> \
                        <span class="token operator">-</span><span class="token operator">-</span>dataset custom \
                        <span class="token operator">-</span><span class="token operator">-</span>savedir <span class="token punctuation">.</span><span class="token operator">/</span>results_segmentation<span class="token operator">/</span>human_city \
                        <span class="token operator">-</span><span class="token operator">-</span>data<span class="token operator">-</span>path <span class="token punctuation">.</span><span class="token operator">/</span>vision_datasets<span class="token operator">/</span>human_city<span class="token operator">/</span> \
                        <span class="token operator">-</span><span class="token operator">-</span>batch<span class="token operator">-</span>size <span class="token number">25</span> \
                        <span class="token operator">-</span><span class="token operator">-</span>crop<span class="token operator">-</span>size <span class="token number">512</span> <span class="token number">256</span> \
                        <span class="token operator">-</span><span class="token operator">-</span>num<span class="token operator">-</span>classes <span class="token number">2</span> \
                        <span class="token operator">-</span><span class="token operator">-</span>lr <span class="token number">0.009</span> <span class="token operator">-</span><span class="token operator">-</span>scheduler hybrid <span class="token operator">-</span><span class="token operator">-</span>clr<span class="token operator">-</span><span class="token builtin">max</span> <span class="token number">61</span> <span class="token operator">-</span><span class="token operator">-</span>epochs <span class="token number">50</span>
</code></pre></div><h3 id="オリジナルデータの学習-第2段階"><a href="#オリジナルデータの学習-第2段階" class="header-anchor">#</a> オリジナルデータの学習(第2段階)</h3> <p>第2段階では、バッチ正規化レイヤーをフリーズしてから、わずかに高い画像解像度で微調整します。<br>
--finetuneでは，第1段階で出力した学習モデルを指定します．<br>
ここでも，<code>--num-classes</code>でクラス数を指定することを忘れずに．</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># original dataset</span>
!CUDA_VISIBLE_DEVICES<span class="token operator">=</span><span class="token number">0</span> python custom_train_segmentation<span class="token punctuation">.</span>py \
                        <span class="token operator">-</span><span class="token operator">-</span>model espnetv2 <span class="token operator">-</span><span class="token operator">-</span>s <span class="token number">2.0</span> \
                        <span class="token operator">-</span><span class="token operator">-</span>dataset custom \
                        <span class="token operator">-</span><span class="token operator">-</span>savedir <span class="token punctuation">.</span><span class="token operator">/</span>results_segmentation<span class="token operator">/</span>human_city0318 \
                        <span class="token operator">-</span><span class="token operator">-</span>data<span class="token operator">-</span>path <span class="token punctuation">.</span><span class="token operator">/</span>vision_datasets<span class="token operator">/</span>human_city<span class="token operator">/</span> \
                        <span class="token operator">-</span><span class="token operator">-</span>batch<span class="token operator">-</span>size <span class="token number">6</span> \
                        <span class="token operator">-</span><span class="token operator">-</span>crop<span class="token operator">-</span>size <span class="token number">1024</span> <span class="token number">512</span> \
                        <span class="token operator">-</span><span class="token operator">-</span>lr <span class="token number">0.005</span> <span class="token operator">-</span><span class="token operator">-</span>scheduler hybrid <span class="token operator">-</span><span class="token operator">-</span>clr<span class="token operator">-</span><span class="token builtin">max</span> <span class="token number">61</span>\
                        <span class="token operator">-</span><span class="token operator">-</span>epochs <span class="token number">25</span> \
                        <span class="token operator">-</span><span class="token operator">-</span>freeze<span class="token operator">-</span>bn \
                        <span class="token operator">-</span><span class="token operator">-</span>num<span class="token operator">-</span>classes <span class="token number">2</span> \
                        <span class="token operator">-</span><span class="token operator">-</span>finetune <span class="token punctuation">.</span><span class="token operator">/</span>results_segmentation<span class="token operator">/</span>human_city<span class="token operator">/</span>model_espnetv2_custom<span class="token operator">/</span>s_2<span class="token punctuation">.</span>0_sch_hybrid_loss_ce_res_512_sc_0<span class="token punctuation">.</span>25_0<span class="token punctuation">.</span><span class="token number">5</span><span class="token operator">/</span>＊＊＊＊<span class="token operator">/</span>espnetv2_2<span class="token punctuation">.</span>0_512_best<span class="token punctuation">.</span>pth

</code></pre></div><h2 id="オリジナルデータモデルのテスト"><a href="#オリジナルデータモデルのテスト" class="header-anchor">#</a> オリジナルデータモデルのテスト</h2> <h3 id="テストの実行"><a href="#テストの実行" class="header-anchor">#</a> テストの実行</h3> <p>オリジナルデータで学習したモデルで/sample_dataの画像でsegmentationを実施しました．<br>
以下のコマンドで実行できます．</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token operator">%</span>cd <span class="token operator">/</span>content<span class="token operator">/</span>drive<span class="token operator">/</span>My\ Drive<span class="token operator">/</span>segmentation<span class="token operator">/</span>EdgeNets
!CUDA_VISIBLE_DEVICES<span class="token operator">=</span><span class="token number">0</span> python custom_test_segmentation<span class="token punctuation">.</span>py \
                        <span class="token operator">-</span><span class="token operator">-</span>model espnetv2 \
                        <span class="token operator">-</span><span class="token operator">-</span>s <span class="token number">2.0</span> \
                        <span class="token operator">-</span><span class="token operator">-</span>dataset custom \
                        <span class="token operator">-</span><span class="token operator">-</span>data<span class="token operator">-</span>path <span class="token punctuation">.</span><span class="token operator">/</span>sample_images<span class="token operator">/</span> \
                        <span class="token operator">-</span><span class="token operator">-</span>split custom \
                        <span class="token operator">-</span><span class="token operator">-</span>im<span class="token operator">-</span>size <span class="token number">1024</span> <span class="token number">512</span>\
                        <span class="token operator">-</span><span class="token operator">-</span>num<span class="token operator">-</span>classes <span class="token number">2</span> \
                        <span class="token operator">-</span><span class="token operator">-</span>weights<span class="token operator">-</span>test <span class="token punctuation">.</span><span class="token operator">/</span>results_segmentation<span class="token operator">/</span>human_city0318<span class="token operator">/</span>model_espnetv2_custom<span class="token operator">/</span>s_2<span class="token punctuation">.</span>0_sch_hybrid_loss_ce_res_1024_sc_0<span class="token punctuation">.</span>35_1<span class="token punctuation">.</span><span class="token number">0</span><span class="token operator">/</span>＊＊＊＊<span class="token operator">/</span>espnetv2_2<span class="token punctuation">.</span>0_1024_best<span class="token punctuation">.</span>pth \
                        <span class="token operator">-</span><span class="token operator">-</span>savedir<span class="token operator">-</span>name sample_images_org
</code></pre></div><h3 id="テスト結果"><a href="#テスト結果" class="header-anchor">#</a> テスト結果</h3> <p>Cityscapesデータセットの人は立っている状態ばかりなので，立っている人は着色されていますが，座っている人は着色されませんでした．<br>
学習データに入っていないので当然ですが，このようにはっきり形となって出ると，面白いです．<br> <br>
立っている人の画像<br> <img alt="" data-src="/image/org_seg1.png" loading="lazy" class="lazy"><br> <br>
座っている人の画像<br> <img alt="" data-src="/image/org_seg2.png" loading="lazy" class="lazy"></p> <h2 id="まとめ"><a href="#まとめ" class="header-anchor">#</a> まとめ</h2> <p>本稿ではCityscapesデータセットから人のみを抽出した仮のオリジナルデータで学習を実施しました．<br>
次回から，セグメンテーションしてクロマキー合成を実施したいです．</p> <h2 id="参考サイト"><a href="#参考サイト" class="header-anchor">#</a> 参考サイト</h2> <p><a href="https://github.com/sacmehta/EdgeNets" target="_blank" rel="noopener noreferrer">sacmehta/EdgeNets<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a><br> <a href="https://github.com/sacmehta/EdgeNets/blob/master/README_Segmentation.md" target="_blank" rel="noopener noreferrer">sacmehta/EdgeNets/README_Segmentation.md<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> <a href="https://qiita.com/tokyokuma/items/37b1370ea7c84399fbb9" target="_blank" rel="noopener noreferrer">ESPNetで自作データセットを学習してセグメンテーション<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a><br> <a href="https://rikoubou.hatenablog.com/entry/2019/02/21/190310" target="_blank" rel="noopener noreferrer">【python/OpenCV】画像の特定の色を抽出する方法<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a><br> <a href="https://qiita.com/pashango2/items/d6dda5f07109ee5b6163" target="_blank" rel="noopener noreferrer">PIL/Pillowで画像の色を高速に置換する<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a><br> <a href="http://ni4muraano.hatenablog.com/entry/2017/05/15/000000" target="_blank" rel="noopener noreferrer">【OpenCV】 forループを使わずに指定した色を別の色に変更する<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p><a href="https://px.a8.net/svt/ejp?a8mat=3HBXCY+4DRW36+50+2HM5Z5" rel="nofollow"><img border="0" width="1000" height="124" alt="" src="https://www27.a8.net/svt/bgt?aid=210508450265&amp;wid=001&amp;eno=01&amp;mid=s00000000018015052000&amp;mc=1"></a><img border="0" width="1" height="1" src="https://www10.a8.net/0.gif?a8mat=3HBXCY+4DRW36+50+2HM5Z5" alt=""></p> <p><a href="https://px.a8.net/svt/ejp?a8mat=3HIN6N+3YAMCY+CO4+6BMG1" rel="nofollow"><img border="0" width="1000" height="124" alt="" src="https://www23.a8.net/svt/bgt?aid=210821855239&amp;wid=001&amp;eno=01&amp;mid=s00000001642001062000&amp;mc=1"></a><img border="0" width="1" height="1" src="https://www17.a8.net/0.gif?a8mat=3HIN6N+3YAMCY+CO4+6BMG1" alt=""></p> <p><a href="https://px.a8.net/svt/ejp?a8mat=3HIN6N+7FBNEA+4AQ0+5YJRM" rel="nofollow">全国630店舗以上！もみほぐし・足つぼ・ハンドリフレ・クイックヘッドのリラクゼーション店【りらくる】</a><img border="0" width="1" height="1" src="https://www15.a8.net/0.gif?a8mat=3HIN6N+7FBNEA+4AQ0+5YJRM" alt=""></p> <!----></div> <div class="content-time" data-v-c4dc5dfa><time datetime="3/23/2021, 12:00:00 AM" class="time-text" data-v-c4dc5dfa>Create Time: 3/23/2021, 12:00:00 AM
    </time> <time datetime="6/14/2022, 6:24:05 AM" class="time-text" data-v-c4dc5dfa>Last Updated: 6/14/2022, 6:24:05 AM
    </time></div></article> <section class="flex-xb main info-nav" data-v-203269c1 data-v-2602fa21><a href="/posts/segmentation04.html" class="flex-xb nav-item" data-v-203269c1><div class="flex-xcc item-img" data-v-203269c1><img data-src="https://www.hamlet-engineer.com/image/chromakey.jpg" loading="lazy" alt="Python + ESPNetでクロマキー合成を実施する" class="img lazy" data-v-203269c1></div> <article class="flex-ysc item-content" data-v-203269c1><h2 class="content-title" data-v-203269c1>Python + ESPNetでクロマキー合成を実施する</h2> <div class="content" data-v-203269c1><p>セマンティックセグメンテーションの中で軽いモデルであるESPNetv2の実装を目指し，Python + ESPNetで学習した人を検出するセマンティックセグメンテーションのモデルを使って，クロマキー合成を実施します．<br></p>
</div></article></a> <a href="/posts/color_replace.html" class="flex-xb nav-item" data-v-203269c1><div class="flex-xcc item-img" data-v-203269c1><img data-src="https://www.hamlet-engineer.com/image/color_replace.png" loading="lazy" alt="Python, OpenCVで指定した色の抽出と別の色への置換を実装する" class="img lazy" data-v-203269c1></div> <article class="flex-ysc item-content" data-v-203269c1><h2 class="content-title" data-v-203269c1>Python, OpenCVで指定した色の抽出と別の色への置換を実装する</h2> <div class="content" data-v-203269c1><p>Python, OpenCVで指定した色の抽出と別の色への置換を実装します．<br>
本稿では，Cityscapesデータセットのカラーマスキング画像の内，人だけを抽出し，白色に置換します．</p>
</div></article></a></section> <!----></section></section> <footer class="footer" data-v-8dceedee data-v-98a81704><nav class="link-list" data-v-8dceedee><a href="https://twitter.com/hirasu1231" target="_blank" rel="noopener noreferrer" class="list-item" data-v-8dceedee>Twitter</a><a href="https://github.com/hirasu1231" target="_blank" rel="noopener noreferrer" class="list-item" data-v-8dceedee>Github</a></nav> <a href="/" class="copyright router-link-active" data-v-8dceedee>ハムレット型エンジニアのカンニングノート © 2023</a></footer></section><div class="global-ui"><!----><!----></div></div>
    <script src="/assets/js/app.78c225c3.js" defer></script><script src="/assets/js/146.3a75fc9d.js" defer></script>
  </body>
</html>
