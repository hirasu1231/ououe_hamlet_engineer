<!DOCTYPE html>
<html lang="ja-jp">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Python + ESPNetでクロマキー合成を実施する | ハムレット型エンジニアのカンニングノート</title>
    <meta name="generator" content="VuePress 1.8.2">
    <script data-ad-client="ca-pub-2263820744635038" async="true" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <meta name="description" content="Python + ESPNetで学習した人を検出するセマンティックセグメンテーションのモデルを使って，クロマキー合成を実施します．">
    <meta property="article:published_time" content="2021-03-24T00:00:00.000Z">
    <meta property="article:modified_time" content="2021-04-12T09:12:47.000Z">
    <meta property="og:site_name" content="ハムレット型エンジニアのカンニングノート">
    <meta property="og:title" content="Python + ESPNetでクロマキー合成を実施する">
    <meta property="og:description" content="Python + ESPNetで学習した人を検出するセマンティックセグメンテーションのモデルを使って，クロマキー合成を実施します．">
    <meta property="og:type" content="article">
    <meta property="og:url" content="/posts/segmentation04.html">
    <meta property="og:image" content="https://www.hamlet-engineer.com/image/chromakey.jpg">
    <meta name="twitter:title" content="Python + ESPNetでクロマキー合成を実施する">
    <meta name="twitter:description" content="Python + ESPNetで学習した人を検出するセマンティックセグメンテーションのモデルを使って，クロマキー合成を実施します．">
    <meta name="twitter:url" content="/posts/segmentation04.html">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:image" content="https://www.hamlet-engineer.com/image/chromakey.jpg">
    <meta name="twitter:label2" content="Filed under">
    <meta name="twitter:data2" content="Python, Jupyter, ESPNet, セマンティックセグメンテーション">
    <meta property="article:tag" content="Python">
    <meta name="google-site-verification" content="BDXGk8FJfikB_I6Pyxv35Zc87jBMziCgRMvmpNDpdYA">
    
    <link rel="preload" href="/assets/css/0.styles.acab35d9.css" as="style"><link rel="preload" href="/assets/js/app.0625ac58.js" as="script"><link rel="preload" href="/assets/js/28.294e8143.js" as="script"><link rel="prefetch" href="/assets/js/10.4d2566a3.js"><link rel="prefetch" href="/assets/js/11.8bb446ed.js"><link rel="prefetch" href="/assets/js/12.8bb3bbb4.js"><link rel="prefetch" href="/assets/js/13.d3b36262.js"><link rel="prefetch" href="/assets/js/14.1ce3a88a.js"><link rel="prefetch" href="/assets/js/15.7dcb2941.js"><link rel="prefetch" href="/assets/js/16.c5a72513.js"><link rel="prefetch" href="/assets/js/17.34114beb.js"><link rel="prefetch" href="/assets/js/18.2b96aefe.js"><link rel="prefetch" href="/assets/js/19.7e2619ca.js"><link rel="prefetch" href="/assets/js/2.119cf6e6.js"><link rel="prefetch" href="/assets/js/20.9c9c197e.js"><link rel="prefetch" href="/assets/js/21.248ec9ca.js"><link rel="prefetch" href="/assets/js/22.194b51e6.js"><link rel="prefetch" href="/assets/js/23.94530fc8.js"><link rel="prefetch" href="/assets/js/24.e5249dd4.js"><link rel="prefetch" href="/assets/js/25.9958c189.js"><link rel="prefetch" href="/assets/js/26.7cab6cd7.js"><link rel="prefetch" href="/assets/js/27.09d13609.js"><link rel="prefetch" href="/assets/js/29.2152ec81.js"><link rel="prefetch" href="/assets/js/3.b3caa0ed.js"><link rel="prefetch" href="/assets/js/30.dfb81c6d.js"><link rel="prefetch" href="/assets/js/31.ca9deb9a.js"><link rel="prefetch" href="/assets/js/32.55c12eab.js"><link rel="prefetch" href="/assets/js/33.6dc10eab.js"><link rel="prefetch" href="/assets/js/34.37b5ee8a.js"><link rel="prefetch" href="/assets/js/35.b2e5f8ee.js"><link rel="prefetch" href="/assets/js/36.bcefc7ae.js"><link rel="prefetch" href="/assets/js/37.03a784c8.js"><link rel="prefetch" href="/assets/js/38.9cce893c.js"><link rel="prefetch" href="/assets/js/39.1b1cdc63.js"><link rel="prefetch" href="/assets/js/4.81467042.js"><link rel="prefetch" href="/assets/js/5.95e08d49.js"><link rel="prefetch" href="/assets/js/6.5cdd951b.js"><link rel="prefetch" href="/assets/js/7.55235a20.js"><link rel="prefetch" href="/assets/js/8.af26ed32.js"><link rel="prefetch" href="/assets/js/9.ef598a3b.js">
    <link rel="stylesheet" href="/assets/css/0.styles.acab35d9.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><section id="global-layout" data-v-98a81704><header class="header" data-v-00466d8e data-v-98a81704><div class="header-navbar" data-v-00466d8e><div class="flex-xbc main header-nav" data-v-00466d8e><div class="nav-link" data-v-00466d8e><a href="/" class="inblock link-logo router-link-active" data-v-00466d8e><img data-src="/logo.png" loading="lazy" alt="logo" class="logo-img lazy" data-v-00466d8e></a> <nav class="link-list" data-v-00466d8e><a href="/" class="list-item router-link-active" data-v-00466d8e>ホーム</a><a href="/about/" class="list-item" data-v-00466d8e>ページ集</a><a href="/posts/" class="list-item router-link-active" data-v-00466d8e>技術</a><a href="/mental/" class="list-item" data-v-00466d8e>メンタル</a><a href="/other/" class="list-item" data-v-00466d8e>その他</a><a href="/tag/" class="list-item" data-v-00466d8e>タグ</a><a href="/category/" class="list-item" data-v-00466d8e>カテゴリ</a><a href="https://twitter.com/hirasu1231" target="_blank" rel="noopener noreferrer" class="list-item" data-v-00466d8e>筆者</a></nav></div> <div class="search-box" data-v-00466d8e><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div></div></div> </header> <!----> <section class="page" data-v-98a81704 data-v-98a81704><section class="info no-bg" data-v-2602fa21><article class="main info-content" data-v-405d0d6c data-v-2602fa21><div class="content-header" data-v-405d0d6c><h1 class="header-title" data-v-405d0d6c>Python + ESPNetでクロマキー合成を実施する</h1></div> <div class="flex-wcc content-tag" data-v-405d0d6c><div class="inblock tag-list" data-v-405d0d6c><a href="/category/Python/" class="tag-text" data-v-405d0d6c>Python
      </a></div> <span class="tag-space" data-v-405d0d6c>/</span> <div class="inblock tag-list" data-v-405d0d6c><a href="/tag/Python/" class="tag-text" data-v-405d0d6c>Python
      </a><a href="/tag/Jupyter/" class="tag-text" data-v-405d0d6c>Jupyter
      </a><a href="/tag/ESPNet/" class="tag-text" data-v-405d0d6c>ESPNet
      </a><a href="/tag/セマンティックセグメンテーション/" class="tag-text" data-v-405d0d6c>セマンティックセグメンテーション
      </a></div></div> <div class="content content__default" data-v-405d0d6c><p>セマンティックセグメンテーションの中で軽いモデルであるESPNetv2の実装を目指し，Python + ESPNetで学習した人を検出するセマンティックセグメンテーションのモデルを使って，クロマキー合成を実施します．<br></p> <p>今回はGoogle ColabとGoogle Driveを連携させて，notebook形式で実行してます．<br></p> <blockquote><p>Google Colaboratory（以下Google Colab）は、Google社が無料で提供している機械学習の教育や研究用の開発環境です。開発環境はJupyter Notebookに似たインターフェースを持ち、Pythonの主要なライブラリがプリインストールされています。<br>
引用元：<a href="https://interface.cqpub.co.jp/ail01/" target="_blank" rel="noopener noreferrer">Google Colabの使い方<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p></blockquote> <p>最終的に，人以外の背景を着色して，zoomのバーチャル背景機能のようなクロマキー合成を実装したいです．<br> <img alt="" data-src="/image/zoom.jpg" loading="lazy" class="lazy"></p> <h2 id="作業ディレクトリのファイル構成"><a href="#作業ディレクトリのファイル構成" class="header-anchor">#</a> 作業ディレクトリのファイル構成</h2> <p>プロジェクトディレクトリはsegmentationとしています．度々，省略しています．</p> <div class="language- extra-class"><pre class="language-text"><code>segmentation
├── /EdgeNets
│   ├── /results_segmentation &lt;- モデルの出力ディレクトリ
│   │   └── /human_city
│   ├── /result_images &lt;- 着色画像の出力ディレクトリ
│   │   └── /sample_images_org
│   │       ├── sample3.png
│   │       ├── mask_sample3.png
│   │       └── (省略)
│   ├── /sample_images &lt;- サンプル画像
│   │   ├── sample3.png
│   │   └── (省略)
│   ├── grass.jpg &lt;- 背景画像
│   ├── chromakey.jpg &lt;- クロマキー合成画像
│   ├── train_segmentation.py
│   ├── test_segmentation.py
│   ├── custom_test_segmentation.py
│   ├── custom_train_segmentation.py
│   └── (省略)
└── ESPNetv2.ipynb &lt;- 実行用ノートブック
</code></pre></div><h2 id="クロマキー合成"><a href="#クロマキー合成" class="header-anchor">#</a> クロマキー合成</h2> <h3 id="マスク画像の生成"><a href="#マスク画像の生成" class="header-anchor">#</a> マスク画像の生成</h3> <p>クロマキー合成をするには，まず人だけが着色されているマスク画像を出力する必要があります．<br>
そこでマスク画像も出力されるように，<code>custom_test_segmentation.py</code>を改良します．</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># custom_test_segmentation.py</span>
<span class="token comment"># 60行目から68行目付近</span>
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> glob
<span class="token keyword">import</span> os
<span class="token keyword">from</span> argparse <span class="token keyword">import</span> ArgumentParser
<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image
<span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">import</span> functional <span class="token keyword">as</span> F
<span class="token keyword">from</span> tqdm <span class="token keyword">import</span> tqdm
<span class="token keyword">from</span> utilities<span class="token punctuation">.</span>print_utils <span class="token keyword">import</span> <span class="token operator">*</span>
<span class="token keyword">from</span> transforms<span class="token punctuation">.</span>classification<span class="token punctuation">.</span>data_transforms <span class="token keyword">import</span> MEAN<span class="token punctuation">,</span> STD
<span class="token keyword">from</span> utilities<span class="token punctuation">.</span>utils <span class="token keyword">import</span> model_parameters<span class="token punctuation">,</span> compute_flops

<span class="token comment"># ===========================================</span>
__author__ <span class="token operator">=</span> <span class="token string">&quot;Sachin Mehta&quot;</span>
__license__ <span class="token operator">=</span> <span class="token string">&quot;MIT&quot;</span>
__maintainer__ <span class="token operator">=</span> <span class="token string">&quot;Sachin Mehta&quot;</span>
<span class="token comment"># ============================================</span>

IMAGE_EXTENSIONS <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'.jpg'</span><span class="token punctuation">,</span> <span class="token string">'.png'</span><span class="token punctuation">,</span> <span class="token string">'.jpeg'</span><span class="token punctuation">]</span>

<span class="token keyword">def</span> <span class="token function">data_transform</span><span class="token punctuation">(</span>img<span class="token punctuation">,</span> im_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
    img <span class="token operator">=</span> img<span class="token punctuation">.</span>resize<span class="token punctuation">(</span>im_size<span class="token punctuation">,</span> Image<span class="token punctuation">.</span>BILINEAR<span class="token punctuation">)</span>
    img <span class="token operator">=</span> F<span class="token punctuation">.</span>to_tensor<span class="token punctuation">(</span>img<span class="token punctuation">)</span>  <span class="token comment"># convert to tensor (values between 0 and 1)</span>
    img <span class="token operator">=</span> F<span class="token punctuation">.</span>normalize<span class="token punctuation">(</span>img<span class="token punctuation">,</span> MEAN<span class="token punctuation">,</span> STD<span class="token punctuation">)</span>  <span class="token comment"># normalize the tensor</span>
    <span class="token keyword">return</span> img


<span class="token keyword">def</span> <span class="token function">evaluate</span><span class="token punctuation">(</span>args<span class="token punctuation">,</span> model<span class="token punctuation">,</span> image_list<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token punctuation">:</span>
    im_size <span class="token operator">=</span> <span class="token builtin">tuple</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>im_size<span class="token punctuation">)</span>

    <span class="token comment"># get color map for dataset</span>
    <span class="token keyword">from</span> utilities<span class="token punctuation">.</span>color_map <span class="token keyword">import</span> VOCColormap
    cmap <span class="token operator">=</span> VOCColormap<span class="token punctuation">(</span>num_classes<span class="token operator">=</span>args<span class="token punctuation">.</span>num_classes<span class="token punctuation">)</span><span class="token punctuation">.</span>get_color_map_voc<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>cmap<span class="token punctuation">)</span>
    

    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> imgName <span class="token keyword">in</span> tqdm<span class="token punctuation">(</span><span class="token builtin">enumerate</span><span class="token punctuation">(</span>image_list<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        img <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>imgName<span class="token punctuation">)</span><span class="token punctuation">.</span>convert<span class="token punctuation">(</span><span class="token string">'RGB'</span><span class="token punctuation">)</span>
        img_clone <span class="token operator">=</span> img<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
        w<span class="token punctuation">,</span> h <span class="token operator">=</span> img<span class="token punctuation">.</span>size

        img <span class="token operator">=</span> data_transform<span class="token punctuation">(</span>img<span class="token punctuation">,</span> im_size<span class="token punctuation">)</span>
        img <span class="token operator">=</span> img<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment"># add a batch dimension</span>
        img <span class="token operator">=</span> img<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
        img_out <span class="token operator">=</span> model<span class="token punctuation">(</span>img<span class="token punctuation">)</span>
        img_out <span class="token operator">=</span> img_out<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment"># remove the batch dimension</span>
        img_out <span class="token operator">=</span> img_out<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>byte<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># get the label map</span>
        img_out <span class="token operator">=</span> img_out<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token operator">=</span><span class="token string">'cpu'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
        img_out <span class="token operator">=</span> Image<span class="token punctuation">.</span>fromarray<span class="token punctuation">(</span>img_out<span class="token punctuation">)</span>
        <span class="token comment"># resize to original size</span>
        img_out <span class="token operator">=</span> img_out<span class="token punctuation">.</span>resize<span class="token punctuation">(</span><span class="token punctuation">(</span>w<span class="token punctuation">,</span> h<span class="token punctuation">)</span><span class="token punctuation">,</span> Image<span class="token punctuation">.</span>NEAREST<span class="token punctuation">)</span>
        
        <span class="token comment"># pascal dataset accepts colored segmentations</span>
        img_out<span class="token punctuation">.</span>putpalette<span class="token punctuation">(</span>cmap<span class="token punctuation">)</span> <span class="token comment"># クラスごとに着色</span>
        img_out <span class="token operator">=</span> img_out<span class="token punctuation">.</span>convert<span class="token punctuation">(</span><span class="token string">'RGB'</span><span class="token punctuation">)</span>
        blended <span class="token operator">=</span> Image<span class="token punctuation">.</span>blend<span class="token punctuation">(</span>img_clone<span class="token punctuation">,</span> img_out<span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.7</span><span class="token punctuation">)</span>

        <span class="token comment"># save the segmentation blend image</span>
        name <span class="token operator">=</span> imgName<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'/'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
        img_extn <span class="token operator">=</span> imgName<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'.'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
        blend_name <span class="token operator">=</span> <span class="token string">'{}/{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>savedir<span class="token punctuation">,</span> name<span class="token punctuation">.</span>replace<span class="token punctuation">(</span>img_extn<span class="token punctuation">,</span> <span class="token string">'png'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        blended<span class="token punctuation">.</span>save<span class="token punctuation">(</span>blend_name<span class="token punctuation">)</span>
        <span class="token comment"># save the segmentation mask image</span>
        mask_name <span class="token operator">=</span> <span class="token string">'{}/mask_{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>savedir<span class="token punctuation">,</span> name<span class="token punctuation">.</span>replace<span class="token punctuation">(</span>img_extn<span class="token punctuation">,</span> <span class="token string">'png'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        img_out<span class="token punctuation">.</span>save<span class="token punctuation">(</span>mask_name<span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># read all the images in the folder</span>
    <span class="token keyword">if</span> args<span class="token punctuation">.</span>dataset <span class="token operator">==</span> <span class="token string">'custom'</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> args<span class="token punctuation">.</span>split <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token string">'val'</span><span class="token punctuation">,</span> <span class="token string">'test'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
            image_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
            <span class="token keyword">for</span> extn <span class="token keyword">in</span> IMAGE_EXTENSIONS<span class="token punctuation">:</span>
                image_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>args<span class="token punctuation">.</span>data_path<span class="token punctuation">,</span> args<span class="token punctuation">.</span>split<span class="token punctuation">,</span> <span class="token string">&quot;rgb&quot;</span><span class="token punctuation">,</span> <span class="token string">'*'</span> <span class="token operator">+</span> extn<span class="token punctuation">)</span>
                image_list <span class="token operator">=</span> image_list <span class="token operator">+</span>  glob<span class="token punctuation">.</span>glob<span class="token punctuation">(</span>image_path<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">50</span><span class="token punctuation">]</span>
            seg_classes <span class="token operator">=</span> args<span class="token punctuation">.</span>num_classes
            
        <span class="token keyword">elif</span> args<span class="token punctuation">.</span>split <span class="token operator">==</span> <span class="token string">'custom'</span><span class="token punctuation">:</span>
            image_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
            <span class="token keyword">for</span> extn <span class="token keyword">in</span> IMAGE_EXTENSIONS<span class="token punctuation">:</span>
                image_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>args<span class="token punctuation">.</span>data_path<span class="token punctuation">,</span> <span class="token string">'*'</span> <span class="token operator">+</span> extn<span class="token punctuation">)</span>
                image_list <span class="token operator">=</span> image_list <span class="token operator">+</span>  glob<span class="token punctuation">.</span>glob<span class="token punctuation">(</span>image_path<span class="token punctuation">)</span>
            seg_classes <span class="token operator">=</span> args<span class="token punctuation">.</span>num_classes
            
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            print_error_message<span class="token punctuation">(</span><span class="token string">'{} split not yet supported'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>split<span class="token punctuation">)</span><span class="token punctuation">)</span>
            
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        print_error_message<span class="token punctuation">(</span><span class="token string">'{} dataset not yet supported'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>image_list<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        print_error_message<span class="token punctuation">(</span><span class="token string">'No files in directory: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>image_path<span class="token punctuation">)</span><span class="token punctuation">)</span>

    print_info_message<span class="token punctuation">(</span><span class="token string">'# of images for testing: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>image_list<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> args<span class="token punctuation">.</span>model <span class="token operator">==</span> <span class="token string">'espnetv2'</span><span class="token punctuation">:</span>
        <span class="token keyword">from</span> model<span class="token punctuation">.</span>segmentation<span class="token punctuation">.</span>espnetv2 <span class="token keyword">import</span> espnetv2_seg
        args<span class="token punctuation">.</span>classes <span class="token operator">=</span> seg_classes
        model <span class="token operator">=</span> espnetv2_seg<span class="token punctuation">(</span>args<span class="token punctuation">)</span>
    <span class="token keyword">elif</span> args<span class="token punctuation">.</span>model <span class="token operator">==</span> <span class="token string">'dicenet'</span><span class="token punctuation">:</span>
        <span class="token keyword">from</span> model<span class="token punctuation">.</span>segmentation<span class="token punctuation">.</span>dicenet <span class="token keyword">import</span> dicenet_seg
        model <span class="token operator">=</span> dicenet_seg<span class="token punctuation">(</span>args<span class="token punctuation">,</span> classes<span class="token operator">=</span>seg_classes<span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        print_error_message<span class="token punctuation">(</span><span class="token string">'{} network not yet supported'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>model<span class="token punctuation">)</span><span class="token punctuation">)</span>
        exit<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token comment"># mdoel information</span>
    num_params <span class="token operator">=</span> model_parameters<span class="token punctuation">(</span>model<span class="token punctuation">)</span>
    flops <span class="token operator">=</span> compute_flops<span class="token punctuation">(</span>model<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token operator">=</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> args<span class="token punctuation">.</span>im_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> args<span class="token punctuation">.</span>im_size<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    print_info_message<span class="token punctuation">(</span><span class="token string">'FLOPs for an input of size {}x{}: {:.2f} million'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>im_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> args<span class="token punctuation">.</span>im_size<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> flops<span class="token punctuation">)</span><span class="token punctuation">)</span>
    print_info_message<span class="token punctuation">(</span><span class="token string">'# of parameters: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>num_params<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> args<span class="token punctuation">.</span>weights_test<span class="token punctuation">:</span>
        print_info_message<span class="token punctuation">(</span><span class="token string">'Loading model weights'</span><span class="token punctuation">)</span>
        weight_dict <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>args<span class="token punctuation">.</span>weights_test<span class="token punctuation">,</span> map_location<span class="token operator">=</span>torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cpu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>weight_dict<span class="token punctuation">)</span>
        print_info_message<span class="token punctuation">(</span><span class="token string">'Weight loaded successfully'</span><span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        print_error_message<span class="token punctuation">(</span><span class="token string">'weight file does not exist or not specified. Please check: {}'</span><span class="token punctuation">,</span> <span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>weights_test<span class="token punctuation">)</span><span class="token punctuation">)</span>

    num_gpus <span class="token operator">=</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>device_count<span class="token punctuation">(</span><span class="token punctuation">)</span>
    device <span class="token operator">=</span> <span class="token string">'cuda'</span> <span class="token keyword">if</span> num_gpus <span class="token operator">&gt;</span> <span class="token number">0</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span>
    model <span class="token operator">=</span> model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token operator">=</span>device<span class="token punctuation">)</span>

    evaluate<span class="token punctuation">(</span>args<span class="token punctuation">,</span> model<span class="token punctuation">,</span> image_list<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    <span class="token keyword">from</span> commons<span class="token punctuation">.</span>general_details <span class="token keyword">import</span> segmentation_models<span class="token punctuation">,</span> segmentation_datasets

    parser <span class="token operator">=</span> ArgumentParser<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># mdoel details</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--model'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">&quot;espnetv2&quot;</span><span class="token punctuation">,</span> choices<span class="token operator">=</span>segmentation_models<span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Model name'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--weights-test'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Pretrained weights directory.'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--s'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">2.0</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">float</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'scale'</span><span class="token punctuation">)</span>
    <span class="token comment"># dataset details</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--data-path'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">&quot;&quot;</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Data directory'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--dataset'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">'custom'</span><span class="token punctuation">,</span> choices<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'custom'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Dataset name'</span><span class="token punctuation">)</span>
    <span class="token comment"># input details</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--im-size'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> nargs<span class="token operator">=</span><span class="token string">&quot;+&quot;</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Image size for testing (W x H)'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--split'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">'val'</span><span class="token punctuation">,</span> choices<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token string">'val'</span><span class="token punctuation">,</span> <span class="token string">'test'</span><span class="token punctuation">,</span> <span class="token string">'custom'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'data split'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--model-width'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Model width'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--model-height'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Model height'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--channels'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Input channels'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--num-classes'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span>
                        <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'ImageNet classes. Required for loading the base network'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--savedir-name'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">'demo'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">str</span><span class="token punctuation">,</span>
                        <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Save folder location'</span><span class="token punctuation">)</span>

    args <span class="token operator">=</span> parser<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> <span class="token keyword">not</span> args<span class="token punctuation">.</span>weights_test<span class="token punctuation">:</span>
        <span class="token keyword">from</span> model<span class="token punctuation">.</span>weight_locations<span class="token punctuation">.</span>segmentation <span class="token keyword">import</span> model_weight_map

        model_key <span class="token operator">=</span> <span class="token string">'{}_{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>model<span class="token punctuation">,</span> args<span class="token punctuation">.</span>s<span class="token punctuation">)</span>
        dataset_key <span class="token operator">=</span> <span class="token string">'{}_{}x{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>dataset<span class="token punctuation">,</span> args<span class="token punctuation">.</span>im_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> args<span class="token punctuation">.</span>im_size<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">assert</span> model_key <span class="token keyword">in</span> model_weight_map<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'{} does not exist'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>model_key<span class="token punctuation">)</span>
        <span class="token keyword">assert</span> dataset_key <span class="token keyword">in</span> model_weight_map<span class="token punctuation">[</span>model_key<span class="token punctuation">]</span><span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'{} does not exist'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>dataset_key<span class="token punctuation">)</span>
        args<span class="token punctuation">.</span>weights_test <span class="token operator">=</span> model_weight_map<span class="token punctuation">[</span>model_key<span class="token punctuation">]</span><span class="token punctuation">[</span>dataset_key<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'weights'</span><span class="token punctuation">]</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>isfile<span class="token punctuation">(</span>args<span class="token punctuation">.</span>weights_test<span class="token punctuation">)</span><span class="token punctuation">:</span>
            print_error_message<span class="token punctuation">(</span><span class="token string">'weight file does not exist: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>weights_test<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment"># set-up results path</span>
    <span class="token keyword">if</span> args<span class="token punctuation">.</span>dataset <span class="token operator">==</span> <span class="token string">'custom'</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> args<span class="token punctuation">.</span>split <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token string">'val'</span><span class="token punctuation">,</span> <span class="token string">'test'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
            args<span class="token punctuation">.</span>savedir <span class="token operator">=</span> <span class="token string">'results_images/{}_{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>dataset<span class="token punctuation">,</span> args<span class="token punctuation">.</span>split<span class="token punctuation">)</span>
        <span class="token keyword">elif</span> args<span class="token punctuation">.</span>split <span class="token operator">==</span> <span class="token string">'custom'</span><span class="token punctuation">:</span>
            args<span class="token punctuation">.</span>savedir <span class="token operator">=</span> <span class="token string">'results_images/{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>savedir_name<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            print_error_message<span class="token punctuation">(</span><span class="token string">'{} split not yet supported'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>split<span class="token punctuation">)</span><span class="token punctuation">)</span>
            
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        print_error_message<span class="token punctuation">(</span><span class="token string">'{} dataset not yet supported'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>isdir<span class="token punctuation">(</span>args<span class="token punctuation">.</span>savedir<span class="token punctuation">)</span><span class="token punctuation">:</span>
        os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>args<span class="token punctuation">.</span>savedir<span class="token punctuation">)</span>

    <span class="token comment"># This key is used to load the ImageNet weights while training. So, set to empty to avoid errors</span>
    args<span class="token punctuation">.</span>weights <span class="token operator">=</span> <span class="token string">''</span>

    main<span class="token punctuation">(</span>args<span class="token punctuation">)</span>
</code></pre></div><p>以下のコマンドでテストを実行し，マスク画像を生成します．</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token operator">%</span>cd <span class="token operator">/</span>content<span class="token operator">/</span>drive<span class="token operator">/</span>My\ Drive<span class="token operator">/</span>segmentation<span class="token operator">/</span>EdgeNets
!CUDA_VISIBLE_DEVICES<span class="token operator">=</span><span class="token number">0</span> python custom_test_segmentation<span class="token punctuation">.</span>py \
                              <span class="token operator">-</span><span class="token operator">-</span>model espnetv2 \
                              <span class="token operator">-</span><span class="token operator">-</span>s <span class="token number">2.0</span> \
                              <span class="token operator">-</span><span class="token operator">-</span>dataset custom \
                              <span class="token operator">-</span><span class="token operator">-</span>data<span class="token operator">-</span>path <span class="token punctuation">.</span><span class="token operator">/</span>sample_images<span class="token operator">/</span> \
                              <span class="token operator">-</span><span class="token operator">-</span>split custom \
                              <span class="token operator">-</span><span class="token operator">-</span>im<span class="token operator">-</span>size <span class="token number">1024</span> <span class="token number">512</span>\
                              <span class="token operator">-</span><span class="token operator">-</span>num<span class="token operator">-</span>classes <span class="token number">2</span> \
                               <span class="token operator">-</span><span class="token operator">-</span>weights<span class="token operator">-</span>test <span class="token punctuation">.</span><span class="token operator">/</span>results_segmentation<span class="token operator">/</span>human_city<span class="token operator">/</span>model_espnetv2_custom<span class="token operator">/</span>s_2<span class="token punctuation">.</span>0_sch_hybrid_loss_ce_res_1024_sc_0<span class="token punctuation">.</span>35_1<span class="token punctuation">.</span><span class="token number">0</span><span class="token operator">/</span>＊＊＊<span class="token operator">/</span>espnetv2_2<span class="token punctuation">.</span>0_1024_best<span class="token punctuation">.</span>pth \
                               <span class="token operator">-</span><span class="token operator">-</span>savedir<span class="token operator">-</span>name sample_images_org
</code></pre></div><p>マスク画像<br> <img alt="" data-src="/image/mask_sample3.png" loading="lazy" class="lazy"><br></p> <h3 id="クロマキー合成-2"><a href="#クロマキー合成-2" class="header-anchor">#</a> クロマキー合成</h3> <p>クロマキー合成は実際のオリジナル画像，マスク画像，背景画像の3つで実装できます．<br>
マスク画像は白と黒の2色である必要があるので，以下のコードでは色置換も実施しています．<br></p> <p>オリジナル画像<br> <img alt="" data-src="/image/ESPNet_sample3_org.jpg" loading="lazy" class="lazy"><br></p> <p>マスク画像<br> <img alt="" data-src="/image/mask_sample3_gray.png" loading="lazy" class="lazy"><br></p> <p>背景画像<br> <img alt="" data-src="/image/grass.jpg" loading="lazy" class="lazy"><br></p> <p>以下のコードでクロマキー合成が実行できます．</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment">#　作業ディレクトリ：/content/drive/My\ Drive/segmentation/EdgeNets</span>
<span class="token keyword">import</span> cv2
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token comment"># マスク画像の読み込み</span>
mask <span class="token operator">=</span> cv2<span class="token punctuation">.</span>imread<span class="token punctuation">(</span><span class="token string">'./results_images/sample_images_org/mask_sample3.png'</span><span class="token punctuation">)</span>
<span class="token comment"># 特定の色(0, 0, 128)を別の色(255, 255, 255)に置換する</span>
before_color <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">]</span>
after_color <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">255</span><span class="token punctuation">,</span> <span class="token number">255</span><span class="token punctuation">,</span> <span class="token number">255</span><span class="token punctuation">]</span>
mask<span class="token punctuation">[</span>np<span class="token punctuation">.</span>where<span class="token punctuation">(</span><span class="token punctuation">(</span>mask <span class="token operator">==</span> before_color<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">all</span><span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> after_color

<span class="token comment"># オリジナル画像</span>
org <span class="token operator">=</span> cv2<span class="token punctuation">.</span>imread<span class="token punctuation">(</span><span class="token string">'./sample_images/sample3.jpg'</span><span class="token punctuation">)</span>
h<span class="token punctuation">,</span> w<span class="token punctuation">,</span> _ <span class="token operator">=</span> org<span class="token punctuation">.</span>shape

<span class="token comment"># 背景画像</span>
back <span class="token operator">=</span> cv2<span class="token punctuation">.</span>imread<span class="token punctuation">(</span><span class="token string">'grass.jpg'</span><span class="token punctuation">)</span>
back <span class="token operator">=</span> cv2<span class="token punctuation">.</span>resize<span class="token punctuation">(</span>back<span class="token punctuation">,</span> <span class="token punctuation">(</span>w<span class="token punctuation">,</span> h<span class="token punctuation">)</span> <span class="token punctuation">)</span>

<span class="token comment"># クロマキー合成</span>
dst <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>mask<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">,</span> back<span class="token punctuation">,</span> org<span class="token punctuation">)</span>
<span class="token comment"># 保存</span>
cv2<span class="token punctuation">.</span>imwrite<span class="token punctuation">(</span><span class="token string">'chromakey.jpg'</span><span class="token punctuation">,</span> dst<span class="token punctuation">)</span>

<span class="token comment"># google colab用の画像表示コード</span>
<span class="token keyword">from</span> google<span class="token punctuation">.</span>colab<span class="token punctuation">.</span>patches <span class="token keyword">import</span> cv2_imshow
cv2_imshow<span class="token punctuation">(</span>dst<span class="token punctuation">)</span>
</code></pre></div><p>クロマキー合成画像<br> <img alt="" data-src="/image/chromakey.jpg" loading="lazy" class="lazy"><br></p> <h2 id="まとめ"><a href="#まとめ" class="header-anchor">#</a> まとめ</h2> <p>本稿ではPython + ESPNetで学習した人を検出するセマンティックセグメンテーションのモデルを使って，クロマキー合成を実施しました．<br>
今度は，違うモデルで実施してみたいです．</p> <h2 id="参考サイト"><a href="#参考サイト" class="header-anchor">#</a> 参考サイト</h2> <p><a href="https://github.com/sacmehta/EdgeNets" target="_blank" rel="noopener noreferrer">sacmehta/EdgeNets<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a><br> <a href="https://github.com/sacmehta/EdgeNets/blob/master/README_Segmentation.md" target="_blank" rel="noopener noreferrer">sacmehta/EdgeNets/README_Segmentation.md<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> <a href="https://qiita.com/tokyokuma/items/37b1370ea7c84399fbb9" target="_blank" rel="noopener noreferrer">ESPNetで自作データセットを学習してセグメンテーション<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a><br> <a href="https://rikoubou.hatenablog.com/entry/2019/02/21/190310" target="_blank" rel="noopener noreferrer">【python/OpenCV】画像の特定の色を抽出する方法<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a><br> <a href="https://qiita.com/pashango2/items/d6dda5f07109ee5b6163" target="_blank" rel="noopener noreferrer">PIL/Pillowで画像の色を高速に置換する<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a><br> <a href="http://ni4muraano.hatenablog.com/entry/2017/05/15/000000" target="_blank" rel="noopener noreferrer">【OpenCV】 forループを使わずに指定した色を別の色に変更する<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a><br> <a href="https://pystyle.info/opencv-mask-image/" target="_blank" rel="noopener noreferrer">OpenCV – マスク画像を利用した画像処理について<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p></div> <section class="content content__default" data-v-405d0d6c><div id="disqus_thread" data-v-405d0d6c></div></section> <div class="content-time" data-v-405d0d6c><time datetime="3/24/2021, 12:00:00 AM" class="time-text" data-v-405d0d6c>Create Time: 3/24/2021, 12:00:00 AM
    </time> <time datetime="4/12/2021, 9:12:47 AM" class="time-text" data-v-405d0d6c>Last Updated: 4/12/2021, 9:12:47 AM
    </time></div></article> <section class="flex-xb main info-nav" data-v-203269c1 data-v-2602fa21><a href="/posts/cyclegan01.html" class="flex-xb nav-item" data-v-203269c1><div class="flex-xcc item-img" data-v-203269c1><img data-src="https://www.hamlet-engineer.com/image/cyclegan_zebra.png" loading="lazy" alt="Python + CycleGanで茶毛のウマをシマウマに変換する" class="img lazy" data-v-203269c1></div> <article class="flex-ysc item-content" data-v-203269c1><h2 class="content-title" data-v-203269c1>Python + CycleGanで茶毛のウマをシマウマに変換する</h2> <div class="content" data-v-203269c1><p>画像生成系のCycleGanを実装します．Python + CycleGanで茶毛のウマをシマウマに変換します．<br></p>
</div></article></a> <a href="/posts/segmentation03.html" class="flex-xb nav-item" data-v-203269c1><div class="flex-xcc item-img" data-v-203269c1><img data-src="https://www.hamlet-engineer.com/image/org_seg1.png" loading="lazy" alt="Python + ESPNetをオリジナルデータで学習する(学習編)" class="img lazy" data-v-203269c1></div> <article class="flex-ysc item-content" data-v-203269c1><h2 class="content-title" data-v-203269c1>Python + ESPNetをオリジナルデータで学習する(学習編)</h2> <div class="content" data-v-203269c1><p>セマンティックセグメンテーションの中で軽いモデルであるESPNetv2を実装します．<br>
本稿ではCityscapesデータセットから人のみを抽出した仮のオリジナルデータで学習を実施します．<br></p>
</div></article></a></section> <!----></section></section> <footer class="footer" data-v-8dceedee data-v-98a81704><nav class="link-list" data-v-8dceedee><a href="https://twitter.com/hirasu1231" target="_blank" rel="noopener noreferrer" class="list-item" data-v-8dceedee>Twitter</a><a href="https://github.com/hirasu1231" target="_blank" rel="noopener noreferrer" class="list-item" data-v-8dceedee>Github</a></nav> <a href="/" class="copyright router-link-active" data-v-8dceedee>ハムレット型エンジニアのカンニングノート © 2021</a></footer></section><div class="global-ui"><!----><!----></div></div>
    <script src="/assets/js/app.0625ac58.js" defer></script><script src="/assets/js/28.294e8143.js" defer></script>
  </body>
</html>
