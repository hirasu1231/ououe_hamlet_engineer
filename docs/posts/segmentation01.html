<!DOCTYPE html>
<html lang="ja-jp">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Python + ESPNetをCityscapesデータセットで学習する | ハムレット型エンジニアのカンニングノート</title>
    <meta name="generator" content="VuePress 1.8.2">
    
    <meta name="description" content="Python + ESPNetでCityscapesデータセットでセマンティックセグメンテーションの学習を実施します．">
    <meta property="article:published_time" content="2021-03-15T00:00:00.000Z">
    <meta property="article:modified_time" content="2021-04-12T09:12:47.000Z">
    <meta property="og:site_name" content="ハムレット型エンジニアのカンニングノート">
    <meta property="og:title" content="Python + ESPNetをCityscapesデータセットで学習する">
    <meta property="og:description" content="Python + ESPNetでCityscapesデータセットでセマンティックセグメンテーションの学習を実施します．">
    <meta property="og:type" content="article">
    <meta property="og:url" content="/posts/segmentation01.html">
    <meta property="og:image" content="https://www.hamlet-engineer.com/image/ESPNet_sample3_city.png">
    <meta name="twitter:title" content="Python + ESPNetをCityscapesデータセットで学習する">
    <meta name="twitter:description" content="Python + ESPNetでCityscapesデータセットでセマンティックセグメンテーションの学習を実施します．">
    <meta name="twitter:url" content="/posts/segmentation01.html">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:image" content="https://www.hamlet-engineer.com/image/ESPNet_sample3_city.png">
    <meta name="twitter:label2" content="Filed under">
    <meta name="twitter:data2" content="Python, Jupyter, ESPNet, セマンティックセグメンテーション">
    <meta property="article:tag" content="Python">
    <meta name="google-site-verification" content="BDXGk8FJfikB_I6Pyxv35Zc87jBMziCgRMvmpNDpdYA">
    
    <link rel="preload" href="/assets/css/0.styles.cda99d2a.css" as="style"><link rel="preload" href="/assets/js/app.8498328e.js" as="script"><link rel="preload" href="/assets/js/23.98df4d3e.js" as="script"><link rel="prefetch" href="/assets/js/10.fd644f0a.js"><link rel="prefetch" href="/assets/js/11.073e0a7d.js"><link rel="prefetch" href="/assets/js/12.d7491f52.js"><link rel="prefetch" href="/assets/js/13.30a302fa.js"><link rel="prefetch" href="/assets/js/14.aa7992ea.js"><link rel="prefetch" href="/assets/js/15.c1b40f75.js"><link rel="prefetch" href="/assets/js/16.7c545acd.js"><link rel="prefetch" href="/assets/js/17.6e15c122.js"><link rel="prefetch" href="/assets/js/18.5b4452f7.js"><link rel="prefetch" href="/assets/js/19.c2b8f4b3.js"><link rel="prefetch" href="/assets/js/2.119cf6e6.js"><link rel="prefetch" href="/assets/js/20.27feb11b.js"><link rel="prefetch" href="/assets/js/21.2eddd053.js"><link rel="prefetch" href="/assets/js/22.e65fce31.js"><link rel="prefetch" href="/assets/js/24.3c4bcfc4.js"><link rel="prefetch" href="/assets/js/25.c74d0256.js"><link rel="prefetch" href="/assets/js/26.e9e98d20.js"><link rel="prefetch" href="/assets/js/27.2e417698.js"><link rel="prefetch" href="/assets/js/28.7e439a5d.js"><link rel="prefetch" href="/assets/js/29.c985b718.js"><link rel="prefetch" href="/assets/js/3.b3caa0ed.js"><link rel="prefetch" href="/assets/js/30.93ee26bb.js"><link rel="prefetch" href="/assets/js/31.ce82009f.js"><link rel="prefetch" href="/assets/js/32.557c9a7f.js"><link rel="prefetch" href="/assets/js/33.b0e62daa.js"><link rel="prefetch" href="/assets/js/34.e544c124.js"><link rel="prefetch" href="/assets/js/35.5f189397.js"><link rel="prefetch" href="/assets/js/36.3255a169.js"><link rel="prefetch" href="/assets/js/4.966b739d.js"><link rel="prefetch" href="/assets/js/5.6cf8471c.js"><link rel="prefetch" href="/assets/js/6.0fb7b49c.js"><link rel="prefetch" href="/assets/js/7.e5873a6f.js"><link rel="prefetch" href="/assets/js/8.e7f47f4e.js"><link rel="prefetch" href="/assets/js/9.9091e9fc.js">
    <link rel="stylesheet" href="/assets/css/0.styles.cda99d2a.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><section id="global-layout" data-v-98a81704><header class="header" data-v-00466d8e data-v-98a81704><div class="header-navbar" data-v-00466d8e><div class="flex-xbc main header-nav" data-v-00466d8e><div class="nav-link" data-v-00466d8e><a href="/" class="inblock link-logo router-link-active" data-v-00466d8e><img data-src="/logo.png" loading="lazy" alt="logo" class="logo-img lazy" data-v-00466d8e></a> <nav class="link-list" data-v-00466d8e><a href="/" class="list-item router-link-active" data-v-00466d8e>ホーム</a><a href="/about/" class="list-item" data-v-00466d8e>ページ集</a><a href="/posts/" class="list-item router-link-active" data-v-00466d8e>技術</a><a href="/mental/" class="list-item" data-v-00466d8e>メンタル</a><a href="/other/" class="list-item" data-v-00466d8e>その他</a><a href="/tag/" class="list-item" data-v-00466d8e>タグ</a><a href="/category/" class="list-item" data-v-00466d8e>カテゴリ</a><a href="https://twitter.com/hirasu1231" target="_blank" rel="noopener noreferrer" class="list-item" data-v-00466d8e>筆者</a></nav></div> <div class="search-box" data-v-00466d8e><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div></div></div> </header> <!----> <section class="page" data-v-98a81704 data-v-98a81704><section class="info no-bg" data-v-2602fa21><article class="main info-content" data-v-09525e5c data-v-2602fa21><div class="content-header" data-v-09525e5c><h1 class="header-title" data-v-09525e5c>Python + ESPNetをCityscapesデータセットで学習する</h1></div> <div class="flex-wcc content-tag" data-v-09525e5c><div class="inblock tag-list" data-v-09525e5c><a href="/category/Python/" class="tag-text" data-v-09525e5c>Python
      </a></div> <span class="tag-space" data-v-09525e5c>/</span> <div class="inblock tag-list" data-v-09525e5c><a href="/tag/Python/" class="tag-text" data-v-09525e5c>Python
      </a><a href="/tag/Jupyter/" class="tag-text" data-v-09525e5c>Jupyter
      </a><a href="/tag/ESPNet/" class="tag-text" data-v-09525e5c>ESPNet
      </a><a href="/tag/セマンティックセグメンテーション/" class="tag-text" data-v-09525e5c>セマンティックセグメンテーション
      </a></div></div> <div class="content content__default" data-v-09525e5c><p>セマンティックセグメンテーションの中で軽いモデルであるESPNetv2を実装します．<br>
本稿ではまず，デモの起動と公開データセットのCityscapesでの学習を実施します．<br></p> <p>今回はGoogle ColabとGoogle Driveを連携させて，notebook形式で実行してます．<br></p> <blockquote><p>Google Colaboratory（以下Google Colab）は、Google社が無料で提供している機械学習の教育や研究用の開発環境です。開発環境はJupyter Notebookに似たインターフェースを持ち、Pythonの主要なライブラリがプリインストールされています。<br>
引用元：<a href="https://interface.cqpub.co.jp/ail01/" target="_blank" rel="noopener noreferrer">Google Colabの使い方<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p></blockquote> <p>最終的に，人以外の背景を着色して，zoomのバーチャル背景機能のようなクロマキー合成を実装したいです．<br> <img alt="" data-src="/image/zoom.jpg" loading="lazy" class="lazy"></p> <h2 id="ファイル構成"><a href="#ファイル構成" class="header-anchor">#</a> ファイル構成</h2> <p>プロジェクトディレクトリはsegmentationとしています．度々，省略しています．</p> <div class="language- extra-class"><pre class="language-text"><code>segmentation
├── /EdgeNets
│   ├── /data_loader
│   │   └── /segmentation
│   │       ├── /scripts
│   │       │   ├── download_cityscapes.sh
│   │       │   └── (省略)
│   │       └── /cityscape_script
│   │           ├── process_cityscapes.py &lt;- コピー元
│   │           ├── generate_mappings.py &lt;- コピー元
│   │           └── (省略)
│   ├── /sample_images &lt;- サンプル画像
│   ├── /results_segmentation &lt;- モデルの出力ディレクトリ
│   ├── /result_images &lt;- 着色画像の出力ディレクトリ
│   ├── /vision_datasets
│   │       └── /cityscapes &lt;- cityscapesデータセット
│   ├── segmentation_demo.py
│   ├── train_segmentation.py
│   ├── test_segmentation.py
│   ├── process_cityscapes.py &lt;- コピー先
│   ├── generate_mappings.py &lt;- コピー先
│   ├── custom_test_segmentation.py &lt;- 新規作成
│   └── (省略)
└── ESPNetv2.ipynb &lt;- 実行用ノートブック
</code></pre></div><h2 id="edgenets-espnetv2"><a href="#edgenets-espnetv2" class="header-anchor">#</a> EdgeNets(ESPNetv2)</h2> <h3 id="edgenetsのダウンロード"><a href="#edgenetsのダウンロード" class="header-anchor">#</a> EdgeNetsのダウンロード</h3> <p>Google ColabとGoogle Driveを連携させて，gitからESPNetv2を内包している<a href="https://github.com/sacmehta/EdgeNets" target="_blank" rel="noopener noreferrer">EdgeNets<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>をダウンロードします．<br>
segmentationの解説は<a href="(https://github.com/sacmehta/EdgeNets/blob/master/README_Segmentation.md)">README_Segmentation.md</a>に記載されています．</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># Google ColabとGoogle Driveを連携</span>
<span class="token keyword">from</span> google<span class="token punctuation">.</span>colab <span class="token keyword">import</span> drive
drive<span class="token punctuation">.</span>mount<span class="token punctuation">(</span><span class="token string">'/content/drive'</span><span class="token punctuation">)</span>
</code></pre></div><div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># ディレクトリの移動</span>
<span class="token operator">%</span>cd <span class="token operator">/</span>content<span class="token operator">/</span>drive<span class="token operator">/</span>My Drive<span class="token operator">/</span>segmentation
<span class="token comment"># gitのダウンロード</span>
!git clone https<span class="token punctuation">:</span><span class="token operator">//</span>github<span class="token punctuation">.</span>com<span class="token operator">/</span>sacmehta<span class="token operator">/</span>EdgeNets<span class="token punctuation">.</span>git
</code></pre></div><h3 id="edgenetsの起動チェック"><a href="#edgenetsの起動チェック" class="header-anchor">#</a> EdgeNetsの起動チェック</h3> <p>正常に起動するか，デフォルトで入っているデモコードでチェックします．</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># ディレクトリの移動</span>
<span class="token operator">%</span>cd EdgeNets
<span class="token comment"># デモコード</span>
python segmentation_demo<span class="token punctuation">.</span>py
</code></pre></div><p>上記のコードを実行すると，/segmentation_resultsに着色された画像が出力されます．<br> <img alt="" data-src="/image/ESPNet_demo.png" loading="lazy" class="lazy"></p> <h2 id="cityscapesデータセットで学習デモ"><a href="#cityscapesデータセットで学習デモ" class="header-anchor">#</a> Cityscapesデータセットで学習デモ</h2> <p>本稿ではまず，Cityscapesという街中の景色のデータセットでespnetv2の学習を実施します．</p> <h3 id="cityscapesデータセットのダウンロード"><a href="#cityscapesデータセットのダウンロード" class="header-anchor">#</a> Cityscapesデータセットのダウンロード</h3> <p>Cityscapesデータセットをダウンロードするには，まず<a href="https://www.cityscapes-dataset.com" target="_blank" rel="noopener noreferrer">Cityscapesのサイト<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>に登録する必要があります．<br>
そして，./EdgeNets/data_loader/segmentation/scripts/download_cityscapes.shに登録したアドレスとパスワードを記入します．</p> <div class="language-sh extra-class"><pre class="language-sh"><code><span class="token comment"># download_cityscapes.sh</span>
<span class="token comment"># 8~10行目</span>
<span class="token comment"># enter user details</span>
<span class="token assign-left variable">uname</span><span class="token operator">=</span><span class="token string">'登録したアドレス'</span> 
<span class="token assign-left variable">pass</span><span class="token operator">=</span><span class="token string">'登録したパスワード'</span>
</code></pre></div><p>以下のコマンドを実行し， Cityscapesデータセットをダウンロードします．</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token operator">%</span><span class="token operator">%</span>bash
<span class="token comment"># 現在ディレクトリ：/content/drive/My\ Drive/segmentation/EdgeNets</span>
<span class="token comment"># ディレクトリの移動</span>
cd  <span class="token punctuation">.</span><span class="token operator">/</span>data_loader<span class="token operator">/</span>segmentation<span class="token operator">/</span>scripts 
<span class="token comment"># ダウンロード実行</span>
sh download_cityscapes<span class="token punctuation">.</span>sh
</code></pre></div><h3 id="cityscapesデータセットを学習用にマスキング"><a href="#cityscapesデータセットを学習用にマスキング" class="header-anchor">#</a> Cityscapesデータセットを学習用にマスキング</h3> <p>学習のためにCityscapesセグメンテーションマスクで処理する必要があります．<br> <a href="https://github.com/sacmehta/EdgeNets/blob/master/README_Segmentation.md" target="_blank" rel="noopener noreferrer">sacmehta/EdgeNets/README_Segmentation.md<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>に記述されているコマンドをそのまま実行すると，エラーが発生しますので「process_cityscapes.pyとgenerate_mappings.py」を./EdgeNets直下に置きます．(本稿のエラー集_エラー1参照)</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token operator">%</span><span class="token operator">%</span>bash
<span class="token comment"># 現在ディレクトリ：/content/drive/My\ Drive/segmentation/EdgeNets</span>
<span class="token comment"># cp &lt;移動前&gt; &lt;移動先&gt;</span>
<span class="token comment"># process_cityscapes.pyを/EdgeNets直下にコピー</span>
cp data_loader<span class="token operator">/</span>segmentation<span class="token operator">/</span>cityscape_scripts<span class="token operator">/</span>process_cityscapes<span class="token punctuation">.</span>py process_cityscapes<span class="token punctuation">.</span>py
<span class="token comment"># process_cityscapes.pyを/EdgeNets直下にコピー</span>
cp data_loader<span class="token operator">/</span>segmentation<span class="token operator">/</span>cityscape_scripts<span class="token operator">/</span>generate_mappings<span class="token punctuation">.</span>py generate_mappings<span class="token punctuation">.</span>py
</code></pre></div><p>「process_cityscapes.pyとgenerate_mappings.py」の場所を変えたので，それに応じて読み込む場所の記述も書き換えます．</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># process_cityscapes.py</span>
<span class="token comment"># 486行目</span>
cityscapes_path <span class="token operator">=</span> <span class="token string">'./vision_datasets/cityscapes/'</span>

<span class="token comment"># generate_mappings.py</span>
<span class="token comment"># 70行目</span>
cityscapes_path <span class="token operator">=</span> <span class="token string">'./vision_datasets/cityscapes/'</span>
</code></pre></div><p>以下のコマンドでマスキングを実行します．</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token operator">%</span><span class="token operator">%</span>bash
<span class="token comment"># 現在ディレクトリ：/content/drive/My\ Drive/segmentation/EdgeNets</span>
<span class="token comment"># セグメンテーションマスキング</span>
python process_cityscapes<span class="token punctuation">.</span>py
python generate_mappings<span class="token punctuation">.</span>py
</code></pre></div><h3 id="学習の第1段階"><a href="#学習の第1段階" class="header-anchor">#</a> 学習の第1段階</h3> <p>最初の段階では、低解像度の画像を入力として使用して，より大きなバッチサイズに合わせることができます．<br>
学習したモデルは/results_segmentation内に格納されます．</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token operator">%</span><span class="token operator">%</span>bash
<span class="token comment"># 現在ディレクトリ：/content/drive/My\ Drive/segmentation/EdgeNets</span>
<span class="token comment"># Cityscapes dataset</span>
!CUDA_VISIBLE_DEVICES<span class="token operator">=</span><span class="token number">0</span> python train_segmentation<span class="token punctuation">.</span>py \
                                <span class="token operator">-</span><span class="token operator">-</span>model espnetv2 \
                                <span class="token operator">-</span><span class="token operator">-</span>s <span class="token number">2.0</span> \
                                <span class="token operator">-</span><span class="token operator">-</span>dataset city \
                                <span class="token operator">-</span><span class="token operator">-</span>data<span class="token operator">-</span>path <span class="token punctuation">.</span><span class="token operator">/</span>vision_datasets<span class="token operator">/</span>cityscapes<span class="token operator">/</span> \
                                <span class="token operator">-</span><span class="token operator">-</span>batch<span class="token operator">-</span>size <span class="token number">25</span> \
                                <span class="token operator">-</span><span class="token operator">-</span>crop<span class="token operator">-</span>size <span class="token number">512</span> <span class="token number">256</span> \
                                <span class="token operator">-</span><span class="token operator">-</span>lr <span class="token number">0.009</span> \
                                <span class="token operator">-</span><span class="token operator">-</span>scheduler hybrid \
                                <span class="token operator">-</span><span class="token operator">-</span>clr<span class="token operator">-</span><span class="token builtin">max</span> <span class="token number">61</span> \
                                <span class="token operator">-</span><span class="token operator">-</span>epochs <span class="token number">50</span>
</code></pre></div><h3 id="学習の第2段階"><a href="#学習の第2段階" class="header-anchor">#</a> 学習の第2段階</h3> <p>第2段階では、バッチ正規化レイヤーをフリーズしてから，わずかに高い画像解像度で微調整します．<br>
学習したモデルは/results_segmentation内に格納されます．</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token operator">%</span><span class="token operator">%</span>bash
<span class="token comment"># 現在ディレクトリ：/content/drive/My\ Drive/segmentation/EdgeNets</span>
<span class="token comment"># Cityscapes dataset</span>
CUDA_VISIBLE_DEVICES<span class="token operator">=</span><span class="token number">0</span> python train_segmentation<span class="token punctuation">.</span>py \
                                <span class="token operator">-</span><span class="token operator">-</span>model espnetv2\
                                <span class="token operator">-</span><span class="token operator">-</span>s <span class="token number">2.0</span> \
                                <span class="token operator">-</span><span class="token operator">-</span>dataset city \
                                <span class="token operator">-</span><span class="token operator">-</span>data<span class="token operator">-</span>path <span class="token punctuation">.</span><span class="token operator">/</span>vision_datasets<span class="token operator">/</span>cityscapes<span class="token operator">/</span> \
                                <span class="token operator">-</span><span class="token operator">-</span>batch<span class="token operator">-</span>size <span class="token number">6</span> \
                                <span class="token operator">-</span><span class="token operator">-</span>crop<span class="token operator">-</span>size <span class="token number">1024</span> <span class="token number">512</span> \
                                <span class="token operator">-</span><span class="token operator">-</span>lr <span class="token number">0.005</span> \
                                <span class="token operator">-</span><span class="token operator">-</span>scheduler hybrid \
                                <span class="token operator">-</span><span class="token operator">-</span>clr<span class="token operator">-</span><span class="token builtin">max</span> <span class="token number">61</span> \
                                <span class="token operator">-</span><span class="token operator">-</span>epochs <span class="token number">30</span> \
                                <span class="token operator">-</span><span class="token operator">-</span>freeze<span class="token operator">-</span>bn \
                                <span class="token operator">-</span><span class="token operator">-</span>finetune results_segmentation<span class="token operator">/</span>model_espnetv2_city<span class="token operator">/</span>s_2<span class="token punctuation">.</span>0_sch_hybrid_loss_ce_res_512_sc_0<span class="token punctuation">.</span>25_0<span class="token punctuation">.</span><span class="token number">5</span><span class="token operator">/</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">/</span>espnetv2_2<span class="token punctuation">.</span>0_512_best<span class="token punctuation">.</span>pth
</code></pre></div><h2 id="cityscapesデータセットでテスト"><a href="#cityscapesデータセットでテスト" class="header-anchor">#</a> Cityscapesデータセットでテスト</h2> <p>/sample_imagesの画像でテストを実施します．<br></p> <h3 id="test-segmentation-pyの改良"><a href="#test-segmentation-pyの改良" class="header-anchor">#</a> test_segmentation.pyの改良</h3> <p>そこで任意のディレクトリでsegmentationできるように<code>test_segmentation.py</code>を改良して，<code>custom_test_segmentation.py</code>を作成します．<br></p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># ./EdgeNets/model/segmentation/espnetv2.py</span>
<span class="token comment"># 36行目付近</span>
dec_feat_dict<span class="token operator">=</span><span class="token punctuation">{</span>
            <span class="token string">'pascal'</span><span class="token punctuation">:</span> <span class="token number">16</span><span class="token punctuation">,</span>
            <span class="token string">'city'</span><span class="token punctuation">:</span> <span class="token number">16</span><span class="token punctuation">,</span>
            <span class="token string">'coco'</span><span class="token punctuation">:</span> <span class="token number">32</span><span class="token punctuation">,</span>
            <span class="token string">'custom'</span><span class="token punctuation">:</span> <span class="token number">16</span>
        <span class="token punctuation">}</span>
</code></pre></div><p><code>custom_test_segmentation.py</code>では元コードから以下のように若干いじっています．<br></p> <ul><li>入力画像の読み込みを，「.png・.jpg・.jpeg」に対応させた．</li> <li>入力画像の読み込みを任意のディレクトリに指定できるようにした．</li> <li>出力画像を「背景黒の着色画像」から「元画像と直色画像の合成」に変更した．</li> <li>出力画像の着色の仕方を固定のカラーマップからクラス数で変更できるようにした．</li> <li>出力画像の保存先を./result_images/&lt;任意のディレクトリ名&gt;に変更した．</li> <li>コマンドラインの引数を変更
<ul><li>dataset:：任意のデータでsegmentationできるように「custom」を追加</li> <li>split ：任意のデータでsegmentationできるように「custom」を追加．，</li> <li>savedir-name：任意の任意のディレクトリ名で保存できるようにしました</li></ul></li></ul> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># custom_test_segmentation.py</span>
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> glob
<span class="token keyword">import</span> os
<span class="token keyword">from</span> argparse <span class="token keyword">import</span> ArgumentParser
<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image
<span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">import</span> functional <span class="token keyword">as</span> F
<span class="token keyword">from</span> tqdm <span class="token keyword">import</span> tqdm
<span class="token keyword">from</span> utilities<span class="token punctuation">.</span>print_utils <span class="token keyword">import</span> <span class="token operator">*</span>
<span class="token keyword">from</span> transforms<span class="token punctuation">.</span>classification<span class="token punctuation">.</span>data_transforms <span class="token keyword">import</span> MEAN<span class="token punctuation">,</span> STD
<span class="token keyword">from</span> utilities<span class="token punctuation">.</span>utils <span class="token keyword">import</span> model_parameters<span class="token punctuation">,</span> compute_flops

<span class="token comment"># ===========================================</span>
__author__ <span class="token operator">=</span> <span class="token string">&quot;Sachin Mehta&quot;</span>
__license__ <span class="token operator">=</span> <span class="token string">&quot;MIT&quot;</span>
__maintainer__ <span class="token operator">=</span> <span class="token string">&quot;Sachin Mehta&quot;</span>
<span class="token comment"># ============================================</span>

IMAGE_EXTENSIONS <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'.jpg'</span><span class="token punctuation">,</span> <span class="token string">'.png'</span><span class="token punctuation">,</span> <span class="token string">'.jpeg'</span><span class="token punctuation">]</span>

<span class="token keyword">def</span> <span class="token function">data_transform</span><span class="token punctuation">(</span>img<span class="token punctuation">,</span> im_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
    img <span class="token operator">=</span> img<span class="token punctuation">.</span>resize<span class="token punctuation">(</span>im_size<span class="token punctuation">,</span> Image<span class="token punctuation">.</span>BILINEAR<span class="token punctuation">)</span>
    img <span class="token operator">=</span> F<span class="token punctuation">.</span>to_tensor<span class="token punctuation">(</span>img<span class="token punctuation">)</span>  <span class="token comment"># convert to tensor (values between 0 and 1)</span>
    img <span class="token operator">=</span> F<span class="token punctuation">.</span>normalize<span class="token punctuation">(</span>img<span class="token punctuation">,</span> MEAN<span class="token punctuation">,</span> STD<span class="token punctuation">)</span>  <span class="token comment"># normalize the tensor</span>
    <span class="token keyword">return</span> img


<span class="token keyword">def</span> <span class="token function">evaluate</span><span class="token punctuation">(</span>args<span class="token punctuation">,</span> model<span class="token punctuation">,</span> image_list<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token punctuation">:</span>
    im_size <span class="token operator">=</span> <span class="token builtin">tuple</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>im_size<span class="token punctuation">)</span>

    <span class="token comment"># get color map for dataset</span>
    <span class="token keyword">from</span> utilities<span class="token punctuation">.</span>color_map <span class="token keyword">import</span> VOCColormap
    cmap <span class="token operator">=</span> VOCColormap<span class="token punctuation">(</span>num_classes<span class="token operator">=</span>args<span class="token punctuation">.</span>num_classes<span class="token punctuation">)</span><span class="token punctuation">.</span>get_color_map_voc<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>cmap<span class="token punctuation">)</span>
    

    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> imgName <span class="token keyword">in</span> tqdm<span class="token punctuation">(</span><span class="token builtin">enumerate</span><span class="token punctuation">(</span>image_list<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        img <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>imgName<span class="token punctuation">)</span><span class="token punctuation">.</span>convert<span class="token punctuation">(</span><span class="token string">'RGB'</span><span class="token punctuation">)</span>
        img_clone <span class="token operator">=</span> img<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
        w<span class="token punctuation">,</span> h <span class="token operator">=</span> img<span class="token punctuation">.</span>size

        img <span class="token operator">=</span> data_transform<span class="token punctuation">(</span>img<span class="token punctuation">,</span> im_size<span class="token punctuation">)</span>
        img <span class="token operator">=</span> img<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment"># add a batch dimension</span>
        img <span class="token operator">=</span> img<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
        img_out <span class="token operator">=</span> model<span class="token punctuation">(</span>img<span class="token punctuation">)</span>
        img_out <span class="token operator">=</span> img_out<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment"># remove the batch dimension</span>
        img_out <span class="token operator">=</span> img_out<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>byte<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># get the label map</span>
        img_out <span class="token operator">=</span> img_out<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token operator">=</span><span class="token string">'cpu'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
        img_out <span class="token operator">=</span> Image<span class="token punctuation">.</span>fromarray<span class="token punctuation">(</span>img_out<span class="token punctuation">)</span>
        <span class="token comment"># resize to original size</span>
        img_out <span class="token operator">=</span> img_out<span class="token punctuation">.</span>resize<span class="token punctuation">(</span><span class="token punctuation">(</span>w<span class="token punctuation">,</span> h<span class="token punctuation">)</span><span class="token punctuation">,</span> Image<span class="token punctuation">.</span>NEAREST<span class="token punctuation">)</span>
        
        <span class="token comment"># pascal dataset accepts colored segmentations</span>
        img_out<span class="token punctuation">.</span>putpalette<span class="token punctuation">(</span>cmap<span class="token punctuation">)</span> <span class="token comment"># クラスごとに着色</span>
        img_out <span class="token operator">=</span> img_out<span class="token punctuation">.</span>convert<span class="token punctuation">(</span><span class="token string">'RGB'</span><span class="token punctuation">)</span>
        blended <span class="token operator">=</span> Image<span class="token punctuation">.</span>blend<span class="token punctuation">(</span>img_clone<span class="token punctuation">,</span> img_out<span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.7</span><span class="token punctuation">)</span>

        <span class="token comment"># save the segmentation mask</span>
        name <span class="token operator">=</span> imgName<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'/'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
        img_extn <span class="token operator">=</span> imgName<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'.'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
        name <span class="token operator">=</span> <span class="token string">'{}/{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>savedir<span class="token punctuation">,</span> name<span class="token punctuation">.</span>replace<span class="token punctuation">(</span>img_extn<span class="token punctuation">,</span> <span class="token string">'png'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        blended<span class="token punctuation">.</span>save<span class="token punctuation">(</span>name<span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># read all the images in the folder</span>
    <span class="token keyword">if</span> args<span class="token punctuation">.</span>dataset <span class="token operator">==</span> <span class="token string">'custom'</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> args<span class="token punctuation">.</span>split <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token string">'val'</span><span class="token punctuation">,</span> <span class="token string">'test'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
            image_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
            <span class="token keyword">for</span> extn <span class="token keyword">in</span> IMAGE_EXTENSIONS<span class="token punctuation">:</span>
                image_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>args<span class="token punctuation">.</span>data_path<span class="token punctuation">,</span> args<span class="token punctuation">.</span>split<span class="token punctuation">,</span> <span class="token string">&quot;rgb&quot;</span><span class="token punctuation">,</span> <span class="token string">'*'</span> <span class="token operator">+</span> extn<span class="token punctuation">)</span>
                image_list <span class="token operator">=</span> image_list <span class="token operator">+</span>  glob<span class="token punctuation">.</span>glob<span class="token punctuation">(</span>image_path<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">50</span><span class="token punctuation">]</span>
            seg_classes <span class="token operator">=</span> args<span class="token punctuation">.</span>num_classes
            
        <span class="token keyword">elif</span> args<span class="token punctuation">.</span>split <span class="token operator">==</span> <span class="token string">'custom'</span><span class="token punctuation">:</span>
            image_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
            <span class="token keyword">for</span> extn <span class="token keyword">in</span> IMAGE_EXTENSIONS<span class="token punctuation">:</span>
                image_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>args<span class="token punctuation">.</span>data_path<span class="token punctuation">,</span> <span class="token string">'*'</span> <span class="token operator">+</span> extn<span class="token punctuation">)</span>
                image_list <span class="token operator">=</span> image_list <span class="token operator">+</span>  glob<span class="token punctuation">.</span>glob<span class="token punctuation">(</span>image_path<span class="token punctuation">)</span>
            seg_classes <span class="token operator">=</span> args<span class="token punctuation">.</span>num_classes
            
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            print_error_message<span class="token punctuation">(</span><span class="token string">'{} split not yet supported'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>split<span class="token punctuation">)</span><span class="token punctuation">)</span>
            
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        print_error_message<span class="token punctuation">(</span><span class="token string">'{} dataset not yet supported'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>image_list<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        print_error_message<span class="token punctuation">(</span><span class="token string">'No files in directory: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>image_path<span class="token punctuation">)</span><span class="token punctuation">)</span>

    print_info_message<span class="token punctuation">(</span><span class="token string">'# of images for testing: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>image_list<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> args<span class="token punctuation">.</span>model <span class="token operator">==</span> <span class="token string">'espnetv2'</span><span class="token punctuation">:</span>
        <span class="token keyword">from</span> model<span class="token punctuation">.</span>segmentation<span class="token punctuation">.</span>espnetv2 <span class="token keyword">import</span> espnetv2_seg
        args<span class="token punctuation">.</span>classes <span class="token operator">=</span> seg_classes
        model <span class="token operator">=</span> espnetv2_seg<span class="token punctuation">(</span>args<span class="token punctuation">)</span>
    <span class="token keyword">elif</span> args<span class="token punctuation">.</span>model <span class="token operator">==</span> <span class="token string">'dicenet'</span><span class="token punctuation">:</span>
        <span class="token keyword">from</span> model<span class="token punctuation">.</span>segmentation<span class="token punctuation">.</span>dicenet <span class="token keyword">import</span> dicenet_seg
        model <span class="token operator">=</span> dicenet_seg<span class="token punctuation">(</span>args<span class="token punctuation">,</span> classes<span class="token operator">=</span>seg_classes<span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        print_error_message<span class="token punctuation">(</span><span class="token string">'{} network not yet supported'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>model<span class="token punctuation">)</span><span class="token punctuation">)</span>
        exit<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token comment"># mdoel information</span>
    num_params <span class="token operator">=</span> model_parameters<span class="token punctuation">(</span>model<span class="token punctuation">)</span>
    flops <span class="token operator">=</span> compute_flops<span class="token punctuation">(</span>model<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token operator">=</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> args<span class="token punctuation">.</span>im_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> args<span class="token punctuation">.</span>im_size<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    print_info_message<span class="token punctuation">(</span><span class="token string">'FLOPs for an input of size {}x{}: {:.2f} million'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>im_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> args<span class="token punctuation">.</span>im_size<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> flops<span class="token punctuation">)</span><span class="token punctuation">)</span>
    print_info_message<span class="token punctuation">(</span><span class="token string">'# of parameters: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>num_params<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> args<span class="token punctuation">.</span>weights_test<span class="token punctuation">:</span>
        print_info_message<span class="token punctuation">(</span><span class="token string">'Loading model weights'</span><span class="token punctuation">)</span>
        weight_dict <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>args<span class="token punctuation">.</span>weights_test<span class="token punctuation">,</span> map_location<span class="token operator">=</span>torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cpu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>weight_dict<span class="token punctuation">)</span>
        print_info_message<span class="token punctuation">(</span><span class="token string">'Weight loaded successfully'</span><span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        print_error_message<span class="token punctuation">(</span><span class="token string">'weight file does not exist or not specified. Please check: {}'</span><span class="token punctuation">,</span> <span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>weights_test<span class="token punctuation">)</span><span class="token punctuation">)</span>

    num_gpus <span class="token operator">=</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>device_count<span class="token punctuation">(</span><span class="token punctuation">)</span>
    device <span class="token operator">=</span> <span class="token string">'cuda'</span> <span class="token keyword">if</span> num_gpus <span class="token operator">&gt;</span> <span class="token number">0</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span>
    model <span class="token operator">=</span> model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token operator">=</span>device<span class="token punctuation">)</span>

    evaluate<span class="token punctuation">(</span>args<span class="token punctuation">,</span> model<span class="token punctuation">,</span> image_list<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    <span class="token keyword">from</span> commons<span class="token punctuation">.</span>general_details <span class="token keyword">import</span> segmentation_models<span class="token punctuation">,</span> segmentation_datasets

    parser <span class="token operator">=</span> ArgumentParser<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># mdoel details</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--model'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">&quot;espnetv2&quot;</span><span class="token punctuation">,</span> choices<span class="token operator">=</span>segmentation_models<span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Model name'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--weights-test'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Pretrained weights directory.'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--s'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">2.0</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">float</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'scale'</span><span class="token punctuation">)</span>
    <span class="token comment"># dataset details</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--data-path'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">&quot;&quot;</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Data directory'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--dataset'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">'custom'</span><span class="token punctuation">,</span> choices<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'custom'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Dataset name'</span><span class="token punctuation">)</span>
    <span class="token comment"># input details</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--im-size'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> nargs<span class="token operator">=</span><span class="token string">&quot;+&quot;</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Image size for testing (W x H)'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--split'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">'val'</span><span class="token punctuation">,</span> choices<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token string">'val'</span><span class="token punctuation">,</span> <span class="token string">'test'</span><span class="token punctuation">,</span> <span class="token string">'custom'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'data split'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--model-width'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Model width'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--model-height'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Model height'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--channels'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Input channels'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--num-classes'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span>
                        <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'ImageNet classes. Required for loading the base network'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--savedir-name'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">'demo'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">str</span><span class="token punctuation">,</span>
                        <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Save folder location'</span><span class="token punctuation">)</span>

    args <span class="token operator">=</span> parser<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> <span class="token keyword">not</span> args<span class="token punctuation">.</span>weights_test<span class="token punctuation">:</span>
        <span class="token keyword">from</span> model<span class="token punctuation">.</span>weight_locations<span class="token punctuation">.</span>segmentation <span class="token keyword">import</span> model_weight_map

        model_key <span class="token operator">=</span> <span class="token string">'{}_{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>model<span class="token punctuation">,</span> args<span class="token punctuation">.</span>s<span class="token punctuation">)</span>
        dataset_key <span class="token operator">=</span> <span class="token string">'{}_{}x{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>dataset<span class="token punctuation">,</span> args<span class="token punctuation">.</span>im_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> args<span class="token punctuation">.</span>im_size<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">assert</span> model_key <span class="token keyword">in</span> model_weight_map<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'{} does not exist'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>model_key<span class="token punctuation">)</span>
        <span class="token keyword">assert</span> dataset_key <span class="token keyword">in</span> model_weight_map<span class="token punctuation">[</span>model_key<span class="token punctuation">]</span><span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'{} does not exist'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>dataset_key<span class="token punctuation">)</span>
        args<span class="token punctuation">.</span>weights_test <span class="token operator">=</span> model_weight_map<span class="token punctuation">[</span>model_key<span class="token punctuation">]</span><span class="token punctuation">[</span>dataset_key<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'weights'</span><span class="token punctuation">]</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>isfile<span class="token punctuation">(</span>args<span class="token punctuation">.</span>weights_test<span class="token punctuation">)</span><span class="token punctuation">:</span>
            print_error_message<span class="token punctuation">(</span><span class="token string">'weight file does not exist: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>weights_test<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment"># set-up results path</span>
    <span class="token keyword">if</span> args<span class="token punctuation">.</span>dataset <span class="token operator">==</span> <span class="token string">'custom'</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> args<span class="token punctuation">.</span>split <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token string">'val'</span><span class="token punctuation">,</span> <span class="token string">'test'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
            args<span class="token punctuation">.</span>savedir <span class="token operator">=</span> <span class="token string">'results_images/{}_{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>dataset<span class="token punctuation">,</span> args<span class="token punctuation">.</span>split<span class="token punctuation">)</span>
        <span class="token keyword">elif</span> args<span class="token punctuation">.</span>split <span class="token operator">==</span> <span class="token string">'custom'</span><span class="token punctuation">:</span>
            args<span class="token punctuation">.</span>savedir <span class="token operator">=</span> <span class="token string">'results_images/{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>savedir_name<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            print_error_message<span class="token punctuation">(</span><span class="token string">'{} split not yet supported'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>split<span class="token punctuation">)</span><span class="token punctuation">)</span>
            
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        print_error_message<span class="token punctuation">(</span><span class="token string">'{} dataset not yet supported'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>isdir<span class="token punctuation">(</span>args<span class="token punctuation">.</span>savedir<span class="token punctuation">)</span><span class="token punctuation">:</span>
        os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>args<span class="token punctuation">.</span>savedir<span class="token punctuation">)</span>

    <span class="token comment"># This key is used to load the ImageNet weights while training. So, set to empty to avoid errors</span>
    args<span class="token punctuation">.</span>weights <span class="token operator">=</span> <span class="token string">''</span>

    main<span class="token punctuation">(</span>args<span class="token punctuation">)</span>
</code></pre></div><h3 id="テストの実行"><a href="#テストの実行" class="header-anchor">#</a> テストの実行</h3> <p>以下のコマンドでテストを実行します．<br>
以下のコマンドでは，pascalとcityscapesの公開学習済みモデルを使っていますが，<code>--weights-test</code>から任意のモデルを指定することができます．</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token operator">%</span><span class="token operator">%</span>bash
<span class="token comment"># 現在ディレクトリ：/content/drive/My\ Drive/segmentation/EdgeNets</span>
<span class="token comment"># Cityscapes molel</span>
CUDA_VISIBLE_DEVICES<span class="token operator">=</span><span class="token number">0</span> python custom_test_segmentation<span class="token punctuation">.</span>py \
                                <span class="token operator">-</span><span class="token operator">-</span>model espnetv2 \
                                <span class="token operator">-</span><span class="token operator">-</span>s <span class="token number">2.0</span> \
                                <span class="token operator">-</span><span class="token operator">-</span>dataset custom \
                                <span class="token operator">-</span><span class="token operator">-</span>data<span class="token operator">-</span>path <span class="token punctuation">.</span><span class="token operator">/</span>sample_images<span class="token operator">/</span> \
                                <span class="token operator">-</span><span class="token operator">-</span>split custom \
                                <span class="token operator">-</span><span class="token operator">-</span>im<span class="token operator">-</span>size <span class="token number">1024</span> <span class="token number">512</span> \
                                <span class="token operator">-</span><span class="token operator">-</span>num<span class="token operator">-</span>classes <span class="token number">20</span> \
                                 <span class="token operator">-</span><span class="token operator">-</span>weights<span class="token operator">-</span>test model<span class="token operator">/</span>segmentation<span class="token operator">/</span>model_zoo<span class="token operator">/</span>espnetv2<span class="token operator">/</span>espnetv2_s_2<span class="token punctuation">.</span>0_city_1024x512<span class="token punctuation">.</span>pth \
                                 <span class="token operator">-</span><span class="token operator">-</span>savedir<span class="token operator">-</span>name sample_images_city
</code></pre></div><div class="language-python extra-class"><pre class="language-python"><code><span class="token operator">%</span><span class="token operator">%</span>bash
<span class="token comment"># Pascal model</span>
CUDA_VISIBLE_DEVICES<span class="token operator">=</span><span class="token number">0</span> python custom_test_segmentation<span class="token punctuation">.</span>py \
                                <span class="token operator">-</span><span class="token operator">-</span>model espnetv2 \
                                <span class="token operator">-</span><span class="token operator">-</span>s <span class="token number">2.0</span> \
                                <span class="token operator">-</span><span class="token operator">-</span>dataset custom \
                                <span class="token operator">-</span><span class="token operator">-</span>data<span class="token operator">-</span>path <span class="token punctuation">.</span><span class="token operator">/</span>sample_images<span class="token operator">/</span> \
                                <span class="token operator">-</span><span class="token operator">-</span>split custom \
                                <span class="token operator">-</span><span class="token operator">-</span>im<span class="token operator">-</span>size <span class="token number">384</span> <span class="token number">384</span>\
                                <span class="token operator">-</span><span class="token operator">-</span>num<span class="token operator">-</span>classes <span class="token number">21</span> \
                                 <span class="token operator">-</span><span class="token operator">-</span>weights<span class="token operator">-</span>test model<span class="token operator">/</span>segmentation<span class="token operator">/</span>model_zoo<span class="token operator">/</span>espnetv2<span class="token operator">/</span>espnetv2_s_2<span class="token punctuation">.</span>0_pascal_384x384<span class="token punctuation">.</span>pth \
                                 <span class="token operator">-</span><span class="token operator">-</span>savedir<span class="token operator">-</span>name sample_images_pascal
</code></pre></div><h3 id="テストの結果"><a href="#テストの結果" class="header-anchor">#</a> テストの結果</h3> <p>以下がpascalとcityscapes，それぞれの学習済みモデルで直色した画像です．<br>
人単体でやるならば，pascalの方がいいようです．<br>
オリジナル画像<br> <img alt="" data-src="/image/ESPNet_sample3_org.jpg" loading="lazy" class="lazy"></p> <p>cityscapesモデルの着色画像<br> <img alt="" data-src="/image/ESPNet_sample3_city.png" loading="lazy" class="lazy"></p> <p>pascalモデルの着色画像<br> <img alt="" data-src="/image/ESPNet_sample3_pascal.png" loading="lazy" class="lazy"></p> <h2 id="まとめ"><a href="#まとめ" class="header-anchor">#</a> まとめ</h2> <p>本稿ではSemantic Segmentationの中で軽いモデルであるESPNetv2の，デモの起動と公開データセットのCityscapesでの学習を実施しました．<br>
デフォルトのコードでは若干不便なところもあったので，逐次改造したコードを作成しています．<br>
次回からはオリジナルデータで学習することも想定しつつ，人だけを着色するモデルの学習を実施します．</p> <h2 id="参考サイト"><a href="#参考サイト" class="header-anchor">#</a> 参考サイト</h2> <p><a href="https://github.com/sacmehta/EdgeNets" target="_blank" rel="noopener noreferrer">sacmehta/EdgeNets<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a><br> <a href="https://github.com/sacmehta/EdgeNets/blob/master/README_Segmentation.md" target="_blank" rel="noopener noreferrer">sacmehta/EdgeNets/README_Segmentation.md<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> <a href="https://qiita.com/tokyokuma/items/37b1370ea7c84399fbb9" target="_blank" rel="noopener noreferrer">ESPNetで自作データセットを学習してセグメンテーション<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <h2 id="エラー集"><a href="#エラー集" class="header-anchor">#</a> エラー集</h2> <h3 id="エラー1"><a href="#エラー1" class="header-anchor">#</a> エラー1</h3> <p>学習のためにCityscapesセグメンテーションマスクで処理する必要がありますが，<br> <a href="https://github.com/sacmehta/EdgeNets/blob/master/README_Segmentation.md" target="_blank" rel="noopener noreferrer">sacmehta/EdgeNets/README_Segmentation.md<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>に記述されている以下のコマンドをそのまま実行すると，エラーが発生します．<br></p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># 以下のコードではエラーが発生します</span>
<span class="token operator">%</span><span class="token operator">%</span>bash
<span class="token comment"># ディレクトリの移動</span>
cd <span class="token operator">/</span>EdgeNets<span class="token operator">/</span>data_loader<span class="token operator">/</span>segmentation<span class="token operator">/</span>cityscape_scripts
<span class="token comment"># セグメンテーションマスキング</span>
python process_cityscapes<span class="token punctuation">.</span>py
python generate_mappings<span class="token punctuation">.</span>py
ModuleNotFoundError<span class="token punctuation">:</span> No module named <span class="token string">'utilities'</span>
</code></pre></div><p>これは，pythonのコード中に<code>from utilities.print_utils import *</code>が./EdgeNets/utilitiesをインポートしているので，「process_cityscapes.pyとgenerate_mappings.py」を./EdgeNets直下に置く必要があります．</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token operator">%</span><span class="token operator">%</span>bash
<span class="token comment"># 現在ディレクトリ：/content/drive/My\ Drive/segmentation/EdgeNets</span>
<span class="token comment"># cp &lt;移動前&gt; &lt;移動先&gt;</span>
<span class="token comment"># process_cityscapes.pyを/EdgeNets直下にコピー</span>
cp data_loader<span class="token operator">/</span>segmentation<span class="token operator">/</span>cityscape_scripts<span class="token operator">/</span>process_cityscapes<span class="token punctuation">.</span>py process_cityscapes<span class="token punctuation">.</span>py
<span class="token comment"># process_cityscapes.pyを/EdgeNets直下にコピー</span>
cp data_loader<span class="token operator">/</span>segmentation<span class="token operator">/</span>cityscape_scripts<span class="token operator">/</span>generate_mappings<span class="token punctuation">.</span>py generate_mappings<span class="token punctuation">.</span>py
</code></pre></div></div> <div class="content-time" data-v-09525e5c><time datetime="3/15/2021, 12:00:00 AM" class="time-text" data-v-09525e5c>Create Time: 3/15/2021, 12:00:00 AM
    </time> <time datetime="4/12/2021, 9:12:47 AM" class="time-text" data-v-09525e5c>Last Updated: 4/12/2021, 9:12:47 AM
    </time></div></article> <section class="flex-xb main info-nav" data-v-203269c1 data-v-2602fa21><a href="/posts/segmentation02.html" class="flex-xb nav-item" data-v-203269c1><div class="flex-xcc item-img" data-v-203269c1><img data-src="https://www.hamlet-engineer.com/image/color_mask_image.png" loading="lazy" alt="Python + ESPNetをオリジナルデータで学習する(データ生成編)" class="img lazy" data-v-203269c1></div> <article class="flex-ysc item-content" data-v-203269c1><h2 class="content-title" data-v-203269c1>Python + ESPNetをオリジナルデータで学習する(データ生成編)</h2> <div class="content" data-v-203269c1><p>セマンティックセグメンテーションの中で軽いモデルであるESPNetv2を実装します．<br>
本稿ではCityscapesデータセットから人のみを抽出して，仮のオリジナルデータで学習に向けて，データ生成を実施します．<br></p>
</div></article></a> <a href="/posts/frame_mp4.html" class="flex-xb nav-item" data-v-203269c1><div class="flex-xcc item-img" data-v-203269c1><img data-src="https://www.hamlet-engineer.com/image/opencv.png" loading="lazy" alt="Python, OpenCVで好きな動画ファイルからフレームを切り出して保存します" class="img lazy" data-v-203269c1></div> <article class="flex-ysc item-content" data-v-203269c1><h2 class="content-title" data-v-203269c1>Python, OpenCVで好きな動画ファイルからフレームを切り出して保存します</h2> <div class="content" data-v-203269c1><p>Python, OpenCVを用いて，任意の秒数単位で動画のフレームを画像として出力するコードを作成します．</p>
</div></article></a></section> <!----></section></section> <footer class="footer" data-v-8dceedee data-v-98a81704><nav class="link-list" data-v-8dceedee><a href="https://twitter.com/hirasu1231" target="_blank" rel="noopener noreferrer" class="list-item" data-v-8dceedee>Twitter</a><a href="https://github.com/hirasu1231" target="_blank" rel="noopener noreferrer" class="list-item" data-v-8dceedee>Github</a></nav> <a href="/" class="copyright router-link-active" data-v-8dceedee>ハムレット型エンジニアのカンニングノート © 2021</a></footer></section><div class="global-ui"><!----><!----></div></div>
    <script src="/assets/js/app.8498328e.js" defer></script><script src="/assets/js/23.98df4d3e.js" defer></script>
  </body>
</html>
