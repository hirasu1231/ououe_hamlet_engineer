(window.webpackJsonp=window.webpackJsonp||[]).push([[49],{466:function(t,s,a){"use strict";a.r(s);var n=a(2),r=Object(n.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("p",[t._v("Python + CycleGanでオリジナルデータでの学習について，追加情報を記述します．"),a("br")]),t._v(" "),a("ClientOnly",[a("CallInArticleAdsense")],1),t._v(" "),a("p",[t._v("今回はGoogle ColabとGoogle Driveを連携させて，notebook形式で実行してます．"),a("br")]),t._v(" "),a("blockquote",[a("p",[t._v("Google Colaboratory（以下Google Colab）は、Google社が無料で提供している機械学習の教育や研究用の開発環境です。開発環境はJupyter Notebookに似たインターフェースを持ち、Pythonの主要なライブラリがプリインストールされています。"),a("br"),t._v("\n引用元："),a("a",{attrs:{href:"https://interface.cqpub.co.jp/ail01/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Google Colabの使い方"),a("OutboundLink")],1)])]),t._v(" "),a("p",[t._v("最終的に，実写モンハンのディアブロス亜種を原種に戻す試みをします．\n"),a("img",{staticClass:"lazy",attrs:{alt:"","data-src":"/image/diablos_black.jpg",loading:"lazy"}})]),t._v(" "),a("p"),a("div",{staticClass:"table-of-contents"},[a("ul",[a("li",[a("a",{attrs:{href:"#学習経過の観察"}},[t._v("学習経過の観察")])]),a("li",[a("a",{attrs:{href:"#cycleganのloss"}},[t._v("CycleGANのloss")])]),a("li",[a("a",{attrs:{href:"#lossの観察"}},[t._v("lossの観察")])]),a("li",[a("a",{attrs:{href:"#学習時の引数"}},[t._v("学習時の引数")])]),a("li",[a("a",{attrs:{href:"#学習を途中から再開する場合"}},[t._v("学習を途中から再開する場合")])]),a("li",[a("a",{attrs:{href:"#変換時の引数"}},[t._v("変換時の引数")])]),a("li",[a("a",{attrs:{href:"#まとめ"}},[t._v("まとめ")])]),a("li",[a("a",{attrs:{href:"#参考サイト"}},[t._v("参考サイト")])])])]),a("p"),t._v(" "),a("p",[a("a",{attrs:{href:"https://px.a8.net/svt/ejp?a8mat=3HBXCY+4DRW36+50+2HM5Z5",rel:"nofollow"}},[a("img",{attrs:{border:"0",width:"1000",height:"124",alt:"",src:"https://www27.a8.net/svt/bgt?aid=210508450265&wid=001&eno=01&mid=s00000000018015052000&mc=1"}})]),a("img",{attrs:{border:"0",width:"1",height:"1",src:"https://www10.a8.net/0.gif?a8mat=3HBXCY+4DRW36+50+2HM5Z5",alt:""}})]),t._v(" "),a("p",[a("a",{attrs:{href:"https://px.a8.net/svt/ejp?a8mat=3HIN6N+3YAMCY+CO4+6BMG1",rel:"nofollow"}},[a("img",{attrs:{border:"0",width:"1000",height:"124",alt:"",src:"https://www23.a8.net/svt/bgt?aid=210821855239&wid=001&eno=01&mid=s00000001642001062000&mc=1"}})]),a("img",{attrs:{border:"0",width:"1",height:"1",src:"https://www17.a8.net/0.gif?a8mat=3HIN6N+3YAMCY+CO4+6BMG1",alt:""}})]),t._v(" "),a("p",[a("a",{attrs:{href:"https://px.a8.net/svt/ejp?a8mat=3HIN6N+7FBNEA+4AQ0+5YJRM",rel:"nofollow"}},[t._v("全国630店舗以上！もみほぐし・足つぼ・ハンドリフレ・クイックヘッドのリラクゼーション店【りらくる】")]),a("img",{attrs:{border:"0",width:"1",height:"1",src:"https://www15.a8.net/0.gif?a8mat=3HIN6N+7FBNEA+4AQ0+5YJRM",alt:""}})]),t._v(" "),a("h2",{attrs:{id:"学習経過の観察"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#学習経過の観察"}},[t._v("#")]),t._v(" 学習経過の観察")]),t._v(" "),a("p",[t._v("学習を止めないために「display_id 0」としているので、学習中にlossの変化をグラフで可視化できません。")]),t._v(" "),a("p",[t._v("そのため、本稿では"),a("code",[t._v("./checkpoints/＊＊＊/web/images")]),t._v("内にある各epochでの変換結果を見て、学習経過を観察します。")]),t._v(" "),a("p",[a("code",[t._v("./checkpoints/＊＊＊/web/images")]),t._v("内の画像は，下記の4種類が各epochでA・Bそれぞれで出力されます。")]),t._v(" "),a("ul",[a("li",[t._v("＊＊_real_A(or B).png：変換前の画像")]),t._v(" "),a("li",[t._v("＊＊_fake_A(or B).png：変換後の画像")]),t._v(" "),a("li",[t._v("＊＊_rec_A(or B).png：変換後の画像からモデルで復元した画像。real→fake→recという復元の流れとなる。復元できているほど良い。recはreconstruction(復元)を指す。")]),t._v(" "),a("li",[t._v("＊＊_idt_A(or B).png：A→B(or B→A)の変換にA(or B)の画像をいれた時の画像。画像が変換されず保持されていると良い。idtはidentity(同一性)を指す。")])]),t._v(" "),a("p",[t._v("lossは、"),a("code",[t._v("./checkpoints/diablos_gan/loss_log.txt")]),t._v("に記述されています。そこで、loss_log.txtを読み込んでlossの可視化を実行します。")]),t._v(" "),a("h2",{attrs:{id:"cycleganのloss"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#cycleganのloss"}},[t._v("#")]),t._v(" CycleGANのloss")]),t._v(" "),a("p",[t._v("CycleGANのlossは下記の4種類です。")]),t._v(" "),a("ul",[a("li",[t._v("Adversarial Loss「loss_D_A(or B)」：Discriminatorが本物画像を本物し、偽物画像を偽物と判別することを評価するloss")]),t._v(" "),a("li",[t._v("Adversarial Loss「loss_G_A(or B)」：Generator(生成モデル)が生成した偽物の画像（A or B)をDiscriminator(判別モデル)に本物と判定させることを評価するloss")]),t._v(" "),a("li",[t._v("Cycle Consistency Loss「loss_cycle_A(or B)」：real_A→fake_B(or real_B→fake_A)に変換した後に、fake_A→real_B(or fake_B→real_A)へと復元できるかを評価するloss(1番重要なloss)")]),t._v(" "),a("li",[t._v("Identity Mapping Loss「loss_idt_A(or B)」：A→B(or B→A)の変換にA(or B)の画像をいれて、画像が変換されず保持されていることを評価するloss")])]),t._v(" "),a("h2",{attrs:{id:"lossの観察"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#lossの観察"}},[t._v("#")]),t._v(" lossの観察")]),t._v(" "),a("p",[t._v("下記のコードでlossのグラフを閲覧することができますが、Google Colaboratoryでは今回グラフを表示するライブラリの「visdom」が機能しませんので、他の方法を使います。")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ディレクトリの移動")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v("cd "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("content"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("drive"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("My\\ Drive"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("diablos_gan"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("pytorch"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("CycleGAN"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("pix2pix\n!python "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("m visdom"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("server\n")])])]),a("p",[t._v("下記のコードでまず、グラフを描画できるようにデータ整理を実行します。")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ディレクトリの移動")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v("cd "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("content"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("drive"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("My\\ Drive"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("diablos_gan"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("pytorch"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("CycleGAN"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("pix2pix\n")])])]),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pandas "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" pd\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# lossのテキストファイル")]),t._v("\nloss_txt "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"./checkpoints/diablos_gan/loss_log.txt"')]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# テキストファイルの読み込み")]),t._v("\nf "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("loss_txt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'r'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndatalist "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" f"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("readlines"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("close"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2行目を辞書型に変換")]),t._v("\ndict_txt "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" datalist"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("replace"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('","')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('""')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("replace"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('": "')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\":"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("replace"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('", \\""')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("replace"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('")"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('""')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("replace"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"("')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"{\\""')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("replace"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('", \\"\\n"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"}"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nloss_dict "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("eval")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dict_txt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 文字列でのコード実行")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# データフレーム型に変換")]),t._v("\ndf_loss "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pd"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("DataFrame"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("loss_dict"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("index"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2行目以降の処理")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" i "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("len")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("datalist"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2行目以降を辞書型に変換")]),t._v("\n    dict_txt "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" datalist"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("replace"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('","')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('""')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("replace"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('": "')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\":"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("replace"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('", \\""')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("replace"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('")"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('""')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("replace"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"("')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"{\\""')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("replace"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('", \\"\\n"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"}"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    loss_dict "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("eval")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dict_txt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 文字列でのコード実行")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# データフレーム型に変換")]),t._v("\n    df_dict "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pd"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("DataFrame"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("loss_dict"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("index"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# df_lossに結合")]),t._v("\n    df_loss "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pd"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("concat"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("df_loss"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" df_dict"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" axis"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# indexを追加")]),t._v("\ndf_loss "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" df_loss"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reset_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndisplay"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df_loss"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("head"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("下記のコードでlossの可視化を実行します。")]),t._v(" "),a("p",[t._v("出力結果より、「Cycle Consistency Loss(loss_cycle_A・loss_cycle_B)」を見ると、lossが徐々に下がる傾向にあるので、学習は進んでいることがわかります。")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" matplotlib"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pyplot "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" plt\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" seaborn "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" sns\nsns"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("set")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("style"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'darkgrid'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 4行2列のグラフを作成")]),t._v("\nfig"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ax1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ax2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ax3"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ax4"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ax5"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ax6"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ax7"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ax8"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" plt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("subplots"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" figsize"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("24")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Adversarial Loss(D)")]),t._v("\nsns"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lineplot"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'index'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'D_A'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" data"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("df_loss"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ax"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("ax1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("set_title"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'loss_D_A'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nsns"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lineplot"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'index'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'D_B'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" data"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("df_loss"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ax"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("ax2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("set_title"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'loss_D_B'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Adversarial Loss(G)")]),t._v("\nsns"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lineplot"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'index'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'G_A'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" data"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("df_loss"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ax"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("ax3"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("set_title"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'loss_G_A'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nsns"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lineplot"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'index'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'G_B'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" data"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("df_loss"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ax"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("ax4"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("set_title"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'loss_G_B'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Cycle Consistency Loss")]),t._v("\nsns"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lineplot"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'index'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'cycle_A'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" data"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("df_loss"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ax"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("ax5"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("set_title"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'loss_cycle_A'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nsns"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lineplot"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'index'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'cycle_B'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" data"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("df_loss"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ax"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("ax6"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("set_title"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'loss_cycle_B'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Identity Mapping Loss")]),t._v("\nsns"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lineplot"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'index'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'idt_A'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" data"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("df_loss"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ax"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("ax7"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("set_title"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'loss_idt_A'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nsns"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lineplot"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'index'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'idt_B'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" data"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("df_loss"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ax"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("ax8"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("set_title"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'loss_idt_B'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h2",{attrs:{id:"学習時の引数"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#学習時の引数"}},[t._v("#")]),t._v(" 学習時の引数")]),t._v(" "),a("p",[t._v("下記に学習時の引数の意味を示します。")]),t._v(" "),a("ul",[a("li",[t._v("dataroot：CycleGANで学習するデータセット")]),t._v(" "),a("li",[t._v("n_epochs：初期学習率(0.0002)で学習するエポック数")]),t._v(" "),a("li",[t._v("n_epochs_decay：学習率を下げるエポック数(n_epochsに加算されます)")]),t._v(" "),a("li",[t._v("name：モデルを保存するための、"),a("code",[t._v("./checkpoints")]),t._v("の中でのディレクトリ名")]),t._v(" "),a("li",[t._v("model：モデルの学習方法の指定")]),t._v(" "),a("li",[t._v("display_id：学習経過の可視化の設定です。0にしないと、途中で学習が止まります。")]),t._v(" "),a("li",[t._v("gpu_ids：使用するGPUのID")]),t._v(" "),a("li",[t._v("no_dropout：デフォルトで"),a("code",[t._v("no_dropout")]),t._v("となります。過学習を防ぐドロップアウトを使用しないフラグ。テスト実行時も、モデル学習の設定に合わせる必要があります。")])]),t._v(" "),a("p",[t._v("学習画像は、デフォルトで256x256の正方形に変換されます。")]),t._v(" "),a("p",[t._v("学習画像のサイズとアスペクト比を保持したい場合は、下記の引数で設定します。")]),t._v(" "),a("ul",[a("li",[t._v("preprocess：前処理の設定です。デフォルトでは、256x256の正方形に変換されます。また、いくつかのフラグがありますが、noneにすると、変換画像のサイズとアスペクト比を保持されます。")])]),t._v(" "),a("p",[t._v("ただし、「preprocess none」では、GPUの負荷も重くなり、他のモデルで「1920x1280」と「1080x720」の画像を変換した時は、ColabのハイメモリーGPUでもメモリーオーバーしました。")]),t._v(" "),a("p",[t._v("また、学習率への理解は、モデルを修正する幅と捉えてください。")]),t._v(" "),a("p",[t._v("下記のコードでは、初期学習率(0.0002)という一定の幅で10epoch分(n_epochs)だけモデルをざっくり修正していって、最後の100epoch分(n_epochs_decay)分は小さい幅で微調整の修正をするイメージです。")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ディレクトリの移動")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v("cd "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("content"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("drive"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("My\\ Drive"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("diablos_gan"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("pytorch"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("CycleGAN"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("pix2pix\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# オリジナルデータの学習")]),t._v("\n!python train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("py "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("dataroot "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("datasets"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("diablos_gan \\\n                 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("n_epochs  "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("30")]),t._v(" \\\n                 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("n_epochs_decay "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),t._v(" \\\n                 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("name diablos_gan \\\n                 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("model cycle_gan \\\n                 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("display_id "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("gpu_ids "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("\n")])])]),a("h2",{attrs:{id:"学習を途中から再開する場合"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#学習を途中から再開する場合"}},[t._v("#")]),t._v(" 学習を途中から再開する場合")]),t._v(" "),a("p",[t._v("学習を途中から再開する場合、下記のコードを参考にしてください。")]),t._v(" "),a("p",[t._v("下記のコードでは、「50epoch時点から100epochまで初期学習率で学習して、学習率を下げて更に50epoch分学習させる」場合を想定して記述しています。")]),t._v(" "),a("p",[t._v("下記に引数の意味を示します。")]),t._v(" "),a("ul",[a("li",[t._v("epoch_count：途中から学習を開始するepoch数")]),t._v(" "),a("li",[t._v("continue_train：途中から学習を始める場合のフラグ")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ディレクトリの移動")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v("cd "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("content"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("drive"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("My\\ Drive"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("diablos_gan"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("pytorch"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("CycleGAN"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("pix2pix\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# オリジナルデータの学習")]),t._v("\n!python train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("py "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("dataroot "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("datasets"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("diablos_gan \\\n                 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("n_epochs  "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),t._v(" \\\n                  "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("n_epochs_decay "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("50")]),t._v(" \\\n                 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("name diablos_gan \\\n                 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("model cycle_gan \\\n                 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("display_id "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("gpu_ids "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" \\\n                 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("epoch_count "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("50")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("continue_train\n")])])]),a("h2",{attrs:{id:"変換時の引数"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#変換時の引数"}},[t._v("#")]),t._v(" 変換時の引数")]),t._v(" "),a("p",[t._v("下記に変換時の引数の意味を示します。")]),t._v(" "),a("ul",[a("li",[t._v("name：変換モデル名(/checkpointsの中にある変換モデルのディレクトリ名)。変換モデルの名前はlatest_net_G.pthとしてください。"),a("br"),t._v("\nAのデータ -> Bのデータに変換するモデルは"),a("code",[t._v("＊＊＊_G_A.pth")]),t._v("で、Bのデータ -> Aのデータに変換するのモデルは"),a("code",[t._v("＊＊＊_G_B.pth")]),t._v("です。"),a("br"),t._v("\n※「Aのデータ」は白黒画像、「Bのデータ」はカラー画像です。\n--results_dir：変換後の画像を格納するディレクトリ名("),a("code",[t._v("./results_dirの引数/nameの引数/")]),t._v("に格納される)")]),t._v(" "),a("li",[t._v("preprocess：前処理の設定です。デフォルトでは、256x256の正方形に変換されます。また、いくつかのフラグがありますが、noneにすると、変換画像のサイズとアスペクト比を保持されます。")]),t._v(" "),a("li",[t._v("model：変換を実行する場合はtestと記述する。")]),t._v(" "),a("li",[t._v("no_dropout：学習時で"),a("code",[t._v("no_dropout")]),t._v("となっています。過学習を防ぐドロップアウトを使用しないフラグ。テスト実行時も、モデル学習の設定に合わせる必要があります。")])]),t._v(" "),a("p",[t._v("ただし、「preprocess none」では、GPUの負荷も重くなり、他のモデルで「1920x1280」と「1080x720」の画像を変換した時は、ColabのハイメモリーGPUでもメモリーオーバーしました。")]),t._v(" "),a("h2",{attrs:{id:"まとめ"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#まとめ"}},[t._v("#")]),t._v(" まとめ")]),t._v(" "),a("p",[t._v("Python + CycleGanでオリジナルデータでの学習について，追加情報を記述しました．")]),t._v(" "),a("h2",{attrs:{id:"参考サイト"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#参考サイト"}},[t._v("#")]),t._v(" 参考サイト")]),t._v(" "),a("p",[a("a",{attrs:{href:"https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix",target:"_blank",rel:"noopener noreferrer"}},[t._v("junyanz/pytorch-CycleGAN-and-pix2pix"),a("OutboundLink")],1),a("br")]),t._v(" "),a("p",[a("a",{attrs:{href:"https://aidiary.hatenablog.com/entry/20180324/1521896184",target:"_blank",rel:"noopener noreferrer"}},[t._v("PyTorch (15) CycleGAN (horse2zebra)"),a("OutboundLink")],1)]),t._v(" "),a("p",[a("a",{attrs:{href:"https://farml1.com/cyclegan_ukiyoe_movie/",target:"_blank",rel:"noopener noreferrer"}},[t._v("浮世絵風の動画をつくってみる【CycleGAN】"),a("OutboundLink")],1)]),t._v(" "),a("p",[a("a",{attrs:{href:"https://qiita.com/kyoshidajp/items/57ae371b3f5d8a84fb13",target:"_blank",rel:"noopener noreferrer"}},[t._v("Python の eval と exec"),a("OutboundLink")],1)]),t._v(" "),a("p",[a("a",{attrs:{href:"https://px.a8.net/svt/ejp?a8mat=3HBXCY+4DRW36+50+2HM5Z5",rel:"nofollow"}},[a("img",{attrs:{border:"0",width:"1000",height:"124",alt:"",src:"https://www27.a8.net/svt/bgt?aid=210508450265&wid=001&eno=01&mid=s00000000018015052000&mc=1"}})]),a("img",{attrs:{border:"0",width:"1",height:"1",src:"https://www10.a8.net/0.gif?a8mat=3HBXCY+4DRW36+50+2HM5Z5",alt:""}})]),t._v(" "),a("p",[a("a",{attrs:{href:"https://px.a8.net/svt/ejp?a8mat=3HIN6N+3YAMCY+CO4+6BMG1",rel:"nofollow"}},[a("img",{attrs:{border:"0",width:"1000",height:"124",alt:"",src:"https://www23.a8.net/svt/bgt?aid=210821855239&wid=001&eno=01&mid=s00000001642001062000&mc=1"}})]),a("img",{attrs:{border:"0",width:"1",height:"1",src:"https://www17.a8.net/0.gif?a8mat=3HIN6N+3YAMCY+CO4+6BMG1",alt:""}})]),t._v(" "),a("p",[a("a",{attrs:{href:"https://px.a8.net/svt/ejp?a8mat=3HIN6N+7FBNEA+4AQ0+5YJRM",rel:"nofollow"}},[t._v("全国630店舗以上！もみほぐし・足つぼ・ハンドリフレ・クイックヘッドのリラクゼーション店【りらくる】")]),a("img",{attrs:{border:"0",width:"1",height:"1",src:"https://www15.a8.net/0.gif?a8mat=3HIN6N+7FBNEA+4AQ0+5YJRM",alt:""}})]),t._v(" "),a("ClientOnly",[a("CallInArticleAdsense")],1)],1)}),[],!1,null,null,null);s.default=r.exports}}]);