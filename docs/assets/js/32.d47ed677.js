(window.webpackJsonp=window.webpackJsonp||[]).push([[32],{446:function(t,s,a){"use strict";a.r(s);var n=a(2),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("p",[t._v("TransformerTTS + MelGANでテキストからの音声の生成の学習を実施します．"),a("br")]),t._v(" "),a("ClientOnly",[a("CallInArticleAdsense")],1),t._v(" "),a("p"),a("div",{staticClass:"table-of-contents"},[a("ul",[a("li",[a("a",{attrs:{href:"#google-colabのファイル構成"}},[t._v("Google Colabのファイル構成")])]),a("li",[a("a",{attrs:{href:"#google-driveと連携"}},[t._v("Google Driveと連携")])]),a("li",[a("a",{attrs:{href:"#モジュールのインストール"}},[t._v("モジュールのインストール")])]),a("li",[a("a",{attrs:{href:"#学習データ-ljspeech"}},[t._v("学習データ(LJSpeech)")])]),a("li",[a("a",{attrs:{href:"#学習データのダウンロード"}},[t._v("学習データのダウンロード")])]),a("li",[a("a",{attrs:{href:"#configファイルの作成"}},[t._v("configファイルの作成")])]),a("li",[a("a",{attrs:{href:"#学習の実行-aligner-model"}},[t._v("学習の実行(Aligner Model)")]),a("ul",[a("li",[a("a",{attrs:{href:"#step1-データセットの作成-約5時間"}},[t._v("Step1 データセットの作成(約5時間)")])]),a("li",[a("a",{attrs:{href:"#step2-学習実行-約20時間"}},[t._v("Step2 学習実行(約20時間)")])])])]),a("li",[a("a",{attrs:{href:"#学習の実行-tts-model"}},[t._v("学習の実行(TTS Model)")]),a("ul",[a("li",[a("a",{attrs:{href:"#step1-alignmentデータセットの計算-約20時間"}},[t._v("Step1 alignmentデータセットの計算(約20時間)")])]),a("li",[a("a",{attrs:{href:"#step2-学習実行-約30時間"}},[t._v("Step2 学習実行(約30時間)")])])])]),a("li",[a("a",{attrs:{href:"#transformerttsの実行"}},[t._v("TransformerTTSの実行")])]),a("li",[a("a",{attrs:{href:"#melgan"}},[t._v("MelGAN")])]),a("li",[a("a",{attrs:{href:"#まとめ"}},[t._v("まとめ")])]),a("li",[a("a",{attrs:{href:"#参考サイト"}},[t._v("参考サイト")])])])]),a("p"),t._v(" "),a("p",[a("a",{attrs:{href:"https://px.a8.net/svt/ejp?a8mat=3HBXCY+4DRW36+50+2HM5Z5",rel:"nofollow"}},[a("img",{attrs:{border:"0",width:"1000",height:"124",alt:"",src:"https://www27.a8.net/svt/bgt?aid=210508450265&wid=001&eno=01&mid=s00000000018015052000&mc=1"}})]),a("img",{attrs:{border:"0",width:"1",height:"1",src:"https://www10.a8.net/0.gif?a8mat=3HBXCY+4DRW36+50+2HM5Z5",alt:""}})]),t._v(" "),a("p",[a("a",{attrs:{href:"https://px.a8.net/svt/ejp?a8mat=3HIN6N+3YAMCY+CO4+6BMG1",rel:"nofollow"}},[a("img",{attrs:{border:"0",width:"1000",height:"124",alt:"",src:"https://www23.a8.net/svt/bgt?aid=210821855239&wid=001&eno=01&mid=s00000001642001062000&mc=1"}})]),a("img",{attrs:{border:"0",width:"1",height:"1",src:"https://www17.a8.net/0.gif?a8mat=3HIN6N+3YAMCY+CO4+6BMG1",alt:""}})]),t._v(" "),a("p",[a("a",{attrs:{href:"https://px.a8.net/svt/ejp?a8mat=3HIN6N+7FBNEA+4AQ0+5YJRM",rel:"nofollow"}},[t._v("全国630店舗以上！もみほぐし・足つぼ・ハンドリフレ・クイックヘッドのリラクゼーション店【りらくる】")]),a("img",{attrs:{border:"0",width:"1",height:"1",src:"https://www15.a8.net/0.gif?a8mat=3HIN6N+7FBNEA+4AQ0+5YJRM",alt:""}})]),t._v(" "),a("h2",{attrs:{id:"google-colabのファイル構成"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#google-colabのファイル構成"}},[t._v("#")]),t._v(" Google Colabのファイル構成")]),t._v(" "),a("p",[t._v("プロジェクトディレクトリはSpeech_Synthesisとしています．度々，省略しています．")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("Speech_Synthesis\n├── /TransformerTTS\n├── /melgan\n└── TransformerTTS.ipynb <- 実行用ノートブック\n")])])]),a("h2",{attrs:{id:"google-driveと連携"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#google-driveと連携"}},[t._v("#")]),t._v(" Google Driveと連携")]),t._v(" "),a("p",[t._v("Google ColabとGoogle Driveを連携させて，gitから"),a("a",{attrs:{href:"https://github.com/as-ideas/TransformerTTS.git",target:"_blank",rel:"noopener noreferrer"}},[t._v("as-ideas/TransformerTTS"),a("OutboundLink")],1),t._v("・"),a("a",{attrs:{href:"https://github.com/seungwonpark/melgan.git",target:"_blank",rel:"noopener noreferrer"}},[t._v("seungwonpark/melgan"),a("OutboundLink")],1),t._v("をダウンロードします．")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Google ColabとGoogle Driveを連携")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" google"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("colab "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" drive\ndrive"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mount"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'/content/drive'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ディレクトリの移動")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v("cd "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("content"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("drive"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("My\\ Drive"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("Speech_Synthesis\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# gitのダウンロード")]),t._v("\n!git clone https"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("//")]),t._v("github"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("ideas"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("TransformerTTS"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("git\n!git clone https"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("//")]),t._v("github"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("seungwonpark"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("melgan"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("git\n!ls\n")])])]),a("h2",{attrs:{id:"モジュールのインストール"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#モジュールのインストール"}},[t._v("#")]),t._v(" モジュールのインストール")]),t._v(" "),a("p",[t._v("下記のコードでモジュールのインストールします．")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("!apt"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("get install "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("y espeak\n!pip install "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("r TransformerTTS"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("requirements"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("txt\n!pip unstall tqdm\n!pip install tqdm"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4.40")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v(".1")]),t._v("\n")])])]),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 作業ディレクトリへ移動")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v("cd "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("content"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("drive"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("My\\ Drive"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("Speech_Synthesis"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("\n!ls\n")])])]),a("h2",{attrs:{id:"学習データ-ljspeech"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#学習データ-ljspeech"}},[t._v("#")]),t._v(" 学習データ(LJSpeech)")]),t._v(" "),a("p",[t._v("本稿では，LJSpeechというデータを使用します．")]),t._v(" "),a("blockquote",[a("p",[t._v("LJSpeech は、keithito さんによって2017年に公開された、単一女性話者によって録音された24時間程度の英語音声コーパスです。なぜ近年よく使われて始めているのかと言うと（2019年6月時点でGoogle scholarで27件の引用）、End-to-end 音声合成の研究に用いるデータセットとして、LJSpeechは最もといっていいほど手軽に手に入るからだと考えています。LJSpeech は public domainで配布されており、利用に制限もありませんし、企業、教育機関、個人など様々な立場から自由に使用することができます。End-to-end 音声合成（厳密にはseq2seq モデルの学習）は一般に大量のデータが必要なことが知られていますが、その要件も満たしていることから、特にEnd-to-end音声合成の研究で用いられている印象を受けます。最近だと、FastSpeech: Fast, Robust and Controllable Text to Speech にも使われていましたね。"),a("br"),t._v("引用元:"),a("a",{attrs:{href:"https://r9y9.github.io/blog/2019/06/11/ljspeech/",target:"_blank",rel:"noopener noreferrer"}},[t._v("LJSpeech は価値のあるデータセットですが、ニューラルボコーダの品質比較には向かないと思います"),a("OutboundLink")],1)])]),t._v(" "),a("h2",{attrs:{id:"学習データのダウンロード"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#学習データのダウンロード"}},[t._v("#")]),t._v(" 学習データのダウンロード")]),t._v(" "),a("p",[t._v("下記のコードで学習データをダウンロードします．")]),t._v(" "),a("div",{staticClass:"language-init extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("データディレクトリ名\n├── metadata.csv\n└── /wavs <- 音声データ\n        ├── LJ007-oo48.wav\n        └── (省略)\n")])])]),a("p",[t._v("metadata.csvは各wavファイルのセリフが格納されている．区切り文字は"),a("code",[t._v("|")]),t._v("となっている．")]),t._v(" "),a("p",[t._v("下記にmetadata.csvの中身の例を示す．")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("# ファイル名|セリフ1|セリフ2\n# セリフ1==セリフ2\nLJ001-0001|Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the Exhibition|Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the Exhibition\nLJ001-0002|in being comparatively modern.|in being comparatively modern.\nLJ001-0003|For although the Chinese took impressions from wood blocks engraved in relief for centuries before the woodcutters of the Netherlands, by a similar process|For although the Chinese took impressions from wood blocks engraved in relief for centuries before the woodcutters of the Netherlands, by a similar process\nLJ001-0004|produced the block books, which were the immediate predecessors of the true printed book,|produced the block books, which were the immediate predecessors of the true printed book,\n")])])]),a("p",[t._v("下記のコードで学習データをダウンロードします．")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v("cd "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("content"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("drive"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("My\\ Drive"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("Speech_Synthesis"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("TransformerTTS\n!wget https"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("//")]),t._v("data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keithito"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("data"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("speech"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("LJSpeech"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tar"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bz2\n!tar "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("jxvf LJSpeech"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tar"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bz2 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" null\n!ls\n")])])]),a("h2",{attrs:{id:"configファイルの作成"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#configファイルの作成"}},[t._v("#")]),t._v(" configファイルの作成")]),t._v(" "),a("p",[t._v("下記のコードで学習の設定を整理したファイル"),a("code",[t._v("config/training_config.yaml")]),t._v("を作成します．")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# analyze_pdf_text_bert.pyの書き込み")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v("writefile config"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("training_config"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("yaml\npaths"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# PATHS: change accordingly")]),t._v("\n  wav_directory"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'LJSpeech-1.1/wavs'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# path to directory cointaining the wavs")]),t._v("\n  metadata_path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'LJSpeech-1.1/metadata.csv'")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# name of metadata file under wav_directory")]),t._v("\n  log_directory"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'LJSpeech-1.1/logs'")]),t._v("   "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# weights and logs are stored here")]),t._v("\n  train_data_directory"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'LJSpeech-1.1/train'")]),t._v("   "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# training data is stored here")]),t._v("\n\nnaming"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  data_name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" ljspeech "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# raw data naming for default data reader (select function from data/metadata_readers.py)")]),t._v("\n  audio_settings_name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" MelGAN_default\n  text_settings_name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" Stress_NoBreathing\n  aligner_settings_name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" alinger_extralayer_layernorm\n  tts_settings_name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" tts_swap_conv_dims\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# TRAINING DATA SETTINGS")]),t._v("\ntraining_data_settings"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  n_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),t._v("\n  mel_start_value"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v(".5")]),t._v("\n  mel_end_value"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v(".5")]),t._v("\n  max_mel_len"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" 1_200\n  min_mel_len"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("80")]),t._v("\n  bucket_boundaries"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("200")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("300")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("400")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("500")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("600")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("700")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("800")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("900")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1000")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1200")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# mel bucketing")]),t._v("\n  bucket_batch_sizes"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("64")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("32")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("25")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("21")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("16")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("14")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n  val_bucket_batch_size"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# AUDIO SETTINGS")]),t._v("\naudio_settings"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  sampling_rate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("22050")]),t._v("\n  n_fft"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1024")]),t._v("\n  mel_channels"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("80")]),t._v("\n  hop_length"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("256")]),t._v("\n  win_length"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1024")]),t._v("\n  f_min"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("\n  f_max"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("8000")]),t._v("\n  normalizer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" MelGAN                 "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# which mel normalization to use from utils.audio.py [MelGAN or WaveRNN]")]),t._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# SILENCE CUTTING")]),t._v("\n  trim_silence_top_db"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("60")]),t._v("\n  trim_silence"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n  trim_long_silences"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Params for trimming long silences, from https://github.com/resemble-ai/Resemblyzer/blob/master/resemblyzer/hparams.py")]),t._v("\n  vad_window_length"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("30")]),t._v("      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# In milliseconds")]),t._v("\n  vad_moving_average_width"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),t._v("\n  vad_max_silence_length"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v("\n  vad_sample_rate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("16000")]),t._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Wav normalization")]),t._v("\n  norm_wav"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n  target_dBFS"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("30")]),t._v("\n  int16_max"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("32767")]),t._v("\n\ntext_settings"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# TOKENIZER")]),t._v("\n  phoneme_language"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'en-us'")]),t._v("\n  with_stress"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("                  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# use stress symbols in phonemization")]),t._v("\n  model_breathing"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" false           "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# add a token for the initial breathing")]),t._v("\n\naligner_settings"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ARCHITECTURE")]),t._v("\n  decoder_model_dimension"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("256")]),t._v("\n  encoder_model_dimension"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("256")]),t._v("\n  decoder_num_heads"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# the length of this defines the number of layers")]),t._v("\n  encoder_num_heads"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# the length of this defines the number of layers")]),t._v("\n  encoder_feed_forward_dimension"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("512")]),t._v("\n  decoder_feed_forward_dimension"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("512")]),t._v("\n  decoder_prenet_dimension"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("256")]),t._v("\n  encoder_prenet_dimension"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("256")]),t._v("\n  encoder_max_position_encoding"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10000")]),t._v("\n  decoder_max_position_encoding"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10000")]),t._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# LOSSES")]),t._v("\n  stop_loss_scaling"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),t._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# TRAINING")]),t._v("\n  dropout_rate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.1")]),t._v("\n  decoder_prenet_dropout"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.1")]),t._v("\n  learning_rate_schedule"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.0e-4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n  reduction_factor_schedule"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("80_000"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("100_000"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("130_000"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n  max_steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" 260_000\n  force_encoder_diagonal_steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("500")]),t._v("\n  force_decoder_diagonal_steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" 7_000\n  extract_attention_weighted"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# weighted average between last layer decoder attention heads when extracting durations")]),t._v("\n  debug"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# LOGGING")]),t._v("\n  validation_frequency"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" 5_000\n  weights_save_frequency"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" 5_000\n  train_images_plotting_frequency"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" 1_000\n  keep_n_weights"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("\n  keep_checkpoint_every_n_hours"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v("\n  n_steps_avg_losses"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("500")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" 1_000"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" 5_000"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# command line display of average loss values for the last n steps")]),t._v("\n  prediction_start_step"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" 10_000 "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# step after which to predict durations at validation time")]),t._v("\n  prediction_frequency"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" 5_000\n  test_stencences"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" aligner_test_sentences"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("txt\n\ntts_settings"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ARCHITECTURE")]),t._v("\n  decoder_model_dimension"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("384")]),t._v("\n  encoder_model_dimension"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("384")]),t._v("\n  decoder_num_heads"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# the length of this defines the number of layers")]),t._v("\n  encoder_num_heads"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# the length of this defines the number of layers")]),t._v("\n  encoder_feed_forward_dimension"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" null\n  decoder_feed_forward_dimension"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" null\n  encoder_attention_conv_filters"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1536")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("384")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n  decoder_attention_conv_filters"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1536")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("384")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n  encoder_attention_conv_kernel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("\n  decoder_attention_conv_kernel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("\n  encoder_max_position_encoding"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2000")]),t._v("\n  decoder_max_position_encoding"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10000")]),t._v("\n  encoder_dense_blocks"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("\n  decoder_dense_blocks"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("\n  transposed_attn_convs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# if True, convolutions after MHA are over time.")]),t._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# STATS PREDICTORS ARCHITECTURE")]),t._v("\n  duration_conv_filters"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("256")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("226")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n  pitch_conv_filters"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("256")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("226")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n  duration_kernel_size"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("\n  pitch_kernel_size"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# TRAINING")]),t._v("\n  predictors_dropout"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.1")]),t._v("\n  dropout_rate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.1")]),t._v("\n  learning_rate_schedule"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.0e-4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n  max_steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" 100_000\n  debug"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# LOGGING")]),t._v("\n  validation_frequency"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" 5_000\n  prediction_frequency"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" 5_000\n  weights_save_frequency"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" 5_000\n  weights_save_starting_step"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" 5_000\n  train_images_plotting_frequency"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" 1_000\n  keep_n_weights"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v("\n  keep_checkpoint_every_n_hours"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v("\n  n_steps_avg_losses"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("500")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" 1_000"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" 5_000"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# command line display of average loss values for the last n steps")]),t._v("\n  prediction_start_step"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" 4_000\n  text_prediction"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" test_sentences"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("txt\n")])])]),a("h2",{attrs:{id:"学習の実行-aligner-model"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#学習の実行-aligner-model"}},[t._v("#")]),t._v(" 学習の実行(Aligner Model)")]),t._v(" "),a("h3",{attrs:{id:"step1-データセットの作成-約5時間"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#step1-データセットの作成-約5時間"}},[t._v("#")]),t._v(" Step1 データセットの作成(約5時間)")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ディレクトリの移動")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v("cd "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("content"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("drive"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("My\\ Drive"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("Speech_Synthesis"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("TransformerTTS\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# データセットの作成")]),t._v("\n!python create_training_data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("py "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("config config"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("training_config"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("yaml\n")])])]),a("h3",{attrs:{id:"step2-学習実行-約20時間"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#step2-学習実行-約20時間"}},[t._v("#")]),t._v(" Step2 学習実行(約20時間)")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("!python train_aligner"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("py "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("config config"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("training_config"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("yaml\n")])])]),a("h2",{attrs:{id:"学習の実行-tts-model"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#学習の実行-tts-model"}},[t._v("#")]),t._v(" 学習の実行(TTS Model)")]),t._v(" "),a("h3",{attrs:{id:"step1-alignmentデータセットの計算-約20時間"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#step1-alignmentデータセットの計算-約20時間"}},[t._v("#")]),t._v(" Step1 alignmentデータセットの計算(約20時間)")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ディレクトリの移動")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v("cd "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("content"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("drive"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("My\\ Drive"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("Speech_Synthesis"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("TransformerTTS\n\n!python extract_durations"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("py "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("config config"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("training_config"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("yaml\n")])])]),a("h3",{attrs:{id:"step2-学習実行-約30時間"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#step2-学習実行-約30時間"}},[t._v("#")]),t._v(" Step2 学習実行(約30時間)")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ディレクトリの移動")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v("cd "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("content"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("drive"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("My\\ Drive"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("Speech_Synthesis"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("TransformerTTS\n\n!python train_tts"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("py "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("config config"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("training_config"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("yaml\n")])])]),a("h2",{attrs:{id:"transformerttsの実行"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#transformerttsの実行"}},[t._v("#")]),t._v(" TransformerTTSの実行")]),t._v(" "),a("p",[t._v("次のコードでTransformerの学習済みモデルの音声合成を実施します．")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# パスの整理")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pathlib "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Path\nMelGAN_path "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'melgan/'")]),t._v("\nTTS_path "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'TransformerTTS/'")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# モジュールのインポート先を追加")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" sys\nsys"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("append"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("TTS_path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("models "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" ForwardTransformer\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("audio "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Audio\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" scipy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("io"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("wavfile "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" write\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" IPython"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("display "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" ipd\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 学習モデルの読み込み")]),t._v("\nmodel "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ForwardTransformer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("load_model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'TransformerTTS/LJSpeech-1.1/logs/ljspeech/tts_swap_conv_dims.alinger_extralayer_layernorm/weights/step_100000/'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\naudio "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Audio"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_config"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("config"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 音声合成する文章の入力")]),t._v("\nsentence "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Scientists at the CERN laboratory, say they have discovered a new particle.'")]),t._v("\nout_normal "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("predict"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sentence"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# wav音声データに変換")]),t._v("\nwav "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" audio"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reconstruct_waveform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("out_normal"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'mel'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("numpy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("T"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# wav音声データの出力")]),t._v("\nwrite"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'TransformerTTS_LJSpeech_100000.wav'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("config"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'sampling_rate'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" wav"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# wavの再生")]),t._v("\nipd"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("display"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ipd"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Audio"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("wav"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" rate"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("config"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'sampling_rate'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[a("audio",{attrs:{src:"/audio/TransformerTTS_LJSpeech_100000.wav",controls:""}})]),t._v(" "),a("h2",{attrs:{id:"melgan"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#melgan"}},[t._v("#")]),t._v(" MelGAN")]),t._v(" "),a("p",[t._v("次のコードでMelGANの学習済みモデルの音声合成を実施します．")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 作業ディレクトリへ移動")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v("cd "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("content"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("drive"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("My\\ Drive"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("Speech_Synthesis\n!ls\n")])])]),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# パスの初期化")]),t._v("\nsys"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("remove"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("TTS_path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nsys"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("modules"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pop"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'model'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 学習済みモデルの読み込み")]),t._v("\nsys"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("append"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("MelGAN_path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" torch\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" numpy "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" np\n\nvocoder "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hub"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("load"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'seungwonpark/melgan'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'melgan'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nvocoder"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("eval")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nmel "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tensor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("out_normal"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'mel'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("numpy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("T"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("newaxis"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 音声合成の実行")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cuda"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("is_available"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    vocoder "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" vocoder"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cuda"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    mel "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" mel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cuda"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("no_grad"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    audio "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" vocoder"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("inference"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("mel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# wav音声データの出力")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" scipy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("io"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("wavfile "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" write\nwrite"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'melgan_LJSpeech_100000.wav'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("22050")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" audio"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cpu"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("numpy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# jupyter上で音声再生")]),t._v("\nipd"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("display"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ipd"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Audio"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("audio"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cpu"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("numpy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" rate"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("22050")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[a("audio",{attrs:{src:"/audio/melgan_LJSpeech_100000.wav",controls:""}})]),t._v(" "),a("h2",{attrs:{id:"まとめ"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#まとめ"}},[t._v("#")]),t._v(" まとめ")]),t._v(" "),a("p",[t._v("英語ですが，TransformerTTS + MelGANでテキストからの音声の生成の学習を実施しました．")]),t._v(" "),a("p",[t._v("次は，日本語のモデルを作成or実装したかったのですが，学習時にバックエンドで使用するespeakがデフォルトで日本語に対応していないため，抜本的な対策が必要となります．")]),t._v(" "),a("p",[t._v("本稿の内容で続けるか，別のモデルを使用します．")]),t._v(" "),a("br"),t._v(" "),a("h2",{attrs:{id:"参考サイト"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#参考サイト"}},[t._v("#")]),t._v(" 参考サイト")]),t._v(" "),a("p",[a("a",{attrs:{href:"https://paperswithcode.com/sota/text-to-speech-synthesis-on-ljspeech",target:"_blank",rel:"noopener noreferrer"}},[t._v("sota/text-to-speech-synthesis-on-ljspeech"),a("OutboundLink")],1)]),t._v(" "),a("p",[a("a",{attrs:{href:"https://github.com/as-ideas/TransformerTTS",target:"_blank",rel:"noopener noreferrer"}},[t._v("as-ideas/TransformerTTS"),a("OutboundLink")],1)]),t._v(" "),a("p",[a("a",{attrs:{href:"https://r9y9.github.io/blog/2019/06/11/ljspeech/",target:"_blank",rel:"noopener noreferrer"}},[t._v("LJSpeech は価値のあるデータセットですが、ニューラルボコーダの品質比較には向かないと思います"),a("OutboundLink")],1)]),t._v(" "),a("p",[a("a",{attrs:{href:"https://px.a8.net/svt/ejp?a8mat=3HBXCY+4DRW36+50+2HM5Z5",rel:"nofollow"}},[a("img",{attrs:{border:"0",width:"1000",height:"124",alt:"",src:"https://www27.a8.net/svt/bgt?aid=210508450265&wid=001&eno=01&mid=s00000000018015052000&mc=1"}})]),a("img",{attrs:{border:"0",width:"1",height:"1",src:"https://www10.a8.net/0.gif?a8mat=3HBXCY+4DRW36+50+2HM5Z5",alt:""}})]),t._v(" "),a("p",[a("a",{attrs:{href:"https://px.a8.net/svt/ejp?a8mat=3HIN6N+3YAMCY+CO4+6BMG1",rel:"nofollow"}},[a("img",{attrs:{border:"0",width:"1000",height:"124",alt:"",src:"https://www23.a8.net/svt/bgt?aid=210821855239&wid=001&eno=01&mid=s00000001642001062000&mc=1"}})]),a("img",{attrs:{border:"0",width:"1",height:"1",src:"https://www17.a8.net/0.gif?a8mat=3HIN6N+3YAMCY+CO4+6BMG1",alt:""}})]),t._v(" "),a("p",[a("a",{attrs:{href:"https://px.a8.net/svt/ejp?a8mat=3HIN6N+7FBNEA+4AQ0+5YJRM",rel:"nofollow"}},[t._v("全国630店舗以上！もみほぐし・足つぼ・ハンドリフレ・クイックヘッドのリラクゼーション店【りらくる】")]),a("img",{attrs:{border:"0",width:"1",height:"1",src:"https://www15.a8.net/0.gif?a8mat=3HIN6N+7FBNEA+4AQ0+5YJRM",alt:""}})]),t._v(" "),a("ClientOnly",[a("CallInArticleAdsense")],1)],1)}),[],!1,null,null,null);s.default=e.exports}}]);